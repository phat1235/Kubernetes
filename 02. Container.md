# **2 Hiểu về container**
Chương này bao gồm:

* Hiểu container là gì
* Sự khác biệt giữa container và máy ảo
* Tạo, chạy và chia sẻ một image container với Docker
* Các tính năng của nhân Linux giúp container trở nên khả thi

Kubernetes chủ yếu quản lý các ứng dụng chạy trong container – vì vậy trước khi bắt đầu khám phá Kubernetes, bạn cần phải có một sự hiểu biết rõ ràng về container là gì. Chương này giải thích những kiến thức cơ bản về container Linux.

---

### **2.1 Giới thiệu về container**

Trong Chương 1, bạn đã học cách các microservice khác nhau chạy trong cùng một hệ điều hành có thể yêu cầu các phiên bản khác nhau, thậm chí xung đột của các thư viện liên kết động hoặc có các yêu cầu môi trường khác nhau.

Khi một hệ thống chỉ bao gồm một số lượng nhỏ các ứng dụng, việc gán một máy ảo riêng cho từng ứng dụng và chạy mỗi ứng dụng trong hệ điều hành riêng của nó là điều hoàn toàn ổn. Nhưng khi các microservice trở nên nhỏ hơn và số lượng của chúng bắt đầu tăng lên, bạn có thể sẽ không đủ khả năng cung cấp một VM riêng cho từng dịch vụ nếu muốn giữ chi phí phần cứng thấp và không lãng phí tài nguyên.

Không chỉ vấn đề lãng phí tài nguyên phần cứng – mỗi VM thường cần được cấu hình và quản lý riêng, có nghĩa là chạy nhiều VM hơn cũng đồng nghĩa với yêu cầu nhân sự cao hơn và cần một hệ thống tự động hóa tốt hơn, thường phức tạp hơn. Do sự chuyển đổi sang kiến trúc microservice, nơi hệ thống bao gồm hàng trăm phiên bản ứng dụng được triển khai, một giải pháp thay thế cho VM là cần thiết. Container chính là giải pháp đó.

---

### **2.1.1 So sánh container với máy ảo**

Thay vì sử dụng máy ảo để cô lập môi trường của từng microservice (hoặc quy trình phần mềm nói chung), hầu hết các nhóm phát triển và vận hành hiện nay thích sử dụng container. Chúng cho phép bạn chạy nhiều dịch vụ trên cùng một máy chủ, trong khi vẫn giữ chúng tách biệt với nhau. Giống như VM, nhưng với chi phí thấp hơn nhiều.

Không giống như VM, mỗi cái chạy một hệ điều hành riêng với nhiều tiến trình hệ thống, một tiến trình chạy trong container chạy trong hệ điều hành hiện có của máy chủ. Vì chỉ có một hệ điều hành, nên không có các tiến trình hệ thống trùng lặp. Mặc dù tất cả các tiến trình ứng dụng chạy trong cùng một hệ điều hành, môi trường của chúng được tách biệt, mặc dù không hoàn toàn như khi chạy trong các VM riêng. Đối với tiến trình trong container, sự tách biệt này khiến nó “nghĩ” rằng không có tiến trình nào khác tồn tại trên máy tính. Bạn sẽ tìm hiểu cách điều này khả thi trong các phần tiếp theo, nhưng trước tiên hãy đi sâu hơn vào sự khác biệt giữa container và VM.

---

#### **So sánh chi phí tài nguyên giữa container và máy ảo**

So với VM, container nhẹ hơn nhiều, vì chúng không yêu cầu một nhóm tài nguyên riêng hoặc bất kỳ tiến trình hệ điều hành bổ sung nào. Trong khi mỗi VM thường chạy tập hợp tiến trình hệ thống riêng, đòi hỏi tài nguyên tính toán bổ sung bên cạnh những gì tiến trình ứng dụng người dùng tiêu thụ, một container đơn giản chỉ là một tiến trình cô lập chạy trong hệ điều hành máy chủ hiện tại và chỉ tiêu thụ tài nguyên mà ứng dụng cần. Chúng gần như không có chi phí tài nguyên bổ sung.

Hình 2.1 cho thấy hai máy vật lý, một máy chạy hai VM, và máy còn lại chạy container. Máy thứ hai có chỗ cho nhiều container hơn, vì nó chỉ chạy một hệ điều hành, trong khi máy thứ nhất chạy ba – một hệ điều hành máy chủ và hai hệ điều hành khách.

**Hình 2.1** Sử dụng VM để cô lập nhóm ứng dụng so với việc cô lập từng ứng dụng bằng container
![](https://img001.prntscr.com/file/img001/O4V68MykRf2JPcVE0jJwCQ.png)
Do chi phí tài nguyên của VM, bạn thường phải nhóm nhiều ứng dụng vào một VM. Bạn có thể không đủ khả năng dành một VM riêng cho từng ứng dụng. Nhưng container không gây chi phí tài nguyên bổ sung, nghĩa là bạn có thể tạo một container riêng cho mỗi ứng dụng. Trên thực tế, bạn **không bao giờ** nên chạy nhiều ứng dụng trong cùng một container, vì điều này làm cho việc quản lý các tiến trình trong container khó khăn hơn nhiều. Hơn nữa, tất cả phần mềm hiện có xử lý container, bao gồm cả Kubernetes, đều được thiết kế với giả định rằng chỉ có **một ứng dụng trong một container**. Nhưng như bạn sẽ tìm hiểu trong chương tiếp theo, Kubernetes cung cấp cách để chạy các ứng dụng liên quan cùng nhau, nhưng vẫn giữ chúng trong các container riêng biệt.

---

#### **So sánh thời gian khởi động của container và máy ảo**

Ngoài chi phí tài nguyên thấp hơn khi chạy, container cũng khởi động ứng dụng nhanh hơn, vì chỉ cần khởi động tiến trình ứng dụng chính. Không cần khởi động thêm các tiến trình hệ thống như khi khởi động một VM mới.

---

#### **So sánh mức độ cô lập của container và máy ảo**

Bạn sẽ đồng ý rằng container rõ ràng tốt hơn khi nói đến việc sử dụng tài nguyên, nhưng cũng có một nhược điểm. Khi bạn chạy ứng dụng trong VM, mỗi VM chạy hệ điều hành và nhân riêng của nó.

Bên dưới các VM là hypervisor (và có thể là một hệ điều hành bổ sung), chia tài nguyên phần cứng vật lý thành các nhóm tài nguyên ảo nhỏ hơn mà hệ điều hành trong mỗi VM có thể sử dụng. Như hình 2.2 minh họa, các ứng dụng chạy trong các VM này thực hiện các lời gọi hệ thống (system call – syscall) tới nhân của hệ điều hành khách trong VM, và các lệnh máy mà nhân thực thi trên CPU ảo sau đó được chuyển tiếp tới CPU vật lý của máy chủ thông qua hypervisor.

**Hình 2.2** Cách các ứng dụng sử dụng phần cứng khi chạy trong VM so với trong container
![](https://img001.prntscr.com/file/img001/0fKH5GPrT7uZiOALZpeCpg.png)

**Lưu ý**
Có hai loại hypervisor. Hypervisor loại 1 không yêu cầu chạy một hệ điều hành máy chủ, trong khi hypervisor loại 2 thì cần.

Container, mặt khác, tất cả đều thực hiện lời gọi hệ thống trên cùng một nhân chạy trong hệ điều hành máy chủ. Nhân này là thành phần duy nhất thực thi lệnh trên CPU của máy chủ. CPU không cần xử lý bất kỳ loại ảo hóa nào như với VM.

Hãy xem hình sau để thấy sự khác biệt giữa việc chạy ba ứng dụng trên máy vật lý, chạy chúng trong hai VM riêng, hoặc chạy chúng trong ba container.

**Hình 2.3** Sự khác biệt giữa việc chạy ứng dụng trên máy vật lý, trong máy ảo, và trong container
![](https://img001.prntscr.com/file/img001/E5cZbrUcRlGaOWVEWBLBrA.png)
Trong trường hợp đầu tiên, cả ba ứng dụng dùng chung một nhân và hoàn toàn không được tách biệt. Trong trường hợp thứ hai, ứng dụng A và B chạy trong cùng một VM và do đó dùng chung một nhân, trong khi ứng dụng C hoàn toàn tách biệt với hai ứng dụng kia, vì nó sử dụng nhân riêng. Nó chỉ chia sẻ phần cứng với hai ứng dụng đầu tiên.

Trường hợp thứ ba cho thấy cùng ba ứng dụng chạy trong container. Mặc dù chúng đều dùng chung một nhân, chúng được tách biệt khỏi nhau và hoàn toàn không biết sự tồn tại của nhau. Sự tách biệt này được cung cấp bởi chính nhân hệ điều hành. Mỗi ứng dụng chỉ nhìn thấy một phần phần cứng vật lý và nghĩ rằng mình là tiến trình duy nhất chạy trong hệ điều hành, mặc dù tất cả đều chạy trong cùng một hệ điều hành.

---

### **Hiểu các tác động bảo mật của việc cô lập container**

Ưu điểm chính của việc sử dụng VM so với container là mức độ cô lập hoàn toàn mà chúng cung cấp, vì mỗi VM có nhân Linux riêng, trong khi tất cả container dùng chung một nhân. Điều này rõ ràng có thể gây ra rủi ro bảo mật. Nếu có một lỗi trong nhân, một ứng dụng trong container có thể khai thác nó để đọc bộ nhớ của các ứng dụng trong container khác. Nếu các ứng dụng chạy trong các VM khác nhau và do đó chỉ chia sẻ phần cứng, khả năng xảy ra các cuộc tấn công như vậy sẽ thấp hơn nhiều. Tất nhiên, mức độ cô lập hoàn toàn chỉ đạt được khi chạy ứng dụng trên các máy vật lý riêng biệt.

Ngoài ra, container chia sẻ không gian bộ nhớ, trong khi mỗi VM sử dụng phân vùng bộ nhớ riêng. Do đó, nếu bạn không giới hạn lượng bộ nhớ mà một container có thể sử dụng, điều này có thể khiến các container khác hết bộ nhớ hoặc dữ liệu của chúng bị chuyển sang lưu trữ trên đĩa.

**Lưu ý**
Điều này không thể xảy ra trong Kubernetes, vì nó yêu cầu vô hiệu hóa swap trên tất cả các node.

---

### **Hiểu những gì cho phép container và máy ảo hoạt động**

Trong khi máy ảo được hỗ trợ nhờ tính năng ảo hóa trong CPU và phần mềm ảo hóa trên máy chủ, container được hỗ trợ bởi chính nhân Linux. Bạn sẽ tìm hiểu về các công nghệ container sau này khi có thể tự thử nghiệm. Bạn sẽ cần cài Docker cho phần này, vì vậy hãy cùng tìm hiểu cách Docker phù hợp với câu chuyện về container.

### 2.1.2 Giới thiệu nền tảng Docker Container

Mặc dù công nghệ container đã tồn tại từ lâu, nhưng nó chỉ trở nên phổ biến rộng rãi với sự xuất hiện của Docker. Docker là hệ thống container đầu tiên giúp chúng dễ dàng di chuyển qua nhiều máy tính khác nhau. Nó đơn giản hóa quá trình đóng gói ứng dụng và tất cả các thư viện, phụ thuộc khác – thậm chí cả toàn bộ hệ điều hành – thành một gói đơn giản, di động, có thể được sử dụng để triển khai ứng dụng trên bất kỳ máy tính nào chạy Docker.

#### Giới thiệu containers, images và registries

Docker là một nền tảng để đóng gói, phân phối và chạy ứng dụng. Như đã đề cập, nó cho phép bạn đóng gói ứng dụng cùng với toàn bộ môi trường của nó. Điều này có thể chỉ là một vài thư viện liên kết động mà ứng dụng cần, hoặc tất cả các tệp tin thường đi kèm với một hệ điều hành. Docker cho phép bạn phân phối gói này qua kho lưu trữ công cộng đến bất kỳ máy tính nào có Docker.

**Hình 2.4** Ba khái niệm chính trong Docker là images, registries và containers.
![](https://img001.prntscr.com/file/img001/vRf5INeGRx61vDMpqmwgfA.png)
Hình 2.4 cho thấy ba khái niệm chính trong Docker xuất hiện trong quá trình tôi vừa mô tả. Đây là ý nghĩa của từng khái niệm:

* **Images** — Một image container là thứ mà bạn đóng gói ứng dụng và môi trường của nó vào. Giống như một tệp zip hoặc tarball. Nó chứa toàn bộ hệ thống tệp mà ứng dụng sẽ sử dụng và siêu dữ liệu bổ sung, chẳng hạn như đường dẫn đến tệp thực thi để chạy khi image được khởi chạy, các cổng mà ứng dụng lắng nghe và các thông tin khác về image.
* **Registries** — Một registry là kho lưu trữ các container images cho phép trao đổi images giữa các cá nhân và máy tính khác nhau. Sau khi bạn tạo image, bạn có thể chạy nó trên cùng một máy tính hoặc **push** (tải lên) image đến một registry và sau đó **pull** (tải xuống) nó về một máy khác. Một số registry là công khai, cho phép bất kỳ ai cũng có thể tải xuống images từ đó, trong khi một số khác là riêng tư, chỉ truy cập được với những cá nhân, tổ chức hoặc máy tính có thông tin xác thực cần thiết.
* **Containers** — Một container được khởi tạo từ một container image. Một container đang chạy là một tiến trình bình thường chạy trong hệ điều hành của máy chủ, nhưng môi trường của nó được tách biệt khỏi môi trường của máy chủ và các tiến trình khác. Hệ thống tệp của container bắt nguồn từ container image, nhưng cũng có thể gắn thêm các hệ thống tệp bổ sung vào container. Thông thường, container bị giới hạn tài nguyên, nghĩa là nó chỉ có thể truy cập và sử dụng lượng tài nguyên như CPU và bộ nhớ đã được phân bổ cho nó.

#### Xây dựng, phân phối và chạy một container image

Để hiểu cách containers, images và registries liên quan đến nhau, hãy xem cách xây dựng một container image, phân phối nó qua registry và tạo một container đang chạy từ image. Ba quá trình này được minh họa trong các hình 2.5 đến 2.7.

* **Hình 2.5** Xây dựng một container image
![](https://img001.prntscr.com/file/img001/ojS3rmL2TDCaG8LfIlmWsQ.png)
  Như thể hiện trong hình 2.5, nhà phát triển đầu tiên xây dựng một image, sau đó đẩy nó lên một registry như thể hiện trong hình 2.6. Image giờ đây có sẵn cho bất kỳ ai có quyền truy cập vào registry.

* **Hình 2.6** Tải một container image lên một registry
![](https://img001.prntscr.com/file/img001/3voeXPHpQ9GG9NxMWjtmlg.png)
  Như hình tiếp theo cho thấy, một người khác giờ đây có thể kéo image về bất kỳ máy tính nào đang chạy Docker và chạy nó. Docker tạo một container biệt lập dựa trên image và gọi tệp thực thi được chỉ định trong image.

* **Hình 2.7** Chạy một container trên một máy tính khác
![](https://img001.prntscr.com/file/img001/FAHpI2mCSoifZJJ5Ft9znA.png)
  Việc chạy ứng dụng trên bất kỳ máy tính nào là khả thi nhờ vào thực tế rằng môi trường của ứng dụng được tách biệt khỏi môi trường của máy chủ.

#### Hiểu môi trường mà ứng dụng nhìn thấy

Khi bạn chạy một ứng dụng trong container, nó nhìn thấy chính xác nội dung hệ thống tệp mà bạn đã đóng gói vào container image, cũng như bất kỳ hệ thống tệp bổ sung nào bạn gắn vào container. Ứng dụng nhìn thấy cùng một tệp cho dù nó đang chạy trên laptop của bạn hay trên một máy chủ sản xuất đầy đủ, ngay cả khi máy chủ sản xuất sử dụng một bản phân phối Linux hoàn toàn khác. Ứng dụng thường không có quyền truy cập vào các tệp trong hệ điều hành của máy chủ, vì vậy không quan trọng nếu máy chủ có một bộ thư viện hoàn toàn khác với máy tính phát triển của bạn.

Ví dụ: nếu bạn đóng gói ứng dụng của mình với các tệp của toàn bộ hệ điều hành **Red Hat Enterprise Linux (RHEL)** và sau đó chạy nó, ứng dụng sẽ nghĩ rằng nó đang chạy bên trong RHEL, cho dù bạn chạy nó trên máy tính dựa trên Fedora hay Debian. Bản phân phối Linux được cài đặt trên máy chủ là không liên quan. Điều duy nhất có thể quan trọng là phiên bản kernel và các mô-đun kernel mà nó tải. Sau này, tôi sẽ giải thích lý do.

Điều này tương tự như việc tạo một image VM bằng cách tạo một VM mới, cài đặt hệ điều hành và ứng dụng của bạn trong đó, sau đó phân phối toàn bộ image VM để những người khác có thể chạy nó trên các máy chủ khác nhau. Docker đạt được cùng hiệu quả, nhưng thay vì sử dụng VM để cách ly ứng dụng, nó sử dụng công nghệ container của Linux để đạt được mức độ cách ly (gần như) tương đương.

#### Hiểu các lớp image

Không giống như các image máy ảo, vốn là các khối lớn của toàn bộ hệ thống tệp cần thiết cho hệ điều hành được cài đặt trong VM, container images bao gồm nhiều lớp thường nhỏ hơn nhiều. Các lớp này có thể được chia sẻ và tái sử dụng giữa nhiều images khác nhau. Điều này có nghĩa là chỉ một số lớp nhất định của một image cần được tải xuống nếu các lớp còn lại đã được tải xuống máy chủ như một phần của image khác chứa cùng các lớp đó.

Các lớp làm cho việc phân phối image rất hiệu quả nhưng cũng giúp giảm dung lượng lưu trữ của images. Docker chỉ lưu trữ mỗi lớp một lần. Như bạn có thể thấy trong hình sau, hai containers được tạo từ hai images chứa cùng các lớp sẽ sử dụng cùng các tệp.

**Hình 2.8** Containers có thể chia sẻ các lớp image
![](https://img001.prntscr.com/file/img001/RCqCkNq2T_-D_DU_Ph9SkA.png)
Hình minh họa rằng containers A và B chia sẻ một lớp image, nghĩa là ứng dụng A và B đọc một số tệp giống nhau. Ngoài ra, chúng cũng chia sẻ lớp nền với container C. Nhưng nếu cả ba containers đều truy cập cùng các tệp, làm sao chúng có thể hoàn toàn tách biệt với nhau? Những thay đổi mà ứng dụng A thực hiện với một tệp trong lớp chia sẻ có hiển thị với ứng dụng B không? Câu trả lời là **không**. Lý do như sau.

Hệ thống tệp được cách ly bởi cơ chế **Copy-on-Write (CoW)**. Hệ thống tệp của một container bao gồm các lớp chỉ đọc từ container image và một lớp đọc/ghi bổ sung được xếp chồng lên trên. Khi một ứng dụng chạy trong container A thay đổi một tệp trong một trong các lớp chỉ đọc, toàn bộ tệp sẽ được sao chép vào lớp đọc/ghi của container và nội dung tệp sẽ được thay đổi ở đó. Vì mỗi container có lớp ghi riêng nên các thay đổi đối với các tệp chia sẻ sẽ không hiển thị trong bất kỳ container nào khác.

Khi bạn xóa một tệp, nó chỉ được đánh dấu là đã xóa trong lớp đọc/ghi, nhưng nó vẫn tồn tại trong một hoặc nhiều lớp bên dưới. Điều này có nghĩa là xóa tệp sẽ **không bao giờ** giảm kích thước của image.

**Cảnh báo**
Ngay cả những thao tác tưởng chừng vô hại như thay đổi quyền hoặc quyền sở hữu của một tệp cũng tạo ra một bản sao mới của toàn bộ tệp trong lớp đọc/ghi. Nếu bạn thực hiện loại thao tác này trên một tệp lớn hoặc nhiều tệp, kích thước image có thể tăng đáng kể.

#### Hiểu các giới hạn về tính di động của container images

Về lý thuyết, một container image dựa trên Docker có thể chạy trên bất kỳ máy tính Linux nào chạy Docker, nhưng có một lưu ý nhỏ, vì containers không có kernel riêng của chúng. Nếu một ứng dụng trong container yêu cầu một phiên bản kernel cụ thể, nó có thể không hoạt động trên mọi máy tính.

Nếu một máy tính đang chạy một phiên bản khác của Linux kernel hoặc không tải các mô-đun kernel cần thiết, ứng dụng sẽ không thể chạy trên đó. Kịch bản này được minh họa trong hình sau.

**Hình 2.9** Nếu một container yêu cầu các tính năng hoặc mô-đun kernel cụ thể, nó có thể không hoạt động ở mọi nơi.
![](https://img001.prntscr.com/file/img001/UIX5n95YQ3WrUXCuV4572w.png)
Container B yêu cầu một mô-đun kernel cụ thể để chạy đúng cách. Mô-đun này được tải trong kernel ở máy tính đầu tiên nhưng không có trong máy thứ hai. Bạn có thể chạy container image trên máy thứ hai, nhưng nó sẽ gặp lỗi khi cố gắng sử dụng mô-đun bị thiếu.

Và vấn đề không chỉ ở kernel và các mô-đun của nó. Ứng dụng trong container được xây dựng cho một kiến trúc phần cứng cụ thể chỉ có thể chạy trên các máy tính có cùng kiến trúc. Bạn không thể đưa một ứng dụng được biên dịch cho kiến trúc CPU x86 vào một container và mong muốn chạy nó trên một máy tính dựa trên ARM chỉ vì Docker có sẵn trên đó. Để làm điều này, bạn sẽ cần một VM để giả lập kiến trúc x86.

### 2.1.3 Cài đặt Docker và chạy container Hello World

Bây giờ bạn đã có kiến thức cơ bản về container là gì, vậy hãy dùng Docker để chạy một container. Bạn sẽ cài đặt Docker và chạy một container Hello World.

#### Cài đặt Docker

Lý tưởng nhất là bạn sẽ cài đặt Docker trực tiếp trên một máy tính Linux, như vậy bạn sẽ không phải xử lý sự phức tạp bổ sung của việc chạy container bên trong một VM đang chạy trong hệ điều hành chủ của bạn. Nhưng nếu bạn đang sử dụng macOS hoặc Windows và không biết cách thiết lập một VM Linux, ứng dụng **Docker Desktop** sẽ thiết lập nó cho bạn. Công cụ dòng lệnh Docker (CLI) mà bạn sẽ sử dụng để chạy container sẽ được cài đặt trong hệ điều hành chủ, nhưng Docker daemon sẽ chạy bên trong VM, cũng như tất cả các container mà nó tạo ra.

Nền tảng Docker bao gồm nhiều thành phần, nhưng bạn chỉ cần cài đặt **Docker Engine** để chạy container. Nếu bạn sử dụng macOS hoặc Windows, hãy cài đặt **Docker Desktop**. Để biết chi tiết, hãy làm theo hướng dẫn tại
[http://docs.docker.com/install](http://docs.docker.com/install).

**Ghi chú**
Docker Desktop cho Windows có thể chạy cả container Windows và Linux. Hãy đảm bảo bạn cấu hình nó để sử dụng container Linux, vì tất cả các ví dụ trong cuốn sách này đều giả định điều đó.

---

#### Chạy container Hello World

Sau khi cài đặt xong, bạn sử dụng công cụ CLI docker để chạy các lệnh Docker. Hãy thử tải và chạy một image có sẵn từ **Docker Hub**, registry image công cộng chứa các container image sẵn sàng sử dụng cho nhiều gói phần mềm nổi tiếng. Một trong số đó là image **busybox**, bạn sẽ dùng để chạy lệnh đơn giản `echo "Hello world"` trong container đầu tiên của mình.

Nếu bạn chưa quen với **busybox**, đây là một tệp thực thi đơn kết hợp nhiều công cụ dòng lệnh UNIX tiêu chuẩn, chẳng hạn như echo, ls, gzip, và nhiều công cụ khác. Thay vì image busybox, bạn cũng có thể sử dụng bất kỳ image container hệ điều hành đầy đủ nào khác như Fedora, Ubuntu hoặc bất kỳ image nào chứa tệp thực thi echo.

Khi bạn đã cài đặt Docker, bạn không cần phải tải xuống hoặc cài đặt bất kỳ thứ gì khác để chạy image busybox. Bạn có thể làm mọi thứ với một lệnh `docker run` duy nhất, bằng cách chỉ định image cần tải xuống và lệnh cần chạy trong đó. Để chạy container Hello World, lệnh và kết quả đầu ra như sau:

```
$ docker run busybox echo "Hello World"
Unable to find image 'busybox:latest' locally   #A
latest: Pulling from library/busybox            #A
7c9d20b9b6cd: Pull complete                     #A
Digest: sha256:fe301db49df08c384001ed752dff6d52b4...  #A
Status: Downloaded newer image for busybox:latest    #A
Hello World                                    #B
```

Với một lệnh duy nhất này, bạn đã nói với Docker image nào sẽ được dùng để tạo container và lệnh nào sẽ chạy trong container. Điều này có thể không trông ấn tượng lắm, nhưng hãy nhớ rằng toàn bộ “ứng dụng” đã được tải xuống và thực thi chỉ với một lệnh duy nhất, mà không cần bạn phải cài đặt ứng dụng hoặc bất kỳ phụ thuộc nào của nó.

Trong ví dụ này, ứng dụng chỉ là một tệp thực thi đơn giản, nhưng nó cũng có thể là một ứng dụng phức tạp với hàng tá thư viện và tệp bổ sung. Toàn bộ quá trình thiết lập và chạy ứng dụng sẽ giống hệt nhau. Điều không rõ ràng ở đây là nó chạy trong một container, được cách ly khỏi các tiến trình khác trên máy tính. Bạn sẽ thấy điều này là đúng trong các bài tập còn lại của chương này.

---

#### Hiểu điều gì xảy ra khi bạn chạy một container

**Hình 2.10** cho thấy chính xác điều gì xảy ra khi bạn thực thi lệnh `docker run`.
![](https://img001.prntscr.com/file/img001/KrLDTiw4TN-o1PhXhEFGVA.png)
**Hình 2.10** Chạy `echo "Hello world"` trong một container dựa trên container image busybox.

Công cụ CLI docker gửi một lệnh chạy container đến Docker daemon, daemon sẽ kiểm tra xem image busybox đã có sẵn trong bộ nhớ cache image cục bộ hay chưa. Nếu chưa, daemon sẽ tải nó từ **Docker Hub registry**.

Sau khi tải image về máy tính của bạn, Docker daemon tạo một container từ image đó và thực thi lệnh echo trong đó. Lệnh này in văn bản ra đầu ra chuẩn, tiến trình sau đó kết thúc và container dừng lại.

Nếu máy tính cục bộ của bạn chạy hệ điều hành Linux, cả công cụ CLI docker và daemon đều chạy trong hệ điều hành này. Nếu nó chạy macOS hoặc Windows, daemon và các container sẽ chạy trong VM Linux.

---

#### Chạy các image khác

Chạy các container image có sẵn khác cũng giống như chạy image busybox. Thực tế, nó thường còn đơn giản hơn, vì bạn thường không cần chỉ định lệnh nào sẽ thực thi, như với lệnh echo trong ví dụ trước. Lệnh cần thực thi thường được viết sẵn trong image, nhưng bạn có thể ghi đè nó khi chạy.

Ví dụ, nếu bạn muốn chạy **Redis datastore**, bạn có thể tìm tên image trên [http://hub.docker.com](http://hub.docker.com) hoặc một registry công cộng khác. Trong trường hợp của Redis, một trong các image có tên là **redis\:alpine**, vì vậy bạn sẽ chạy nó như sau:

```
$ docker run redis:alpine
```

Để dừng và thoát khỏi container, nhấn **Control-C**.

**Ghi chú**
Nếu bạn muốn chạy một image từ một registry khác, bạn phải chỉ định registry cùng với tên image. Ví dụ: nếu bạn muốn chạy một image từ registry **Quay.io**, là một registry image công cộng khác, hãy chạy như sau:

```
docker run quay.io/some/image
```

---

#### Hiểu các image tags

Nếu bạn đã tìm kiếm image Redis trên Docker Hub, bạn sẽ thấy có rất nhiều image tags để bạn lựa chọn. Đối với Redis, các tag bao gồm **latest**, **buster**, **alpine**, nhưng cũng có **5.0.7-buster**, **5.0.7-alpine**, và nhiều tag khác.

Docker cho phép bạn có nhiều phiên bản hoặc biến thể của cùng một image dưới cùng một tên. Mỗi biến thể có một tag duy nhất. Nếu bạn tham chiếu đến các image mà không chỉ định rõ tag, Docker sẽ mặc định cho rằng bạn đang tham chiếu đến tag đặc biệt **latest**. Khi tải lên một phiên bản mới của image, tác giả image thường gắn tag cho nó với cả số phiên bản thực tế và **latest**.

Khi bạn muốn chạy phiên bản mới nhất của một image, hãy dùng tag **latest** thay vì chỉ định phiên bản.

**Ghi chú**
Lệnh `docker run` chỉ tải image nếu nó chưa được tải trước đó. Sử dụng tag **latest** đảm bảo rằng bạn nhận được phiên bản mới nhất khi lần đầu tiên chạy image. Image được lưu trong bộ nhớ cache cục bộ sẽ được sử dụng kể từ thời điểm đó trở đi.

Ngay cả đối với một phiên bản duy nhất, thường có một số biến thể của image. Đối với Redis, tôi đã đề cập **5.0.7-buster** và **5.0.7-alpine**. Cả hai đều chứa cùng một phiên bản Redis, nhưng khác nhau ở image nền mà chúng được xây dựng. **5.0.7-buster** dựa trên phiên bản Debian “Buster”, trong khi **5.0.7-alpine** dựa trên image nền Alpine Linux, một image rất tối giản chỉ có 5MB – nó chỉ chứa một tập hợp nhỏ các binary được cài đặt mà bạn thấy trong một bản phân phối Linux điển hình.

Để chạy một phiên bản và/hoặc biến thể cụ thể của image, hãy chỉ định tag trong tên image. Ví dụ, để chạy tag **5.0.7-alpine**, bạn sẽ thực thi lệnh sau:

```
$ docker run redis:5.0.7-alpine
```

Ngày nay, bạn có thể tìm thấy container images cho hầu hết tất cả các ứng dụng phổ biến. Bạn có thể sử dụng Docker để chạy các image đó bằng lệnh một dòng đơn giản `docker run`.

### 2.1.4 Giới thiệu Sáng kiến Container Mở (Open Container Initiative) và các lựa chọn thay thế Docker

Docker là nền tảng container đầu tiên đưa container trở nên phổ biến. Tôi hy vọng rằng tôi đã làm rõ rằng Docker không phải là thứ cung cấp sự cô lập tiến trình. Sự cô lập thực sự của container diễn ra ở mức nhân Linux, sử dụng các cơ chế mà nhân Linux cung cấp. Docker là công cụ sử dụng các cơ chế này để giúp việc chạy container trở nên gần như đơn giản. Nhưng đây chắc chắn không phải là công cụ duy nhất.

#### Giới thiệu Sáng kiến Container Mở (OCI)

Sau thành công của Docker, Sáng kiến Container Mở (Open Container Initiative – OCI) ra đời để tạo ra các tiêu chuẩn mở trong ngành liên quan đến định dạng và runtime của container. Docker là một phần của sáng kiến này, cùng với các runtime container khác và nhiều tổ chức quan tâm đến công nghệ container.

Các thành viên của OCI đã tạo ra **Đặc tả Định dạng Ảnh OCI (OCI Image Format Specification)**, quy định định dạng tiêu chuẩn cho các ảnh container, và **Đặc tả Runtime OCI (OCI Runtime Specification)**, định nghĩa giao diện tiêu chuẩn cho runtime của container với mục tiêu tiêu chuẩn hóa việc tạo, cấu hình và thực thi container.

#### Giới thiệu Giao diện Runtime Container (CRI) và triển khai của nó (CRI-O)

Cuốn sách này tập trung vào việc sử dụng Docker làm runtime container cho Kubernetes, vì ban đầu đây là runtime duy nhất được Kubernetes hỗ trợ và hiện vẫn là runtime được sử dụng rộng rãi nhất. Nhưng giờ đây Kubernetes hỗ trợ nhiều runtime container khác thông qua **Giao diện Runtime Container (Container Runtime Interface – CRI)**.

Một triển khai của CRI là **CRI-O**, một lựa chọn thay thế nhẹ cho Docker, cho phép bạn sử dụng bất kỳ runtime container nào tuân thủ OCI với Kubernetes. Các ví dụ về runtime tuân thủ OCI bao gồm **rkt** (đọc là Rocket), **runC**, và **Kata Containers**.

---

### 2.2 Triển khai Kiada — Ứng dụng Demo Kubernetes in Action

Bây giờ bạn đã có một thiết lập Docker hoạt động, bạn có thể bắt đầu xây dựng một ứng dụng phức tạp hơn. Bạn sẽ xây dựng một ứng dụng dựa trên microservices có tên là **Kiada - Ứng dụng Demo Kubernetes in Action**.

Trong chương này, bạn sẽ sử dụng Docker để chạy ứng dụng này. Trong các chương tiếp theo, bạn sẽ chạy ứng dụng trong Kubernetes. Trong suốt cuốn sách này, bạn sẽ mở rộng nó từng bước và tìm hiểu các tính năng riêng lẻ của Kubernetes giúp bạn giải quyết các vấn đề điển hình khi chạy ứng dụng.

---

### 2.2.1 Giới thiệu Bộ ứng dụng Kiada (Kiada Suite)

**Ứng dụng Demo Kubernetes in Action** là một ứng dụng web hiển thị các trích dẫn từ cuốn sách này, đặt cho bạn các câu hỏi liên quan đến Kubernetes để giúp bạn kiểm tra mức độ tiến bộ kiến thức của mình, và cung cấp danh sách các liên kết đến các trang web bên ngoài liên quan đến Kubernetes hoặc cuốn sách này. Nó cũng in ra thông tin về container đã xử lý yêu cầu của trình duyệt. Bạn sẽ sớm thấy tại sao điều này quan trọng.

---

#### Giao diện và hoạt động của ứng dụng

Ảnh chụp màn hình của ứng dụng web được trình bày trong hình sau:

**Hình 2.11** Ảnh chụp màn hình Ứng dụng Demo Kubernetes in Action (Kiada)
![](https://img001.prntscr.com/file/img001/COyIS3vXSZGn-nXUCqL1qQ.png)
Kiến trúc của ứng dụng Kiada được hiển thị trong hình tiếp theo. HTML được cung cấp bởi một ứng dụng web chạy trong máy chủ **Node.js**. Mã JavaScript phía client sau đó sẽ lấy trích dẫn và câu hỏi từ các dịch vụ RESTful **Quote** và **Quiz**. Ứng dụng Node.js và các dịch vụ này tạo thành **Bộ ứng dụng Kiada (Kiada Suite)** hoàn chỉnh.

**Hình 2.12** Kiến trúc và hoạt động của Bộ ứng dụng Kiada
![](https://img001.prntscr.com/file/img001/gQCF4aI-Q-Od11yxpZMZnA.png)
Trình duyệt web giao tiếp trực tiếp với ba dịch vụ khác nhau. Nếu bạn quen thuộc với kiến trúc microservices, bạn có thể tự hỏi tại sao không có **API Gateway** nào trong hệ thống. Điều này được thiết kế để tôi có thể minh họa các vấn đề và giải pháp liên quan đến các trường hợp có nhiều dịch vụ khác nhau được triển khai trong Kubernetes (các dịch vụ có thể không nằm sau cùng một API Gateway). Nhưng chương 11 cũng sẽ giải thích cách đưa API Gateway gốc của Kubernetes vào hệ thống.

---

#### Giao diện và hoạt động của phiên bản văn bản thuần túy

Bạn sẽ dành nhiều thời gian tương tác với Kubernetes qua **terminal**, nên bạn có thể không muốn chuyển qua lại giữa nó và trình duyệt web khi thực hiện các bài tập. Vì lý do này, ứng dụng cũng có thể được sử dụng ở chế độ văn bản thuần túy.

Chế độ văn bản thuần túy cho phép bạn sử dụng ứng dụng trực tiếp từ terminal bằng công cụ như **curl**. Trong trường hợp đó, phản hồi được gửi bởi ứng dụng sẽ như sau:

```
==== TIP OF THE MINUTE
Liveness probes can only be used in the pod’s regular containers.
They can’t be defined in init containers.
==== POP QUIZ
Third question
0) First answer
1) Second answer
2) Third answer
Submit your answer to /question/0/answers/<index of answer> using the POST
==== REQUEST INFO
Request processed by Kubia 1.0 running in pod "kiada-ssl" on node "kind-wor
Pod hostname: kiada-ssl; Pod IP: 10.244.2.188; Node IP: 172.18.0.2; Client
```

Phiên bản HTML có thể truy cập tại URI `/html`, trong khi phiên bản văn bản ở `/text`. Nếu client yêu cầu đường dẫn gốc `/`, ứng dụng sẽ kiểm tra **header Accept** của yêu cầu để đoán xem client có phải là trình duyệt web đồ họa không, trong trường hợp đó nó sẽ chuyển hướng đến `/html`, hoặc nếu là công cụ dựa trên văn bản như **curl**, nó sẽ gửi phản hồi văn bản thuần túy.

Trong chế độ hoạt động này, chính ứng dụng **Node.js** sẽ gọi các dịch vụ **Quote** và **Quiz**, như được hiển thị trong hình tiếp theo.

**Hình 2.13** Hoạt động khi client yêu cầu phiên bản văn bản
![](https://img001.prntscr.com/file/img001/kFy3ykmpSBqSH_v3OsNDlQ.png)
Xét về mặt mạng, chế độ hoạt động này rất khác so với chế độ trước đó. Trong trường hợp này, các dịch vụ **Quote** và **Quiz** được gọi **bên trong cluster**, trong khi trước đó chúng được gọi trực tiếp từ trình duyệt. Để hỗ trợ cả hai chế độ hoạt động, các dịch vụ do đó phải được **cung cấp cả nội bộ và bên ngoài**.

---

**Lưu ý**
Phiên bản ban đầu của ứng dụng sẽ **không kết nối với bất kỳ dịch vụ nào**. Bạn sẽ xây dựng và tích hợp các dịch vụ trong các chương sau.


### 2.2.2 Xây dựng ứng dụng

Với cái nhìn tổng quan về ứng dụng đã có, bây giờ là lúc bắt đầu xây dựng ứng dụng. Thay vì đi thẳng đến phiên bản hoàn chỉnh của ứng dụng, chúng ta sẽ tiến hành chậm rãi và xây dựng ứng dụng theo từng bước trong suốt cuốn sách này.

#### Giới thiệu phiên bản ban đầu của ứng dụng

Phiên bản ban đầu của ứng dụng mà bạn sẽ chạy trong chương này, dù hỗ trợ cả hai chế độ HTML và văn bản thuần (plain-text), sẽ không hiển thị câu trích dẫn (quote) và bài đố nhanh (pop quiz), mà chỉ hiển thị thông tin về ứng dụng và yêu cầu (request).
Thông tin này bao gồm phiên bản của ứng dụng, tên máy chủ (hostname) xử lý yêu cầu của khách hàng, và địa chỉ IP của khách hàng. Đây là phản hồi dạng văn bản thuần mà nó gửi:

```
Kiada version 0.1. Request processed by "<server-hostname>". Client IP: <cl
```

Mã nguồn của ứng dụng có sẵn trong kho mã của cuốn sách trên GitHub. Bạn sẽ tìm thấy mã của phiên bản ban đầu trong thư mục **Chapter02/kiada-0.1**.
Mã JavaScript nằm trong tệp **app.js**, còn HTML và các tài nguyên khác nằm trong thư mục **html**. Mẫu phản hồi HTML nằm trong **index.html**, còn phản hồi văn bản thuần nằm trong **index.txt**.

Bây giờ bạn có thể tải xuống và cài đặt Node.js trên máy tính của mình và thử nghiệm ứng dụng trực tiếp, nhưng điều đó không cần thiết. Vì bạn đã cài Docker, nên việc đóng gói ứng dụng vào một image của container và chạy nó trong container sẽ dễ dàng hơn. Cách này giúp bạn không cần cài đặt gì thêm và có thể chạy cùng một image trên bất kỳ máy nào có Docker mà không phải cài đặt lại.

---

### Tạo Dockerfile cho container image

Để đóng gói ứng dụng của bạn thành một image, bạn cần một tệp gọi là **Dockerfile**, tệp này chứa danh sách các lệnh mà Docker thực hiện khi xây dựng image.
Danh sách sau hiển thị nội dung của tệp mà bạn sẽ tìm thấy trong **Chapter02/kiada-0.1/Dockerfile**.

**Danh sách 2.1. Dockerfile tối giản để xây dựng container image cho ứng dụng của bạn**

```
FROM node:16        #A
COPY app.js /app.js #B
COPY html/ /html    #C
ENTRYPOINT ["node", "app.js"] #D
```

Dòng **FROM** xác định container image mà bạn sẽ dùng làm điểm bắt đầu (image cơ sở mà bạn xây dựng dựa trên đó). Image cơ sở được sử dụng trong danh sách là **node** với thẻ (tag) **16**.
Trong dòng thứ hai, tệp **app.js** được sao chép từ thư mục cục bộ của bạn vào thư mục gốc của image. Tương tự, dòng thứ ba sao chép thư mục **html** vào image. Cuối cùng, dòng cuối cùng chỉ định lệnh mà Docker sẽ chạy khi bạn khởi động container. Trong danh sách, lệnh này là:

```
node app.js
```

---

### Chọn image cơ sở

Bạn có thể thắc mắc tại sao lại dùng image cụ thể này làm cơ sở.
Vì ứng dụng của bạn là ứng dụng **Node.js**, bạn cần image của mình chứa tệp nhị phân **node** để chạy ứng dụng. Bạn có thể dùng bất kỳ image nào có chứa tệp nhị phân này, hoặc thậm chí có thể dùng image của một bản phân phối Linux như **Fedora** hoặc **Ubuntu** và cài đặt Node.js vào container khi xây dựng image.
Nhưng vì image **node** đã chứa sẵn mọi thứ cần thiết để chạy ứng dụng Node.js, nên việc xây dựng image từ đầu là không hợp lý. Tuy nhiên, trong một số tổ chức, việc sử dụng image cơ sở cụ thể và thêm phần mềm vào đó khi build có thể là bắt buộc.

---

### Xây dựng container image

Tệp **Dockerfile**, **app.js**, và các tệp trong thư mục **html** là tất cả những gì bạn cần để xây dựng image của mình.
Với lệnh sau, bạn sẽ xây dựng image và gắn thẻ nó là **kiada\:latest**:

```
$ docker build -t kiada:latest .
```

Kết quả:

```
Sending build context to Docker daemon 3.072kB
Step 1/4 : FROM node:16 #A
16: Pulling from library/node
092586df9206: Pull complete #B
ef599477fae0: Pull complete #B
... #B
89e674ac3af7: Pull complete #B
08df71ec9bb0: Pull complete #B
Digest: sha256:a919d679dd773a56acce15afa0f436055c9b9f20e1f28b4469a4bee69e0.
Status: Downloaded newer image for node:16
---> e498dabfee1c #C
Step 2/4 : COPY app.js /app.js #D
---> 28d67701d6d9 #D
Step 3/4 : COPY html/ /html #E
---> 1d4de446f0f0 #E
Step 4/4 : ENTRYPOINT ["node", "app.js"] #F
---> Running in a01d42eda116 #F
Removing intermediate container a01d42eda116 #F
---> b0ecc49d7a1d #F
Successfully built b0ecc49d7a1d #G
Successfully tagged kiada:latest #G
```

Tùy chọn **-t** chỉ định tên và thẻ của image, còn dấu chấm ở cuối chỉ định rằng **Dockerfile** và các tệp cần thiết để xây dựng image nằm trong thư mục hiện tại. Đây được gọi là **build context**.

Khi quá trình build hoàn tất, image mới được tạo sẽ có trong kho image cục bộ trên máy tính của bạn. Bạn có thể xem bằng cách liệt kê các image cục bộ với lệnh sau:

```
$ docker images
REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE
kiada latest b0ecc49d7a1d 1 minute ago 908 MB
...
```

---

### Hiểu cách image được xây dựng

Hình dưới đây minh họa điều gì xảy ra trong quá trình build.
Bạn yêu cầu Docker xây dựng một image tên **kiada** dựa trên nội dung của thư mục hiện tại. Docker đọc **Dockerfile** trong thư mục và xây dựng image dựa trên các chỉ thị trong tệp đó.

**Hình 2.14.** Xây dựng container image mới bằng Dockerfile
![](https://img001.prntscr.com/file/img001/X88zqF3aRRiCtG8PKXrHmQ.png)
Quá trình build thực tế không được thực hiện bởi công cụ CLI **docker**. Thay vào đó, toàn bộ nội dung thư mục được tải lên **Docker daemon** và image được daemon này build.
Bạn đã biết rằng công cụ CLI và daemon không nhất thiết phải ở trên cùng một máy tính. Nếu bạn dùng Docker trên hệ điều hành phi-Linux như **macOS** hoặc **Windows**, client nằm trên hệ điều hành chủ, còn daemon chạy bên trong một máy ảo Linux. Thậm chí nó có thể chạy trên một máy từ xa.

**Mẹo:**
Đừng thêm các tệp không cần thiết vào thư mục build, vì chúng sẽ làm chậm quá trình build — đặc biệt nếu **Docker daemon** nằm trên hệ thống từ xa.

Để build image, Docker trước tiên sẽ kéo (pull) image cơ sở (**node:16**) từ kho image công khai (**Docker Hub** trong trường hợp này), trừ khi image đã có sẵn trong máy cục bộ.
Sau đó nó tạo một container mới từ image và thực thi chỉ thị tiếp theo từ **Dockerfile**. Trạng thái cuối cùng của container sẽ tạo ra một image mới với ID riêng. Quá trình build tiếp tục với các chỉ thị còn lại trong **Dockerfile**. Mỗi chỉ thị tạo một image mới. Image cuối cùng sẽ được gắn thẻ với thẻ mà bạn chỉ định bằng cờ **-t** trong lệnh **docker build**.

---

### Hiểu các lớp của image

Bạn đã học rằng image gồm nhiều lớp (layer).
Người ta có thể nghĩ rằng mỗi image chỉ gồm các lớp của image cơ sở và một lớp mới duy nhất ở trên, nhưng thực tế không phải vậy. Khi xây dựng image, một lớp mới được tạo cho từng chỉ thị riêng biệt trong **Dockerfile**.

Trong quá trình build image **kiada**, sau khi kéo tất cả các lớp của image cơ sở, Docker tạo một lớp mới và thêm tệp **app.js** vào đó. Sau đó nó thêm một lớp khác với các tệp từ thư mục **html** và cuối cùng tạo lớp cuối cùng chỉ định lệnh chạy khi container được khởi động. Lớp cuối cùng này được gắn thẻ là **kiada\:latest**.

Bạn có thể xem các lớp của một image và kích thước của chúng bằng lệnh **docker history**. Lệnh và kết quả như sau (lưu ý rằng các lớp ở trên cùng được in trước):

```
$ docker history kiada:latest
IMAGE CREATED CREATED BY SIZE
b0ecc49d7a1d 7 min ago /bin/sh -c #(nop) ENTRYPOINT ["n... 0B #A
1d4de446f0f0 7 min ago /bin/sh -c #(nop) COPY dir:6ecee... 534kB #A
28d67701d6d9 7 min ago /bin/sh -c #(nop) COPY file:2ed5... 2.8kB #A
e498dabfee1c 2 days ago /bin/sh -c #(nop) CMD ["node"] 0B #B
<missing> 2 days ago /bin/sh -c #(nop) ENTRYPOINT ["d... 0B #B
<missing> 2 days ago /bin/sh -c #(nop) COPY file:2387... 116B #B
<missing> 2 days ago /bin/sh -c set -ex && for key in... 5.4MB #B
<missing> 2 days ago /bin/sh -c #(nop) ENV YARN_VERS... 0B #B
<missing> 2 days ago /bin/sh -c ARCH= && dpkgArch="$(... 67MB #B
<missing> 2 days ago /bin/sh -c #(nop) ENV NODE_VERS... 0B #B
<missing> 3 weeks ago /bin/sh -c groupadd --gid 1000 n... 333kB #B
<missing> 3 weeks ago /bin/sh -c set -ex; apt-get upd... 562MB #B
<missing> 3 weeks ago /bin/sh -c apt-get update && apt... 142MB #B
<missing> 3 weeks ago /bin/sh -c set -ex; if ! comman... 7.8MB #B
<missing> 3 weeks ago /bin/sh -c apt-get update && apt... 23.2MB #B
<missing> 3 weeks ago /bin/sh -c #(nop) CMD ["bash"] 0B #B
<missing> 3 weeks ago /bin/sh -c #(nop) ADD file:9788b... 101MB #B
```

Phần lớn các lớp mà bạn thấy đến từ image **node:16** (chúng cũng bao gồm các lớp của image cơ sở của chính nó).
Ba lớp trên cùng tương ứng với các chỉ thị **COPY** và **ENTRYPOINT** trong **Dockerfile**.

Như bạn thấy trong cột **CREATED BY**, mỗi lớp được tạo ra bằng cách thực thi một lệnh trong container. Ngoài việc thêm tệp với chỉ thị **COPY**, bạn cũng có thể dùng các chỉ thị khác trong **Dockerfile**.
Ví dụ, chỉ thị **RUN** thực thi một lệnh trong container trong quá trình build. Trong danh sách trên, bạn sẽ thấy một lớp nơi các lệnh **apt-get update** và một số lệnh **apt-get** bổ sung được thực thi. **apt-get** là một phần của trình quản lý gói Ubuntu, được dùng để cài đặt các gói phần mềm. Lệnh hiển thị trong danh sách cài đặt một số gói vào hệ thống tệp của image.

Để tìm hiểu về **RUN** và các chỉ thị khác mà bạn có thể dùng trong **Dockerfile**, hãy tham khảo tài liệu Dockerfile tại:
[https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)

**Mẹo:**
Mỗi chỉ thị tạo một lớp mới. Tôi đã đề cập rằng khi bạn xóa một tệp, tệp đó chỉ được đánh dấu là đã xóa trong lớp mới và không bị xóa khỏi các lớp bên dưới. Do đó, việc xóa tệp bằng một chỉ thị sau đó sẽ không làm giảm kích thước của image.
Nếu bạn dùng chỉ thị **RUN**, hãy đảm bảo rằng lệnh mà nó thực thi sẽ xóa tất cả các tệp tạm thời mà nó tạo ra trước khi kết thúc.

### 2.2.3 Chạy container

Với image đã được build và sẵn sàng, bây giờ bạn có thể chạy container với lệnh sau:

```bash
$ docker run --name kiada-container -p 1234:8080 -d kiada
9d62e8a9c37e056a82bb1efad57789e947df58669f94adc2006c087a03c54e02
```

Lệnh này yêu cầu Docker chạy một container mới có tên là **kiada-container** từ image **kiada**. Container được tách khỏi console (tùy chọn `-d`) và chạy ở chế độ nền. Cổng **1234** trên máy host được ánh xạ đến cổng **8080** trong container (được chỉ định bởi tùy chọn `-p 1234:8080`), vì vậy bạn có thể truy cập ứng dụng tại **[http://localhost:1234](http://localhost:1234)**.

Hình dưới đây sẽ giúp bạn hình dung cách mọi thứ kết nối với nhau.
Lưu ý rằng máy ảo Linux chỉ tồn tại nếu bạn dùng macOS hoặc Windows. Nếu bạn dùng Linux trực tiếp, sẽ không có máy ảo và hộp thể hiện cổng **1234** sẽ nằm ở rìa của máy tính cục bộ.

**Hình 2.15 Minh họa container đang chạy**

![](https://img001.prntscr.com/file/img001/o4Gq21IrQaO1S_uTABsORg.png)
---

### Truy cập ứng dụng của bạn

Bây giờ hãy truy cập ứng dụng tại **[http://localhost:1234](http://localhost:1234)** bằng **curl** hoặc trình duyệt web:

```bash
$ curl localhost:1234
Kiada version 0.1. Request processed by "44d76963e8e1". Client IP: ::ffff:1
```

**LƯU Ý**
Nếu Docker Daemon chạy trên một máy khác, bạn phải thay **localhost** bằng địa chỉ IP của máy đó. Bạn có thể tìm địa chỉ này trong biến môi trường **DOCKER\_HOST**.

Nếu mọi thứ diễn ra đúng, bạn sẽ thấy phản hồi do ứng dụng gửi về.
Trong trường hợp của tôi, nó trả về **44d76963e8e1** dưới dạng hostname. Trong trường hợp của bạn, bạn sẽ thấy một số thập lục phân khác. Đó là **ID của container**. Bạn cũng sẽ thấy nó khi liệt kê các container đang chạy.

---

### Liệt kê tất cả container đang chạy

Để liệt kê tất cả container đang chạy trên máy tính của bạn, chạy lệnh sau.
Kết quả đã được chỉnh sửa để dễ đọc hơn — hai dòng cuối cùng là phần tiếp theo của hai dòng đầu tiên.

```bash
$ docker ps
CONTAINER ID   IMAGE         COMMAND         CREATED          ...
44d76963e8e1   kiada:latest  "node app.js"   6 minutes ago     ...
...            STATUS        PORTS           NAMES
...            Up 6 minutes  0.0.0.0:1234->8080/tcp   kiada-container
```

Với mỗi container, Docker in ra ID và tên, image mà nó sử dụng, và lệnh mà nó thực thi.
Nó cũng hiển thị thời gian tạo, trạng thái, và các cổng host được ánh xạ đến container.

---

### Lấy thêm thông tin về container

Lệnh **docker ps** chỉ hiển thị thông tin cơ bản nhất về container.
Để xem thêm thông tin, bạn có thể dùng lệnh **docker inspect**:

```bash
$ docker inspect kiada-container
```

Docker sẽ in ra một tài liệu dài ở định dạng JSON chứa nhiều thông tin về container, chẳng hạn như trạng thái, cấu hình, và cài đặt mạng, bao gồm cả địa chỉ IP.

---

### Kiểm tra log của ứng dụng

Docker lưu trữ tất cả những gì ứng dụng ghi ra **standard output** và **error streams**. Đây thường là nơi ứng dụng ghi log. Bạn có thể dùng lệnh **docker logs** để xem log:

```bash
$ docker logs kiada-container
Kiada - Kubernetes in Action Demo Application
---------------------------------------------
Kiada 0.1 starting...
Local hostname is 44d76963e8e1
Listening on port 8080
Received request for / from ::ffff:172.17.0.1
```

Bây giờ bạn đã biết các lệnh cơ bản để chạy và kiểm tra ứng dụng trong container. Tiếp theo, bạn sẽ học cách phân phối nó.

---

### 2.2.4 Phân phối image của container

Image mà bạn build hiện chỉ có sẵn cục bộ. Để chạy trên các máy khác, bạn phải **push** nó lên một **image registry** bên ngoài.
Hãy push nó lên **Docker Hub** công khai, để bạn không cần thiết lập registry riêng. Bạn cũng có thể dùng các registry khác như **Quay.io** hoặc **Google Container Registry**.

Trước khi push image, bạn phải **đặt lại tag** theo quy tắc đặt tên của Docker Hub.
Tên image phải bao gồm **Docker Hub ID** của bạn, ID này được tạo khi bạn đăng ký tại [http://hub.docker.com](http://hub.docker.com).
Tôi sẽ dùng ID của mình (**luksa**) trong ví dụ sau, bạn nhớ thay bằng ID của bạn.

---

### Gán thêm tag cho image

Khi đã có ID, bạn sẵn sàng thêm một **tag** khác cho image.
Tên hiện tại là **kiada**, và bạn sẽ gán thêm tag **yourid/kiada:0.1** (thay **yourid** bằng Docker Hub ID thực của bạn):

```bash
$ docker tag kiada luksa/kiada:0.1
```

Chạy lại lệnh **docker images** để xác nhận image giờ có hai tên:

```bash
$ docker images
REPOSITORY      TAG      IMAGE ID        CREATED             VIRTUAL SIZE
luksa/kiada      0.1      b0ecc49d7a1d    About an hour ago    908 MB
kiada            latest   b0ecc49d7a1d    About an hour ago    908 MB
node             12       e498dabfee1c    3 days ago           908 MB
...
```

Như bạn thấy, cả **kiada** và **luksa/kiada:0.1** đều trỏ đến cùng một **image ID**, nghĩa là đây không phải hai image khác nhau, mà là **một image với hai tên**.

---

### Push image lên Docker Hub

Trước khi push image lên Docker Hub, bạn phải đăng nhập bằng lệnh:

```bash
$ docker login -u yourid docker.io
```

Lệnh sẽ yêu cầu bạn nhập mật khẩu Docker Hub.
Sau khi đăng nhập, push image **yourid/kiada:0.1** lên Docker Hub:

```bash
$ docker push yourid/kiada:0.1
```

---

### Chạy image trên các host khác

Khi quá trình push hoàn tất, image sẽ có sẵn cho mọi người.
Bạn có thể chạy image trên bất kỳ host nào hỗ trợ Docker bằng lệnh:

```bash
$ docker run --name kiada-container -p 1234:8080 -d luksa/kiada:0.1
```

Nếu container chạy đúng trên máy bạn, nó cũng sẽ chạy trên bất kỳ máy Linux nào khác, miễn là **Node.js binary** không yêu cầu tính năng Kernel đặc biệt (và thực tế là không yêu cầu).

---

### 2.2.5 Dừng và xóa container

Nếu bạn đã chạy container trên máy khác, giờ bạn có thể dừng nó, vì chúng ta chỉ cần container trên máy cục bộ để làm các bài tập tiếp theo.

---

### Dừng container

Ra lệnh cho Docker dừng container bằng:

```bash
$ docker stop kiada-container
```

Lệnh này gửi tín hiệu kết thúc đến **tiến trình chính** trong container để nó **tắt một cách an toàn**.
Nếu tiến trình không phản hồi hoặc không tắt kịp, Docker sẽ **kill** nó.
Khi tiến trình cấp cao nhất trong container kết thúc, container sẽ dừng.

---

### Xóa container

Container không còn chạy, nhưng vẫn tồn tại. Docker giữ nó lại phòng khi bạn muốn khởi động lại.
Bạn có thể xem các container đã dừng bằng:

```bash
$ docker ps -a
```

Tùy chọn `-a` sẽ in ra tất cả container — cả đang chạy và đã dừng.
Bạn có thể khởi động lại container với:

```bash
$ docker start kiada-container
```

Bạn có thể xóa container trên host khác vì không còn cần nữa:

```bash
$ docker rm kiada-container
```

Lệnh này sẽ **xóa container**. Tất cả nội dung của nó bị xóa và không thể khởi động lại.
Tuy nhiên, **image vẫn còn**. Nếu bạn tạo lại container, image không cần tải lại.
Nếu muốn xóa luôn image, dùng:

```bash
$ docker rmi kiada:latest
```

Hoặc bạn có thể xóa tất cả image không dùng đến bằng:

```bash
$ docker image prune
```

### 2.3 Hiểu về container

Bạn nên giữ container chạy trên máy tính cục bộ của mình để có thể sử dụng nó trong các bài tập tiếp theo, nơi bạn sẽ xem xét cách các container cho phép cô lập tiến trình mà không cần sử dụng máy ảo. Nhiều tính năng của nhân Linux giúp điều này trở nên khả thi và đã đến lúc làm quen với chúng.

---

### 2.3.1 Sử dụng Namespaces để tùy chỉnh môi trường của một tiến trình

Tính năng đầu tiên gọi là **Linux Namespaces** đảm bảo rằng mỗi tiến trình có cái nhìn riêng của nó về hệ thống. Điều này có nghĩa là một tiến trình chạy trong container sẽ chỉ thấy một số tệp, tiến trình và giao diện mạng trên hệ thống, cũng như một hostname hệ thống khác, giống như thể nó đang chạy trong một máy ảo riêng biệt.

Ban đầu, tất cả tài nguyên hệ thống có sẵn trong hệ điều hành Linux, chẳng hạn như filesystem, ID tiến trình, ID người dùng, giao diện mạng và những tài nguyên khác, đều nằm trong cùng một “bucket” mà tất cả các tiến trình đều nhìn thấy và sử dụng. Tuy nhiên, Kernel cho phép bạn tạo thêm các bucket bổ sung được gọi là **namespace** và di chuyển tài nguyên vào trong đó để chúng được tổ chức thành các tập nhỏ hơn. Điều này cho phép bạn làm cho mỗi tập chỉ hiển thị cho một tiến trình hoặc một nhóm tiến trình. Khi bạn tạo một tiến trình mới, bạn có thể chỉ định namespace mà nó nên sử dụng. Tiến trình chỉ nhìn thấy các tài nguyên trong namespace này và không thấy các tài nguyên trong namespace khác.

---

### Giới thiệu các loại namespace có sẵn

Cụ thể hơn, không chỉ có một loại namespace duy nhất. Trên thực tế, có nhiều loại – mỗi loại dành cho một loại tài nguyên. Vì vậy, một tiến trình sử dụng không chỉ một namespace mà là một namespace cho mỗi loại tài nguyên.

Các loại namespace sau đây tồn tại:

* **Mount namespace (mnt)**: cô lập điểm mount (hệ thống tệp).
* **Process ID namespace (pid)**: cô lập ID tiến trình.
* **Network namespace (net)**: cô lập thiết bị mạng, stack, cổng, v.v.
* **Inter-process communication namespace (ipc)**: cô lập giao tiếp giữa các tiến trình (bao gồm cô lập hàng đợi tin nhắn, bộ nhớ chia sẻ và những thứ khác).
* **UNIX Time-sharing System (UTS) namespace**: cô lập hostname hệ thống và tên miền NIS (Network Information Service).
* **User ID namespace (user)**: cô lập ID người dùng và nhóm.
* **Time namespace**: cho phép mỗi container có độ lệch riêng với đồng hồ hệ thống.
* **Cgroup namespace**: cô lập thư mục gốc của Control Groups. Bạn sẽ học về cgroups sau trong chương này.

---

### Sử dụng network namespaces để cung cấp cho tiến trình một tập hợp giao diện mạng riêng

**Network namespace** mà một tiến trình chạy trong đó xác định tiến trình đó có thể nhìn thấy những giao diện mạng nào. Mỗi giao diện mạng thuộc về đúng một namespace nhưng có thể được di chuyển từ namespace này sang namespace khác. Nếu mỗi container sử dụng network namespace riêng của nó, mỗi container sẽ nhìn thấy tập hợp giao diện mạng riêng của mình.

Xem hình minh họa sau để có cái nhìn tổng quan hơn về cách network namespaces được sử dụng để tạo một container. Hãy tưởng tượng bạn muốn chạy một tiến trình container hóa và cung cấp cho nó một tập hợp giao diện mạng riêng mà chỉ tiến trình đó có thể sử dụng.

**Hình 2.16** Network namespace giới hạn các giao diện mạng mà một tiến trình sử dụng
![](https://img001.prntscr.com/file/img001/xqToM9NKT3-a8T_KtwP9uQ.png)
Ban đầu, chỉ tồn tại **network namespace mặc định**. Sau đó, bạn tạo hai giao diện mạng mới cho container và một network namespace mới. Các giao diện này có thể được di chuyển từ namespace mặc định sang namespace mới. Khi ở đó, chúng có thể được đổi tên, vì tên chỉ cần duy nhất trong mỗi namespace. Cuối cùng, tiến trình có thể được khởi chạy trong network namespace này, điều này cho phép nó chỉ nhìn thấy hai giao diện được tạo riêng cho nó.

Bằng cách chỉ nhìn vào các giao diện mạng có sẵn, tiến trình không thể biết liệu nó đang ở trong container, VM hay OS chạy trực tiếp trên máy vật lý.

---

### Sử dụng UTS namespace để cung cấp cho tiến trình một hostname riêng

Một ví dụ khác về cách làm cho tiến trình trông như đang chạy trên host riêng của nó là sử dụng **UTS namespace**. Namespace này xác định hostname và domain name mà tiến trình chạy bên trong nó nhìn thấy. Bằng cách gán hai UTS namespace khác nhau cho hai tiến trình khác nhau, bạn có thể làm cho chúng nhìn thấy các hostname hệ thống khác nhau. Với hai tiến trình đó, trông như thể chúng chạy trên hai máy tính khác nhau.

---

### Hiểu cách namespaces cô lập các tiến trình với nhau

Bằng cách tạo một instance namespace riêng cho tất cả các loại namespace có sẵn và gán nó cho một tiến trình, bạn có thể làm cho tiến trình tin rằng nó đang chạy trong hệ điều hành riêng của mình. Lý do chính cho điều này là mỗi tiến trình có môi trường riêng của nó. Một tiến trình chỉ có thể nhìn thấy và sử dụng tài nguyên trong các namespace của riêng nó. Nó không thể sử dụng bất kỳ tài nguyên nào trong namespace khác. Tương tự, các tiến trình khác cũng không thể sử dụng tài nguyên của nó. Đây là cách container cô lập môi trường của các tiến trình chạy bên trong chúng.

---

### Chia sẻ namespace giữa nhiều tiến trình

Trong chương tiếp theo, bạn sẽ học rằng bạn không phải lúc nào cũng muốn cô lập các container hoàn toàn với nhau. Các container liên quan có thể muốn chia sẻ một số tài nguyên nhất định. Hình dưới đây minh họa ví dụ về hai tiến trình chia sẻ cùng các giao diện mạng và hostname, domain name của hệ thống, nhưng không chia sẻ hệ thống tệp.

**Hình 2.17** Mỗi tiến trình được liên kết với nhiều loại namespace, một số có thể được chia sẻ.
![](https://img001.prntscr.com/file/img001/uvf05gNAQHeI55UgdNTAiA.png)
Tập trung vào các thiết bị mạng được chia sẻ trước tiên. Hai tiến trình nhìn thấy và sử dụng cùng hai thiết bị (eth0 và lo) vì chúng sử dụng cùng một network namespace. Điều này cho phép chúng bind cùng một địa chỉ IP và giao tiếp qua thiết bị loopback, giống như thể chúng đang chạy trên một máy không sử dụng container. Hai tiến trình cũng sử dụng cùng một UTS namespace nên chúng nhìn thấy cùng hostname hệ thống. Ngược lại, mỗi tiến trình sử dụng namespace mount riêng, có nghĩa là chúng có hệ thống tệp riêng biệt.

Tóm lại, các tiến trình có thể muốn chia sẻ một số tài nguyên nhưng không phải tài nguyên khác. Điều này khả thi vì tồn tại các loại namespace riêng biệt. Một tiến trình có một namespace liên kết cho mỗi loại.

Với tất cả những điều này, người ta có thể hỏi: **container thực sự là gì?** Một tiến trình chạy “trong container” không chạy trong một thứ gì đó giống như một hộp thực tế như VM. Nó chỉ là một tiến trình được gán nhiều namespace (một cho mỗi loại). Một số được chia sẻ với tiến trình khác, trong khi một số thì không. Điều này có nghĩa là ranh giới giữa các tiến trình không hoàn toàn trùng khớp với nhau.

Trong một chương sau, bạn sẽ học cách debug một container bằng cách chạy một tiến trình mới trực tiếp trên host OS nhưng sử dụng network namespace của một container hiện có, trong khi sử dụng các namespace mặc định của host cho mọi thứ khác. Điều này sẽ cho phép bạn debug hệ thống mạng của container bằng các công cụ có sẵn trên host mà có thể không có trong container.


### 2.3.2 Khám phá môi trường của một container đang chạy

Điều gì sẽ xảy ra nếu bạn muốn xem môi trường bên trong container trông như thế nào?
Tên host của hệ thống là gì, địa chỉ IP cục bộ là gì, những tệp nhị phân và thư viện nào có sẵn trên hệ thống tệp, v.v...?

Để khám phá các đặc điểm này trong trường hợp của một máy ảo (VM), bạn thường kết nối từ xa qua **ssh** và sử dụng shell để thực thi các lệnh. Với container, bạn chạy một shell bên trong container.

**Lưu ý**
Tệp thực thi của shell phải có trong hệ thống tệp của container. Điều này không phải lúc nào cũng đúng với các container chạy trong môi trường production.

---

#### Chạy một shell bên trong container hiện có

Image Node.js mà image của bạn dựa trên có cung cấp shell bash, nghĩa là bạn có thể chạy nó trong container với lệnh sau:

```bash
$ docker exec -it kiada-container bash
root@44d76963e8e1:/# #A
```

Lệnh này chạy **bash** như một tiến trình bổ sung trong container `kiada-container` hiện có. Tiến trình này có cùng **Linux namespaces** như tiến trình chính của container (máy chủ Node.js đang chạy). Bằng cách này, bạn có thể khám phá container từ bên trong và xem cách Node.js và ứng dụng của bạn nhìn thấy hệ thống khi chạy trong container.

Tùy chọn **-it** là viết tắt của hai tùy chọn:

* **-i** bảo Docker chạy lệnh ở chế độ tương tác.
* **-t** bảo Docker cấp phát một pseudo terminal (TTY) để bạn có thể sử dụng shell đúng cách.

Bạn cần cả hai nếu muốn sử dụng shell như bình thường. Nếu bỏ **-i**, bạn không thể thực thi lệnh nào. Nếu bỏ **-t**, dấu nhắc lệnh sẽ không xuất hiện và một số lệnh có thể báo lỗi vì biến **TERM** chưa được thiết lập.

---

#### Liệt kê các tiến trình đang chạy trong container

Hãy liệt kê các tiến trình đang chạy trong container bằng cách thực thi lệnh **ps aux** bên trong shell mà bạn đã mở trong container:

```bash
root@44d76963e8e1:/# ps aux
USER  PID  %CPU  %MEM  VSZ   RSS   TTY  STAT  START  TIME  COMMAND
root    1   0.0   0.1   676380  16504  ?    Sl   12:31  0:00  node app.js
root   10   0.0   0.0    20216   1924  ?    Ss   12:31  0:00  bash
root   19   0.0   0.0    17492   1136  ?    R+   12:38  0:00  ps aux
```

Danh sách chỉ hiển thị ba tiến trình. Đây là những tiến trình duy nhất chạy trong container. Bạn không thể thấy các tiến trình khác chạy trong hệ điều hành host hoặc trong các container khác vì container chạy trong **Process ID namespace** riêng.

---

#### Xem các tiến trình container trong danh sách tiến trình của host

Nếu bây giờ bạn mở một terminal khác và liệt kê các tiến trình trong hệ điều hành host, bạn cũng sẽ thấy các tiến trình chạy trong container. Điều này xác nhận rằng các tiến trình trong container thực chất là các tiến trình thông thường chạy trong hệ điều hành host.
Ví dụ:

```bash
$ ps aux | grep app.js
USER  PID  %CPU  %MEM  VSZ   RSS   TTY  STAT  START  TIME  COMMAND
root  382   0.0   0.1   676380  16504  ?    Sl   12:31  0:00  node app.js
```

**Lưu ý**
Nếu bạn sử dụng macOS hoặc Windows, bạn phải liệt kê các tiến trình trong VM chạy Docker daemon, vì đó là nơi container của bạn chạy. Trong **Docker Desktop**, bạn có thể vào VM bằng lệnh:

```bash
wsl -d docker-desktop
```

hoặc:

```bash
docker run --net=host --ipc=host --uts=host --pid=host -it \
--security-opt=seccomp=unconfined --privileged --rm -v /:/host \
alpine chroot /host
```

Nếu bạn để ý kỹ, bạn có thể thấy rằng **PID** trong container khác với **PID** trên host. Vì container sử dụng **Process ID namespace** riêng nên nó có **cây tiến trình riêng với dãy số PID riêng**.

Như hình 2.18 minh họa, cây tiến trình này là **cây con** của toàn bộ cây tiến trình trên host. Mỗi tiến trình do đó có **hai PID**.

![](https://img001.prntscr.com/file/img001/wT7kyMktQDOoHZ6p0pfrIA.png)
---

#### Hiểu về việc cô lập hệ thống tệp giữa container với host và các container khác

Giống như cây tiến trình riêng biệt, mỗi container cũng có **hệ thống tệp riêng**. Nếu bạn liệt kê nội dung thư mục gốc của container, chỉ các tệp trong container mới được hiển thị. Điều này bao gồm các tệp từ image của container và các tệp được tạo trong quá trình hoạt động, chẳng hạn như log.

Ví dụ:

```bash
root@44d76963e8e1:/# ls /
app.js  boot  etc  lib  media  opt  root  sbin  sys  usr
bin     dev   home lib64 mnt    proc run   srv   tmp  var
```

Thư mục này chứa tệp **app.js** và các thư mục hệ thống khác thuộc image **node:16**. Bạn có thể thoải mái duyệt qua hệ thống tệp của container.

Bạn sẽ thấy không có cách nào xem tệp từ hệ thống tệp của host. Điều này rất tốt vì nó ngăn chặn kẻ tấn công tiềm ẩn truy cập vào các tệp này qua các lỗ hổng của máy chủ Node.js.

Để thoát khỏi container, thoát khỏi shell bằng lệnh **exit** hoặc nhấn **Control-D**, bạn sẽ quay lại máy host (tương tự như đăng xuất khỏi một phiên ssh).

**Mẹo**
Vào một container đang chạy như thế này rất hữu ích khi gỡ lỗi một ứng dụng đang chạy trong container. Khi có sự cố, điều đầu tiên bạn muốn kiểm tra là **trạng thái thực tế của hệ thống mà ứng dụng của bạn nhìn thấy**.

---

### 2.3.3 Giới hạn việc sử dụng tài nguyên của tiến trình với Linux Control Groups

**Linux Namespaces** cho phép tiến trình chỉ truy cập một số tài nguyên nhất định của host, nhưng **không giới hạn** việc một tiến trình có thể tiêu thụ bao nhiêu tài nguyên đó.

Ví dụ:

* Bạn có thể dùng namespace để cho phép một tiến trình chỉ truy cập một giao diện mạng cụ thể,
* nhưng không thể giới hạn **băng thông mạng** mà tiến trình đó tiêu thụ.

Tương tự, bạn không thể dùng namespace để giới hạn **thời gian CPU** hoặc **bộ nhớ** mà một tiến trình có thể sử dụng.
Bạn có thể muốn điều này để **ngăn một tiến trình chiếm toàn bộ CPU** và làm các tiến trình hệ thống quan trọng khác không chạy được.

Để làm được điều đó, chúng ta cần một tính năng khác của **Linux kernel**.

---

#### Giới thiệu về cgroups

Tính năng thứ hai của Linux kernel giúp container có thể hoạt động được gọi là **Linux Control Groups (cgroups)**.
Nó **giới hạn, tính toán và cô lập** các tài nguyên hệ thống như CPU, bộ nhớ, băng thông mạng hoặc đĩa.

Khi dùng **cgroups**, một tiến trình hoặc nhóm tiến trình chỉ có thể sử dụng lượng CPU, bộ nhớ, băng thông mạng được cấp phát.
Nhờ vậy, các tiến trình không thể chiếm tài nguyên dành riêng cho các tiến trình khác.

Bạn chưa cần hiểu chi tiết cách cgroups thực hiện việc này, nhưng hãy xem **Docker** cho phép chúng ta giới hạn CPU và bộ nhớ của container như thế nào.

---

#### Giới hạn việc sử dụng CPU của container

Nếu bạn không đặt giới hạn, container có quyền truy cập **không giới hạn** đến tất cả các lõi CPU trên host.

Bạn có thể chỉ định rõ ràng lõi CPU mà container có thể sử dụng với tùy chọn **--cpuset-cpus**.
Ví dụ, để cho phép container chỉ sử dụng lõi 1 và 2:

```bash
$ docker run --cpuset-cpus="1,2" ...
```

Bạn cũng có thể giới hạn **thời gian CPU** với các tùy chọn **--cpus**, **--cpu-period**, **--cpu-quota** và **--cpu-shares**.
Ví dụ, để cho phép container chỉ dùng **một nửa lõi CPU**:

```bash
$ docker run --cpus="0.5" ...
```

---

#### Giới hạn việc sử dụng bộ nhớ của container

Tương tự CPU, container có thể dùng toàn bộ bộ nhớ hệ thống như một tiến trình OS bình thường, nhưng bạn có thể muốn giới hạn nó.

Docker cung cấp các tùy chọn:

* **--memory**,
* **--memory-reservation**,
* **--kernel-memory**,
* **--memory-swap**,
* **--memory-swappiness**.

Ví dụ, để giới hạn bộ nhớ tối đa trong container là **100MB** (m là megabyte):

```bash
$ docker run --memory="100m" ...
```

Thực chất, các tùy chọn Docker này chỉ **cấu hình cgroups** của tiến trình.
**Kernel** sẽ xử lý việc giới hạn tài nguyên.

Xem tài liệu Docker để biết thêm chi tiết về các tùy chọn giới hạn CPU và bộ nhớ khác.

### 2.3.4 Tăng cường cô lập giữa các container

Linux Namespaces và Cgroups tách biệt môi trường của các container và ngăn một container chiếm dụng toàn bộ tài nguyên tính toán của các container khác. Nhưng các tiến trình trong những container này sử dụng cùng một kernel hệ thống, vì vậy chúng ta không thể nói rằng chúng thực sự được cô lập hoàn toàn. Một container độc hại có thể thực hiện các lời gọi hệ thống (system calls) gây ảnh hưởng đến các container khác.

Hãy tưởng tượng một node Kubernetes đang chạy nhiều container. Mỗi container có thiết bị mạng và tệp riêng của nó, và chỉ có thể sử dụng một lượng CPU và bộ nhớ giới hạn. Nhìn qua thì có vẻ một chương trình độc hại trong một container sẽ không thể gây hại cho các container khác. Nhưng chuyện gì xảy ra nếu chương trình độc hại đó thay đổi đồng hồ hệ thống, vốn được chia sẻ bởi tất cả các container?

Tùy thuộc vào ứng dụng, việc thay đổi thời gian có thể không gây ra quá nhiều vấn đề, nhưng nếu cho phép các chương trình thực hiện bất kỳ lời gọi hệ thống nào đến kernel, chúng có thể làm gần như mọi thứ. Sys-call cho phép chúng sửa đổi bộ nhớ kernel, thêm hoặc xóa các module kernel và nhiều việc khác mà các container thông thường không được phép làm.

Điều này dẫn chúng ta đến tập hợp công nghệ thứ ba giúp container có thể hoạt động. Việc giải thích chi tiết nằm ngoài phạm vi của cuốn sách này, vì vậy vui lòng tham khảo các tài liệu khác tập trung vào container hoặc các công nghệ dùng để bảo mật chúng. Phần này chỉ cung cấp giới thiệu ngắn gọn về các công nghệ đó.

---

### Cấp toàn quyền cho container trong hệ thống

Kernel của hệ điều hành cung cấp một tập hợp sys-call mà các chương trình sử dụng để tương tác với hệ điều hành và phần cứng bên dưới. Những lời gọi này bao gồm việc tạo tiến trình, thao tác tệp và thiết bị, thiết lập kênh giao tiếp giữa các ứng dụng, v.v.

Một số sys-call là an toàn và có sẵn cho mọi tiến trình, nhưng một số khác chỉ dành cho các tiến trình có quyền cao hơn. Nếu nhìn vào ví dụ trước đó, các ứng dụng chạy trên node Kubernetes nên được phép mở các tệp cục bộ của chúng, nhưng không được phép thay đổi đồng hồ hệ thống hoặc sửa đổi kernel theo cách có thể làm hỏng các container khác.

Hầu hết các container nên chạy mà không cần quyền nâng cao. Chỉ những chương trình mà bạn tin tưởng và thực sự cần thêm quyền hạn mới nên chạy trong container có đặc quyền (privileged container).

**Lưu ý**
Với Docker, bạn tạo container có đặc quyền bằng cách sử dụng cờ `--privileged`.

---

### Sử dụng Capabilities để cấp một phần quyền cho container

Nếu một ứng dụng chỉ cần gọi một số sys-call yêu cầu quyền nâng cao, thì việc tạo container có toàn quyền là không lý tưởng. May mắn thay, kernel Linux chia nhỏ quyền hạn thành các đơn vị gọi là **capabilities**.

Ví dụ về capabilities:

* **CAP\_NET\_ADMIN**: cho phép tiến trình thực hiện các thao tác liên quan đến mạng
* **CAP\_NET\_BIND\_SERVICE**: cho phép tiến trình bind đến các cổng nhỏ hơn 1024
* **CAP\_SYS\_TIME**: cho phép tiến trình thay đổi đồng hồ hệ thống

Các capabilities có thể được thêm hoặc xóa khi tạo container. Mỗi capability đại diện cho một tập hợp quyền mà các tiến trình trong container được phép sử dụng. Docker và Kubernetes loại bỏ tất cả capabilities ngoại trừ những quyền cần thiết cho các ứng dụng thông thường, nhưng người dùng có thể thêm hoặc xóa các quyền khác nếu được phép.

**Lưu ý**
Luôn tuân theo nguyên tắc **ít quyền nhất** khi chạy container. Đừng cấp cho chúng bất kỳ capability nào mà chúng không cần. Điều này ngăn kẻ tấn công lợi dụng container để xâm nhập hệ điều hành của bạn.

---

### Sử dụng seccomp profile để lọc các sys-call riêng lẻ

Nếu bạn cần kiểm soát chi tiết hơn các sys-call mà một chương trình có thể thực hiện, bạn có thể sử dụng **seccomp (Secure Computing Mode)**.
Bạn có thể tạo một **seccomp profile** tùy chỉnh bằng cách tạo một tệp JSON liệt kê các sys-call mà container sử dụng profile này được phép gọi. Sau đó, bạn cung cấp tệp này cho Docker khi tạo container.

---

### Tăng cường bảo mật container bằng AppArmor và SELinux

Và nếu những công nghệ được thảo luận trước đó vẫn chưa đủ, container còn có thể được bảo mật bằng hai cơ chế **kiểm soát truy cập bắt buộc (MAC)** bổ sung:

* **SELinux (Security-Enhanced Linux)**
* **AppArmor (Application Armor)**

Với SELinux, bạn gán nhãn cho tệp và tài nguyên hệ thống, cũng như cho người dùng và tiến trình. Một người dùng hoặc tiến trình chỉ có thể truy cập một tệp hoặc tài nguyên nếu nhãn của tất cả các đối tượng liên quan khớp với một tập hợp chính sách.

AppArmor tương tự, nhưng sử dụng đường dẫn tệp thay vì nhãn và tập trung vào tiến trình hơn là người dùng.

Cả SELinux và AppArmor đều cải thiện đáng kể bảo mật của hệ điều hành, nhưng đừng lo lắng nếu bạn cảm thấy quá tải với tất cả các cơ chế liên quan đến bảo mật này. Mục tiêu của phần này là làm sáng tỏ mọi thứ liên quan đến việc cô lập container đúng cách, nhưng chỉ cần hiểu cơ bản về **namespaces** là đủ cho thời điểm hiện tại.

---

## 2.4 Tóm tắt

Nếu trước khi đọc chương này bạn mới làm quen với container, bây giờ bạn đã hiểu chúng là gì, tại sao chúng ta sử dụng chúng, và những tính năng nào của kernel Linux giúp chúng hoạt động. Nếu trước đây bạn đã từng sử dụng container, tôi hy vọng chương này đã giúp bạn làm rõ những thắc mắc về cách container hoạt động, và bạn đã hiểu rằng chúng chẳng qua chỉ là các tiến trình hệ điều hành thông thường mà kernel Linux cô lập khỏi các tiến trình khác.

Sau khi đọc chương này, bạn cần nắm được rằng:

* Container là các tiến trình thông thường, nhưng được cô lập với nhau và với các tiến trình khác đang chạy trong hệ điều hành host.
* Container nhẹ hơn nhiều so với máy ảo, nhưng vì chúng sử dụng chung kernel Linux nên không được cô lập như VM.
* Docker là nền tảng container đầu tiên làm container trở nên phổ biến và là runtime container đầu tiên được Kubernetes hỗ trợ. Hiện nay, các runtime khác cũng được hỗ trợ thông qua **Container Runtime Interface (CRI)**.
* Một **container image** chứa ứng dụng người dùng và tất cả các phụ thuộc của nó. Nó được phân phối thông qua **container registry** và được dùng để tạo các container đang chạy.
* Container có thể được tải xuống và thực thi chỉ với một lệnh `docker run`.
* Docker xây dựng image từ **Dockerfile**, chứa các lệnh mà Docker cần thực hiện trong quá trình build. Image bao gồm nhiều lớp (layer) có thể được chia sẻ giữa các image. Mỗi lớp chỉ cần truyền và lưu trữ một lần.
* Container được cô lập bằng các tính năng của kernel Linux như **Namespaces**, **Control groups**, **Capabilities**, **seccomp**, **AppArmor** và/hoặc **SELinux**.
* **Namespaces** đảm bảo một container chỉ nhìn thấy một phần tài nguyên trên host, **Control groups** giới hạn lượng tài nguyên nó có thể sử dụng, trong khi các tính năng khác tăng cường mức độ cô lập giữa các container.

Sau khi kiểm tra kỹ các container trên con tàu này, bạn đã sẵn sàng nhổ neo và bước sang chương tiếp theo, nơi bạn sẽ học cách chạy container với Kubernetes.
