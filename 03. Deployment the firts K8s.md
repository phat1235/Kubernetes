# 3 Triển khai ứng dụng đầu tiên của bạn
Chương này bao gồm
- Chạy cụm Kubernetes cục bộ trên máy tính xách tay của bạn
- Thiết lập cụm trên Google Kubernetes Engine
- Thiết lập cụm trên Amazon Elastic Kubernetes Service
- Cài đặt và sử dụng công cụ dòng lệnh kubectl
- Triển khai một ứng dụng trong Kubernetes và làm cho nó khả dụng trên toàn cầu
- Mở rộng ứng dụng theo chiều ngang

Mục tiêu của chương này là chỉ cho bạn cách chạy cụm Kubernetes phát triển một nút đơn cục bộ hoặc thiết lập cụm nhiều nút được quản lý đầy đủ trên đám mây. Khi cụm của bạn đã chạy, bạn sẽ sử dụng nó để chạy container mà bạn đã tạo trong chương trước.

**Lưu ý**
Bạn có thể tìm thấy các tệp mã cho chương này tại
[https://github.com/luksa/kubernetes-in-action-2ndedition/tree/master/Chapter03](https://github.com/luksa/kubernetes-in-action-2ndedition/tree/master/Chapter03)

---

### 3.1 Triển khai cụm Kubernetes

Thiết lập một cụm Kubernetes đầy đủ, nhiều nút không phải là nhiệm vụ đơn giản, đặc biệt nếu bạn không quen thuộc với quản trị Linux và mạng. Cài đặt Kubernetes đúng cách sẽ bao gồm nhiều máy vật lý hoặc máy ảo và yêu cầu cấu hình mạng phù hợp để cho phép tất cả container trong cụm có thể giao tiếp với nhau.

Bạn có thể cài đặt Kubernetes trên máy tính xách tay, trên hạ tầng của tổ chức, hoặc trên các máy ảo được cung cấp bởi các nhà cung cấp đám mây (Google Compute Engine, Amazon EC2, Microsoft Azure, v.v.). Ngoài ra, hầu hết các nhà cung cấp đám mây hiện nay cung cấp dịch vụ Kubernetes được quản lý, giúp bạn không phải lo lắng về việc cài đặt và quản trị. Dưới đây là tổng quan ngắn gọn về những gì các nhà cung cấp lớn cung cấp:

* Google cung cấp GKE - Google Kubernetes Engine
* Amazon có EKS - Amazon Elastic Kubernetes Service
* Microsoft có AKS – Azure Kubernetes Service
* IBM có IBM Cloud Kubernetes Service
* Alibaba cung cấp Alibaba Cloud Container Service

Việc cài đặt và quản lý Kubernetes khó hơn nhiều so với việc chỉ sử dụng nó, đặc biệt là cho đến khi bạn quen thuộc với kiến trúc và cách vận hành của nó. Vì lý do này, chúng ta sẽ bắt đầu với những cách dễ nhất để có được một cụm Kubernetes hoạt động. Bạn sẽ học một số cách để chạy cụm Kubernetes một nút trên máy tính cục bộ và cách sử dụng cụm được lưu trữ chạy trên Google Kubernetes Engine (GKE).

Một tùy chọn thứ ba, liên quan đến việc cài đặt cụm bằng công cụ **kubeadm**, được giải thích trong **Phụ lục B**. Hướng dẫn ở đó sẽ chỉ cho bạn cách thiết lập cụm Kubernetes ba nút bằng máy ảo. Nhưng bạn chỉ nên thử điều đó sau khi đã quen với việc sử dụng Kubernetes. Nhiều tùy chọn khác cũng tồn tại, nhưng chúng nằm ngoài phạm vi của cuốn sách này. Hãy tham khảo trang web [kubernetes.io](https://kubernetes.io) để tìm hiểu thêm.

Nếu bạn đã được cấp quyền truy cập vào cụm hiện có do người khác triển khai, bạn có thể bỏ qua phần này và chuyển đến **mục 3.2** nơi bạn sẽ học cách tương tác với các cụm Kubernetes.

---

### 3.1.1 Sử dụng cụm Kubernetes tích hợp trong Docker Desktop

Nếu bạn sử dụng macOS hoặc Windows, rất có thể bạn đã cài đặt Docker Desktop để chạy các bài tập trong chương trước. Nó chứa một cụm Kubernetes một nút mà bạn có thể kích hoạt qua hộp thoại **Settings**. Đây có thể là cách dễ nhất để bạn bắt đầu với Kubernetes, nhưng lưu ý rằng phiên bản Kubernetes có thể không mới bằng khi sử dụng các tùy chọn thay thế được mô tả trong các phần tiếp theo.

**Lưu ý**
Mặc dù về mặt kỹ thuật nó không phải là một cụm, nhưng hệ thống Kubernetes một nút được Docker Desktop cung cấp vẫn đủ để bạn khám phá hầu hết các chủ đề được thảo luận trong cuốn sách này. Khi một bài tập yêu cầu cụm nhiều nút, tôi sẽ chỉ rõ điều đó.

---

#### Kích hoạt Kubernetes trong Docker Desktop

Giả sử Docker Desktop đã được cài đặt trên máy tính của bạn, bạn có thể khởi động cụm Kubernetes bằng cách nhấp vào biểu tượng **cá voi** trên khay hệ thống và mở hộp thoại **Settings**. Nhấp vào tab **Kubernetes** và đảm bảo rằng hộp kiểm **Enable Kubernetes** được chọn.

Các thành phần tạo nên **Control Plane** chạy dưới dạng container Docker, nhưng chúng không được hiển thị trong danh sách container đang chạy khi bạn gõ lệnh:

```
docker ps
```

Để hiển thị chúng, hãy chọn hộp kiểm **Show system containers**.

**Lưu ý**
Việc cài đặt ban đầu của cụm mất vài phút vì tất cả các image container cho các thành phần Kubernetes phải được tải xuống.

**Hình 3.1** Hộp thoại **Settings** trong Docker Desktop cho Windows
![](https://img001.prntscr.com/file/img001/87O9mW5YQp-FSilXmhVXDA.png)

Hãy nhớ đến nút **Reset Kubernetes Cluster** nếu bạn muốn đặt lại cụm để xóa tất cả các đối tượng mà bạn đã triển khai trong đó.

---

#### Hình dung hệ thống

Để hiểu các thành phần tạo nên cụm Kubernetes chạy ở đâu trong Docker Desktop, hãy xem hình dưới đây.

**Hình 3.2** Kubernetes chạy trong Docker Desktop
![](https://img001.prntscr.com/file/img001/vBtiGhjnQLuPoe1mv57t9w.png)

Docker Desktop thiết lập một máy ảo Linux lưu trữ **Docker Daemon** và tất cả các container. Máy ảo này cũng chạy **Kubelet** - tác nhân Kubernetes quản lý nút. Các thành phần của **Control Plane** chạy trong container, cũng như tất cả các ứng dụng mà bạn triển khai.

Để liệt kê các container đang chạy, bạn không cần đăng nhập vào máy ảo vì công cụ dòng lệnh **docker** trong hệ điều hành của bạn sẽ hiển thị chúng.

---

#### Khám phá máy ảo từ bên trong

Tại thời điểm viết cuốn sách này, Docker Desktop không cung cấp lệnh để đăng nhập vào máy ảo nếu bạn muốn khám phá nó từ bên trong. Tuy nhiên, bạn có thể chạy một container đặc biệt được cấu hình để sử dụng các **namespace** của máy ảo nhằm chạy **remote shell**, điều này gần giống như việc sử dụng **SSH** để truy cập máy chủ từ xa.

Để chạy container, hãy thực thi lệnh sau:

```
$ docker run --net=host --ipc=host --uts=host --pid=host --privileged \
--security-opt=seccomp=unconfined -it --rm -v /:/host alpine chroot /host
```

Lệnh dài này cần được giải thích:

* Container được tạo từ image **alpine**.
* Các cờ **--net**, **--ipc**, **--uts** và **--pid** làm cho container sử dụng **namespace** của máy chủ thay vì bị cô lập, và các cờ **--privileged** và **--security-opt** cung cấp cho container quyền truy cập không giới hạn vào tất cả các **sys-call**.
* Cờ **-it** chạy container ở chế độ tương tác và cờ **--rm** đảm bảo container sẽ bị xóa khi kết thúc.
* Cờ **-v** gắn thư mục gốc của máy chủ vào thư mục **/host** trong container. Lệnh **chroot /host** sau đó đặt thư mục này làm thư mục gốc trong container.

Sau khi bạn chạy lệnh, bạn sẽ có một shell gần như giống hệt như khi sử dụng **SSH** để vào máy ảo. Sử dụng shell này để khám phá máy ảo – thử liệt kê các tiến trình bằng lệnh:

```
ps aux
```

hoặc khám phá các giao diện mạng bằng lệnh:

```
ip addr
```
### 3.1.2 Chạy một cụm cục bộ bằng Minikube

Một cách khác để tạo một cụm Kubernetes là sử dụng Minikube, một công cụ được duy trì bởi cộng đồng Kubernetes. Phiên bản Kubernetes mà Minikube triển khai thường mới hơn phiên bản được triển khai bởi Docker Desktop. Cụm này bao gồm một nút duy nhất và phù hợp cho cả việc thử nghiệm Kubernetes và phát triển ứng dụng cục bộ. Nó thường chạy Kubernetes trong một máy ảo Linux, nhưng nếu máy tính của bạn chạy trên nền tảng Linux, nó cũng có thể triển khai Kubernetes trực tiếp trên hệ điều hành máy chủ thông qua Docker.

**Lưu ý**
Nếu bạn cấu hình Minikube để sử dụng máy ảo, bạn không cần Docker, nhưng bạn cần một hypervisor như VirtualBox. Trong trường hợp ngược lại, bạn cần Docker, nhưng không cần hypervisor.

#### Cài đặt Minikube

Minikube hỗ trợ macOS, Linux và Windows. Nó có một tệp thực thi nhị phân duy nhất, bạn có thể tìm thấy trong kho Minikube trên GitHub ([http://github.com/kubernetes/minikube](http://github.com/kubernetes/minikube)). Tốt nhất là làm theo hướng dẫn cài đặt hiện tại được công bố ở đó, nhưng nói chung, bạn cài đặt như sau:

Trên macOS, bạn có thể cài đặt nó bằng Brew Package Manager; trên Windows có trình cài đặt có thể tải xuống; và trên Linux, bạn có thể tải xuống gói `.deb` hoặc `.rpm`, hoặc đơn giản là tải tệp nhị phân và làm cho nó có thể thực thi với lệnh sau:

```bash
$ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube
$ sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

Để biết chi tiết về hệ điều hành cụ thể của bạn, vui lòng tham khảo hướng dẫn cài đặt trực tuyến.

#### Khởi động một cụm Kubernetes với Minikube

Sau khi Minikube được cài đặt, khởi động cụm Kubernetes như sau:

```bash
$ minikube start
minikube v1.11.0 on Fedora 31
Using the virtualbox driver based on user configuration
Downloading VM boot image ...
> minikube-v1.11.0.iso.sha256: 65 B / 65 B [-------------] 100.00% ? p/s 0s
> minikube-v1.11.0.iso: 174.99 MiB / 174.99 MiB [] 100.00% 50.16 MiB p/s 4s
Starting control plane node minikube in cluster minikube
Downloading Kubernetes v1.18.3 preload ...
> preloaded-images-k8s-v3-v1.18.3-docker-overlay2-amd64.tar.lz4: 526.01 MiB
Creating virtualbox VM (CPUs=2, Memory=6000MB, Disk=20000MB) ...
Preparing Kubernetes v1.18.3 on Docker 19.03.8 ...
Verifying Kubernetes components...
Enabled addons: default-storageclass, storage-provisioner
Done! kubectl is now configured to use "minikube"
```

Quá trình này có thể mất vài phút vì phải tải xuống ảnh VM và ảnh container của các thành phần Kubernetes.

**Mẹo**
Nếu bạn dùng Linux, bạn có thể giảm tài nguyên yêu cầu của Minikube bằng cách tạo cụm mà không cần máy ảo. Sử dụng lệnh này:

```bash
minikube start --vm-driver none
```

#### Kiểm tra trạng thái Minikube

Khi lệnh `minikube start` hoàn tất, bạn có thể kiểm tra trạng thái của cụm bằng cách chạy lệnh `minikube status`:

```bash
$ minikube status
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

Kết quả lệnh cho thấy máy chủ Kubernetes (VM chứa Kubernetes) đang chạy, Kubelet – tác nhân chịu trách nhiệm quản lý nút – và máy chủ API Kubernetes cũng đang chạy. Dòng cuối cùng cho thấy công cụ dòng lệnh `kubectl` đã được cấu hình để sử dụng cụm Kubernetes mà Minikube cung cấp. Minikube không cài đặt công cụ CLI này, nhưng nó tạo tệp cấu hình cho nó. Việc cài đặt công cụ CLI được giải thích trong phần 3.2.

#### Trực quan hóa hệ thống

Kiến trúc của hệ thống, được hiển thị trong hình dưới đây, gần như giống hệt với Docker Desktop.

**Hình 3.3 Chạy cụm Kubernetes một nút bằng Minikube**

Các thành phần Control Plane chạy trong container trong VM hoặc trực tiếp trong hệ điều hành máy chủ của bạn nếu bạn dùng tùy chọn `--vm-driver none` để tạo cụm. Kubelet chạy trực tiếp trong hệ điều hành của VM hoặc của máy chủ bạn. Nó chạy các ứng dụng mà bạn triển khai trong cụm thông qua Docker Daemon.

Bạn có thể chạy `minikube ssh` để đăng nhập vào VM của Minikube và khám phá nó từ bên trong. Ví dụ: bạn có thể xem những gì đang chạy trong VM bằng cách chạy `ps aux` để liệt kê các tiến trình đang chạy hoặc `docker ps` để liệt kê các container đang chạy.

**Mẹo**
Nếu bạn muốn liệt kê container bằng công cụ docker CLI cục bộ, như trong trường hợp của Docker Desktop, hãy chạy lệnh sau:

```bash
eval $(minikube docker-env)
```

---

### 3.1.3 Chạy cụm cục bộ bằng kind (Kubernetes in Docker)

Một lựa chọn thay thế cho Minikube, dù chưa hoàn thiện bằng, là kind (Kubernetes-in-Docker). Thay vì chạy Kubernetes trong một máy ảo hoặc trực tiếp trên máy chủ, kind chạy mỗi nút của cụm Kubernetes bên trong một container. Không giống Minikube, điều này cho phép nó tạo các cụm nhiều nút bằng cách khởi động nhiều container. Các container ứng dụng thực tế mà bạn triển khai vào Kubernetes sẽ chạy trong các container nút này. Hệ thống được hiển thị trong hình dưới đây.

**Hình 3.4 Chạy cụm Kubernetes nhiều nút bằng kind**
![](https://img001.prntscr.com/file/img001/KJG4XSiuTkqBS8o3cI2i9A.png)
Trong chương trước, tôi đã đề cập rằng một tiến trình chạy trong container thực ra chạy trong hệ điều hành máy chủ. Điều này có nghĩa là khi bạn chạy Kubernetes bằng kind, tất cả các thành phần Kubernetes chạy trong hệ điều hành máy chủ của bạn. Các ứng dụng bạn triển khai vào cụm Kubernetes cũng chạy trong hệ điều hành máy chủ của bạn.

Điều này làm cho kind trở thành công cụ hoàn hảo cho phát triển và thử nghiệm, vì mọi thứ chạy cục bộ và bạn có thể debug tiến trình đang chạy dễ dàng như khi chạy chúng ngoài container. Tôi thích dùng cách này khi phát triển ứng dụng trên Kubernetes, vì nó cho phép tôi làm những việc thú vị như chạy công cụ phân tích lưu lượng mạng như Wireshark hoặc thậm chí trình duyệt web của tôi trong các container chạy ứng dụng của tôi. Tôi dùng một công cụ gọi là `nsenter` cho phép tôi chạy các công cụ này trong không gian mạng hoặc các namespace khác của container.

Nếu bạn mới dùng Kubernetes, lựa chọn an toàn nhất là bắt đầu với Minikube, nhưng nếu bạn muốn thử thách, dưới đây là cách bắt đầu với kind.

#### Cài đặt kind

Cũng giống như Minikube, kind bao gồm một tệp thực thi nhị phân duy nhất. Để cài đặt nó, tham khảo hướng dẫn cài đặt tại:
[https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/).

Trên macOS và Linux, lệnh cài đặt như sau:

```bash
$ curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-$(uname)-amd64
$ chmod +x ./kind
$ mv ./kind /some-dir-in-your-PATH/kind
```

Kiểm tra tài liệu để xem phiên bản mới nhất và sử dụng thay cho `v0.7.0` trong ví dụ trên. Ngoài ra, thay thế `/some-dir-in-your-PATH/` bằng một thư mục thực tế trong PATH của bạn.

**Lưu ý**
Docker phải được cài đặt trên hệ thống của bạn để sử dụng kind.

#### Khởi động một cụm Kubernetes với kind

Khởi động một cụm mới đơn giản như với Minikube. Thực hiện lệnh sau:

```bash
$ kind create cluster
```

Giống như Minikube, kind cấu hình `kubectl` để sử dụng cụm mà nó tạo ra.

#### Khởi động cụm nhiều nút với kind

Kind chạy cụm một nút theo mặc định. Nếu bạn muốn chạy một cụm có nhiều nút worker, bạn phải tạo một tệp cấu hình trước.

Danh sách dưới đây cho thấy nội dung của tệp này (`Chapter03/kind-multi-node.yaml`):

```yaml
kind: Cluster
apiVersion: kind.sigs.k8s.io/v1alpha3
nodes:
- role: control-plane
- role: worker
- role: worker
```

Với tệp này, tạo cụm bằng lệnh:

```bash
$ kind create cluster --config kind-multi-node.yaml
```

#### Liệt kê các nút worker

Tại thời điểm viết tài liệu này, kind chưa cung cấp lệnh để kiểm tra trạng thái của cụm, nhưng bạn có thể liệt kê các nút bằng lệnh:

```bash
$ kind get nodes
kind-worker2
kind-worker
kind-control-plane
```

Vì mỗi nút chạy như một container, bạn cũng có thể xem các nút bằng cách liệt kê các container đang chạy với `docker ps`:

```bash
$ docker ps
CONTAINER ID IMAGE ... NAMES
45d0f712eac0 kindest/node:v1.18.2 ... kind-worker2
d1e88e98e3ae kindest/node:v1.18.2 ... kind-worker
4b7751144ca4 kindest/node:v1.18.2 ... kind-control-plane
```

#### Đăng nhập vào các nút cụm do kind cung cấp

Không giống như Minikube, nơi bạn dùng `minikube ssh` để đăng nhập vào nút nếu muốn kiểm tra các tiến trình đang chạy bên trong, với kind bạn dùng `docker exec`. Ví dụ, để vào nút có tên `kind-control-plane`, chạy:

```bash
$ docker exec -it kind-control-plane bash
```

Thay vì dùng Docker để chạy container, các nút do kind tạo ra sử dụng trình runtime CRI-O, mà tôi đã đề cập trong chương trước như một lựa chọn nhẹ hơn Docker. Công cụ CLI `crictl` được dùng để tương tác với CRI-O. Cách dùng nó tương tự như công cụ docker. Sau khi đăng nhập vào nút, liệt kê các container đang chạy trong đó bằng cách chạy `crictl ps` thay vì `docker ps`. Dưới đây là ví dụ về lệnh và kết quả:

```bash
root@kind-control-plane:/# crictl ps
CONTAINER ID IMAGE CREATED STATE NAME
c7f44d171fb72 eb516548c180f 15 min ago Running coredns ...
cce9c0261854c eb516548c180f 15 min ago Running coredns ...
e6522aae66fcc d428039608992 16 min ago Running kube-proxy ...
6b2dc4bbfee0c ef97cccdfdb50 16 min ago Running kindnet-cni ...
c3e66dfe44deb be321f2ded3f3 16 min ago Running kube-apiserver ...
```
## 3.1.4 Tạo một cụm được quản lý với Google Kubernetes Engine
Nếu bạn muốn sử dụng một cụm Kubernetes đa nút đầy đủ tính năng thay vì cụm cục bộ, bạn có thể sử dụng một cụm được quản lý, chẳng hạn như cụm do Google Kubernetes Engine (GKE) cung cấp. Bằng cách này, bạn không phải tự thiết lập tất cả các nút của cụm và mạng, vốn thường quá khó đối với những người mới bắt đầu với Kubernetes. Việc sử dụng giải pháp được quản lý như GKE đảm bảo rằng bạn không kết thúc với một cụm được cấu hình sai.

### Thiết lập Google Cloud và cài đặt gói nhị phân gcloud client

Trước khi có thể thiết lập một cụm Kubernetes mới, bạn phải thiết lập môi trường GKE của mình. Quy trình có thể thay đổi trong tương lai, vì vậy tôi chỉ cung cấp cho bạn một vài hướng dẫn chung ở đây. Để có hướng dẫn đầy đủ, hãy tham khảo
[https://cloud.google.com/container-engine/docs/before-you-begin](https://cloud.google.com/container-engine/docs/before-you-begin).

Tổng quan, toàn bộ quy trình bao gồm:

1. Đăng ký tài khoản Google nếu bạn chưa có.
2. Tạo một dự án trong Google Cloud Platform Console.
3. Kích hoạt thanh toán. Việc này yêu cầu thông tin thẻ tín dụng của bạn, nhưng Google cung cấp bản dùng thử miễn phí 12 tháng với khoản tín dụng miễn phí \$300. Và họ sẽ không tự động tính phí sau khi kết thúc bản dùng thử miễn phí.
4. Tải xuống và cài đặt Google Cloud SDK, trong đó bao gồm công cụ gcloud.
5. Tạo cụm bằng cách sử dụng công cụ dòng lệnh gcloud.

**Lưu ý**
Một số thao tác (ví dụ thao tác ở bước 2) có thể mất vài phút để hoàn thành, vì vậy hãy thư giãn và uống một tách cà phê trong lúc chờ đợi.

---

### Tạo một cụm Kubernetes GKE với ba nút

Trước khi tạo cụm, bạn phải quyết định cụm sẽ được tạo ở khu vực địa lý (region) và vùng (zone) nào. Tham khảo
[https://cloud.google.com/compute/docs/regions-zones](https://cloud.google.com/compute/docs/regions-zones) để xem danh sách các vị trí khả dụng.

Trong các ví dụ sau, tôi sử dụng khu vực **europe-west3** có trụ sở tại Frankfurt, Đức. Nó có ba vùng khác nhau — tôi sẽ sử dụng vùng **europe-west3-c**. Vùng mặc định cho tất cả các thao tác gcloud có thể được thiết lập với lệnh sau:

```bash
$ gcloud config set compute/zone europe-west3-c
```

Tạo cụm Kubernetes như sau:

```bash
$ gcloud container clusters create kiada --num-nodes 3
```

Kết quả:

```
Creating cluster kiada in europe-west3-c...
...
kubeconfig entry generated for kiada.
NAME   LOCAT.   MASTER_VER  MASTER_IP    MACH_TYPE       ... NODES  STATUS
kiada  eu-w3-c  1.13.11...  5.24.21.22   n1-standard-1    ... 3      RUNNING
```

**Lưu ý**
Tôi đang tạo cả ba nút worker trong cùng một vùng, nhưng bạn cũng có thể phân bổ chúng trên tất cả các vùng trong khu vực bằng cách đặt giá trị cấu hình compute/zone thành toàn bộ khu vực thay vì một vùng duy nhất. Nếu làm vậy, lưu ý rằng **--num-nodes** chỉ định số nút trên mỗi vùng. Nếu khu vực chứa ba vùng và bạn chỉ muốn có ba nút, bạn phải đặt **--num-nodes** thành 1.

Bây giờ bạn sẽ có một cụm Kubernetes đang chạy với ba nút worker.
Mỗi nút là một máy ảo được cung cấp bởi nền tảng hạ tầng dưới dạng dịch vụ **Google Compute Engine (GCE)**. Bạn có thể liệt kê các máy ảo GCE bằng lệnh sau:

```bash
$ gcloud compute instances list
```

Kết quả ví dụ:

```
NAME        ZONE          MACHINE_TYPE   INTERNAL_IP   EXTERNAL_IP      STATUS
...-ctlk    eu-west3-c    n1-standard-1  10.156.0.16   34.89.238.55     RUNNING
...-gj1f    eu-west3-c    n1-standard-1  10.156.0.14   35.242.223.97    RUNNING
...-r01z    eu-west3-c    n1-standard-1  10.156.0.15   35.198.191.189   RUNNING
```

**Mẹo**
Mỗi máy ảo đều phát sinh chi phí. Để giảm chi phí cho cụm, bạn có thể giảm số lượng nút xuống một, hoặc thậm chí về 0 khi không sử dụng. Xem phần tiếp theo để biết chi tiết.

Hệ thống được minh họa trong hình tiếp theo. Lưu ý rằng chỉ các nút worker của bạn chạy trong các máy ảo GCE. Control plane chạy ở nơi khác — bạn không thể truy cập vào các máy chủ lưu trữ nó.

*Hình 3.5 Cụm Kubernetes của bạn trong Google Kubernetes Engine*

![](https://img001.prntscr.com/file/img001/jPbf-RCxQNWs-54iuL8KLg.png)
---

### Mở rộng số lượng nút

Google cho phép bạn dễ dàng tăng hoặc giảm số lượng nút trong cụm của mình. Đối với hầu hết các bài tập trong cuốn sách này, bạn có thể giảm số nút xuống chỉ còn một nếu muốn tiết kiệm tiền. Bạn thậm chí có thể giảm xuống 0 để cụm không phát sinh chi phí nào.

Để giảm cụm xuống 0, sử dụng lệnh sau:

```bash
$ gcloud container clusters resize kiada --size 0
```

Điều hay ở việc giảm xuống 0 là không có đối tượng nào bạn tạo trong cụm Kubernetes, bao gồm cả các ứng dụng bạn triển khai, bị xóa đi. Tất nhiên, nếu giảm xuống 0, các ứng dụng sẽ không có nút nào để chạy, vì vậy chúng sẽ không chạy. Nhưng ngay khi bạn tăng cụm trở lại, chúng sẽ được triển khai lại. Ngay cả khi không có nút worker nào, bạn vẫn có thể tương tác với Kubernetes API (bạn có thể tạo, cập nhật và xóa đối tượng).

---

### Kiểm tra một nút worker GKE

Nếu bạn quan tâm đến những gì đang chạy trên các nút của mình, bạn có thể đăng nhập vào chúng bằng lệnh sau (sử dụng một trong các tên nút từ kết quả lệnh trước):

```bash
$ gcloud compute ssh gke-kiada-default-pool-9bba9b18-4glf
```

Khi đã đăng nhập vào nút, bạn có thể thử liệt kê tất cả các container đang chạy với lệnh:

```bash
docker ps
```

Bạn chưa chạy ứng dụng nào, vì vậy bạn sẽ chỉ thấy các container hệ thống Kubernetes. Hiện tại việc chúng là gì không quan trọng, nhưng bạn sẽ tìm hiểu về chúng trong các chương sau.

---

3.1.5 Tạo cụm bằng Amazon Elastic Kubernetes Service
Nếu bạn muốn sử dụng Amazon thay vì Google để triển khai cụm Kubernetes của mình trên đám mây, bạn có thể thử **Amazon Elastic Kubernetes Service (EKS)**. Hãy cùng điểm qua những điều cơ bản.

Trước hết, bạn phải cài đặt công cụ dòng lệnh **eksctl** bằng cách làm theo hướng dẫn tại:
[https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html).

---

### Tạo cụm Kubernetes EKS

Việc tạo cụm Kubernetes EKS bằng eksctl không khác nhiều so với cách bạn tạo cụm trong GKE. Tất cả những gì bạn phải làm là chạy lệnh sau:

```bash
$ eksctl create cluster --name kiada --region eu-central-1 --nodes 3 --ssh-access
```

Lệnh này tạo một cụm ba nút trong khu vực **eu-central-1**. Danh sách các khu vực có tại:
[https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/).

---

### Kiểm tra một nút worker EKS

Nếu bạn quan tâm đến những gì đang chạy trên các nút đó, bạn có thể sử dụng SSH để kết nối với chúng. Tham số **--ssh-access** được sử dụng trong lệnh tạo cụm đảm bảo rằng khóa SSH public của bạn được nhập vào nút.

Cũng giống như GKE và Minikube, khi đã đăng nhập vào nút, bạn có thể thử liệt kê tất cả các container đang chạy với:

```bash
docker ps
```

Bạn có thể mong đợi thấy các container tương tự như trong các cụm mà chúng ta đã đề cập trước đó.

---

3.1.6 Triển khai cụm đa nút từ đầu
Cho đến khi bạn hiểu sâu hơn về Kubernetes, tôi thực sự khuyên bạn không nên cố gắng cài đặt một cụm đa nút từ đầu. Nếu bạn là quản trị viên hệ thống giàu kinh nghiệm, bạn có thể làm điều đó mà không gặp quá nhiều khó khăn, nhưng hầu hết mọi người có lẽ nên thử một trong các phương pháp được mô tả trong các phần trước trước tiên. Việc quản lý đúng cách các cụm Kubernetes là cực kỳ khó. Chỉ riêng việc cài đặt thôi cũng đã là một nhiệm vụ không thể xem nhẹ.

Nếu bạn vẫn muốn thử thách, bạn có thể bắt đầu với hướng dẫn trong **Phụ lục B**, giải thích cách tạo máy ảo với VirtualBox và cài đặt Kubernetes bằng công cụ **kubeadm**. Bạn cũng có thể sử dụng các hướng dẫn đó để cài đặt Kubernetes trên các máy bare-metal hoặc trong các máy ảo chạy trên đám mây.

Khi bạn đã triển khai thành công một hoặc hai cụm bằng kubeadm, bạn có thể thử triển khai hoàn toàn thủ công, bằng cách làm theo hướng dẫn **Kubernetes the Hard Way** của Kelsey Hightower tại:
[https://github.com/kelseyhightower/Kubernetes-the-hard-way](https://github.com/kelseyhightower/Kubernetes-the-hard-way).

Mặc dù bạn có thể gặp phải một số vấn đề, nhưng việc tìm ra cách giải quyết chúng có thể là một trải nghiệm học tập tuyệt vời.

## 3.2 Tương tác với Kubernetes
Bạn đã tìm hiểu về một số phương pháp có thể để triển khai một cụm Kubernetes. Bây giờ là lúc học cách sử dụng cụm này. Để tương tác với Kubernetes, bạn sử dụng một công cụ dòng lệnh gọi là **kubectl**, được phát âm là kube-control, kube-C-T-L hoặc kube-cuddle.
Như hình dưới đây cho thấy, công cụ này giao tiếp với **Kubernetes API server**, là một phần của **Kubernetes Control Plane**. Control Plane sau đó sẽ kích hoạt các thành phần khác để thực hiện những gì cần thiết dựa trên các thay đổi bạn thực hiện qua API.

**Hình 3.6 Cách bạn tương tác với cụm Kubernetes**
![](https://img001.prntscr.com/file/img001/ibjTIEmCR22dc-7EFhwJrw.png)
### 3.2.1 Thiết lập kubectl - client dòng lệnh của Kubernetes

**Kubectl** là một tệp thực thi duy nhất mà bạn phải tải xuống máy tính và đặt vào **path** của mình. Nó tải cấu hình từ một tệp cấu hình gọi là **kubeconfig**. Để sử dụng kubectl, bạn phải vừa cài đặt nó vừa chuẩn bị tệp kubeconfig để kubectl biết cụm nào cần kết nối.

#### Tải xuống và cài đặt kubectl

Phiên bản ổn định mới nhất cho Linux có thể được tải xuống và cài đặt bằng các lệnh sau:

```bash
$ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/releas
$ chmod +x kubectl
$ sudo mv kubectl /usr/local/bin/
```

Để cài kubectl trên macOS, bạn có thể chạy cùng lệnh, nhưng thay **linux** trong URL bằng **darwin**, hoặc cài qua Homebrew bằng lệnh:

```bash
brew install kubectl
```

Trên Windows, tải **kubectl.exe** từ

```
https://storage.googleapis.com/kubernetesrelease/release/v1.18.2/bin/windows/amd64/kubectl.exe
```

Để tải phiên bản mới nhất, trước tiên hãy truy cập

```
https://storage.googleapis.com/kubernetesrelease/release/stable.txt
```

để xem phiên bản ổn định mới nhất là gì, sau đó thay số phiên bản trong URL đầu tiên bằng phiên bản này.

Để kiểm tra xem bạn đã cài đặt đúng chưa, chạy:

```bash
kubectl --help
```

Lưu ý rằng kubectl có thể chưa được cấu hình để kết nối với cụm Kubernetes của bạn, nghĩa là hầu hết các lệnh có thể chưa hoạt động.

**Mẹo**
Bạn luôn có thể thêm **--help** vào bất kỳ lệnh kubectl nào để nhận thêm thông tin.

---

#### Thiết lập bí danh ngắn cho kubectl

Bạn sẽ dùng kubectl thường xuyên. Việc phải gõ đầy đủ lệnh mỗi lần là tốn thời gian, nhưng bạn có thể rút ngắn bằng cách thiết lập **alias** và **tab completion** cho nó.

Hầu hết người dùng Kubernetes sử dụng **k** làm bí danh cho kubectl. Nếu bạn chưa từng dùng alias, đây là cách định nghĩa trên Linux và macOS. Thêm dòng sau vào tệp **\~/.bashrc** hoặc tệp tương đương:

```bash
alias k=kubectl
```

Trên Windows, nếu dùng Command Prompt, định nghĩa alias bằng cách chạy:

```cmd
doskey k=kubectl $*
```

Nếu dùng PowerShell, chạy:

```powershell
set-alias -name k -value kubectl
```

**Lưu ý**
Bạn có thể không cần alias nếu dùng **gcloud** để thiết lập cụm, vì nó cài đặt cả tệp thực thi **k** bên cạnh kubectl.

---

#### Cấu hình tab completion cho kubectl

Ngay cả với bí danh ngắn như **k**, bạn vẫn phải gõ nhiều. May mắn thay, kubectl có thể xuất mã hoàn thành lệnh cho cả shell bash và zsh. Nó cho phép tự động hoàn thành không chỉ tên lệnh mà cả tên đối tượng.

Ví dụ, sau này bạn sẽ học cách xem chi tiết một node cụ thể bằng lệnh:

```bash
$ kubectl describe node gke-kiada-default-pool-9bba9b18-4glf
```

Đó là một chuỗi gõ dài mà bạn sẽ lặp lại thường xuyên. Với tab completion, mọi thứ dễ dàng hơn nhiều. Bạn chỉ cần nhấn **TAB** sau khi gõ vài ký tự đầu tiên của mỗi phần:

```bash
$ kubectl desc<TAB> no<TAB> gke-ku<TAB>
```

Để bật tab completion trong bash, trước tiên bạn phải cài gói **bash-completion** và sau đó chạy lệnh:

```bash
$ source <(kubectl completion bash)
```

(bạn cũng có thể thêm vào **\~/.bashrc** hoặc tệp tương đương)

**Lưu ý**
Điều này bật hoàn thành lệnh trong bash. Bạn cũng có thể chạy với shell khác như bash, zsh, fish và powershell.

Tuy nhiên, điều này chỉ hoạt động khi bạn dùng đầy đủ **kubectl**. Nó sẽ không hoạt động với bí danh **k**. Để bật completion cho alias, chạy:

```bash
$ complete -o default -F __start_kubectl k
```

---

### 3.2.2 Cấu hình kubectl để dùng cụm Kubernetes cụ thể

Tệp cấu hình **kubeconfig** nằm ở **\~/.kube/config**. Nếu bạn triển khai cụm bằng Docker Desktop, Minikube hoặc GKE, tệp này đã được tạo sẵn. Nếu bạn được cấp quyền truy cập vào cụm hiện có, bạn sẽ nhận được tệp này.

Các công cụ khác như **kind** có thể ghi tệp này vào vị trí khác. Thay vì di chuyển tệp đến vị trí mặc định, bạn cũng có thể chỉ định vị trí cho kubectl bằng cách đặt biến môi trường **KUBECONFIG** như sau:

```bash
$ export KUBECONFIG=/path/to/custom/kubeconfig
```

Để tìm hiểu thêm về cách quản lý cấu hình kubectl và tạo tệp cấu hình từ đầu, hãy xem **phụ lục A**.

**Lưu ý**
Nếu bạn muốn sử dụng nhiều cụm Kubernetes (ví dụ: cả Minikube và GKE), hãy xem phụ lục A để biết cách chuyển đổi giữa các **kubectl context** khác nhau.

---

### 3.2.3 Sử dụng kubectl

Giả sử bạn đã cài đặt và cấu hình kubectl, giờ bạn có thể dùng nó để kết nối với cụm.

#### Kiểm tra cụm có hoạt động và kubectl có kết nối được hay không

Để kiểm tra cụm đang hoạt động, dùng lệnh:

```bash
$ kubectl cluster-info
```

Kết quả:

```
Kubernetes master is running at https://192.168.99.101:8443
KubeDNS is running at https://192.168.99.101:8443/api/v1/namespaces/...
```

Điều này cho biết API server đang hoạt động và phản hồi các yêu cầu.

---

#### Liệt kê các node trong cụm

Dùng lệnh sau để liệt kê tất cả node trong cụm:

```bash
$ kubectl get nodes
```

Kết quả khi chạy trong cụm do kind cung cấp:

```
NAME           STATUS   ROLES    AGE   VERSION
control-plane   Ready    <none>   12m   v1.18.2
kind-worker     Ready    <none>   12m   v1.18.2
kind-worker2    Ready    <none>   12m   v1.18.2
```

Mọi thứ trong Kubernetes đều được biểu diễn bằng **object** và có thể được truy xuất hoặc thao tác qua **RESTful API**.

Lệnh **kubectl get** lấy danh sách các object của loại chỉ định từ API. Lệnh này chỉ hiển thị thông tin tóm tắt về các object.

---

#### Lấy thêm chi tiết về một object

Để xem thông tin chi tiết hơn về một object, dùng lệnh:

```bash
$ kubectl describe node gke-kiada-85f6-node-0rrx
```

Lệnh này hiển thị trạng thái node, thông tin về CPU, RAM, thông tin hệ thống, container đang chạy trên node và nhiều thông tin khác.

Nếu chạy **kubectl describe** mà không chỉ định tên resource, thông tin của tất cả node sẽ được hiển thị.

**Mẹo**
Chạy lệnh **describe** mà không chỉ định tên object hữu ích khi chỉ có một object duy nhất tồn tại. Bạn không phải gõ hoặc copy tên object.

Bạn sẽ học thêm về nhiều lệnh kubectl khác trong suốt cuốn sách.

3.2.4 Tương tác với Kubernetes thông qua bảng điều khiển web
Nếu bạn thích sử dụng giao diện người dùng đồ họa trên web, bạn sẽ vui khi biết rằng Kubernetes cũng đi kèm với một bảng điều khiển web rất tiện lợi. Tuy nhiên, hãy lưu ý rằng chức năng của bảng điều khiển này có thể bị tụt hậu khá nhiều so với **kubectl**, vốn là công cụ chính để tương tác với Kubernetes.

Tuy nhiên, bảng điều khiển này hiển thị các tài nguyên khác nhau trong ngữ cảnh và có thể là một khởi đầu tốt để bạn nắm bắt được các loại tài nguyên chính trong Kubernetes và cách chúng liên kết với nhau. Bảng điều khiển cũng cung cấp khả năng chỉnh sửa các đối tượng đã triển khai và hiển thị lệnh **kubectl** tương đương cho mỗi thao tác – một tính năng mà hầu hết người mới bắt đầu sẽ đánh giá cao.

Hình 3.7 cho thấy bảng điều khiển với hai khối lượng công việc (workloads) được triển khai trong cụm.

**Hình 3.7 Ảnh chụp màn hình bảng điều khiển web Kubernetes**
![](https://img001.prntscr.com/file/img001/AE8xts5NRvOtoowEiPvKmg.png)
Mặc dù bạn sẽ không sử dụng bảng điều khiển trong cuốn sách này, nhưng bạn luôn có thể mở nó để nhanh chóng xem giao diện đồ họa của các đối tượng được triển khai trong cụm của mình sau khi bạn tạo chúng thông qua **kubectl**.

### Truy cập bảng điều khiển trong Docker Desktop

Đáng tiếc là Docker Desktop không cài đặt bảng điều khiển Kubernetes theo mặc định. Việc truy cập nó cũng không hề đơn giản, nhưng cách thực hiện như sau. Trước tiên, bạn cần cài đặt nó bằng lệnh sau:

```
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v
```

Tham khảo **github.com/kubernetes/dashboard** để tìm số phiên bản mới nhất.

Sau khi cài đặt bảng điều khiển, lệnh tiếp theo bạn phải chạy là:

```
$ kubectl proxy
```

Lệnh này chạy một proxy cục bộ đến máy chủ API, cho phép bạn truy cập các dịch vụ thông qua nó. Hãy để tiến trình proxy chạy và sử dụng trình duyệt để mở bảng điều khiển tại URL sau:

```
http://localhost:8001/api/v1/namespaces/kubernetesdashboard/services/https:kubernetes-dashboard:/proxy/
```

Bạn sẽ thấy một trang xác thực. Sau đó, bạn phải chạy lệnh sau để lấy mã token xác thực:

```
PS C:\> kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubern
```

**Lưu ý**
Lệnh này phải được chạy trong **Windows PowerShell**.

Tìm mã token được liệt kê dưới **kubernetes-dashboard-token-xyz** và dán nó vào trường token trên trang xác thực hiển thị trong trình duyệt của bạn. Sau khi làm điều này, bạn sẽ có thể sử dụng bảng điều khiển. Khi sử dụng xong, hãy kết thúc tiến trình **kubectl proxy** bằng **Control-C**.

### Truy cập bảng điều khiển khi sử dụng Minikube

Nếu bạn đang sử dụng **Minikube**, việc truy cập bảng điều khiển dễ dàng hơn nhiều. Chạy lệnh sau và bảng điều khiển sẽ mở trong trình duyệt mặc định của bạn:

```
$ minikube dashboard
```

### Truy cập bảng điều khiển khi chạy Kubernetes ở nơi khác

**Google Kubernetes Engine** không còn cung cấp quyền truy cập vào **Kubernetes Dashboard** mã nguồn mở nữa, nhưng nó cung cấp một bảng điều khiển web thay thế. Điều này cũng áp dụng cho các nhà cung cấp dịch vụ đám mây khác. Để biết cách truy cập bảng điều khiển, vui lòng tham khảo tài liệu của từng nhà cung cấp.

Nếu cụm của bạn chạy trên cơ sở hạ tầng riêng, bạn có thể triển khai bảng điều khiển bằng cách làm theo hướng dẫn tại:
**kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard**

---

## 3.3 Chạy ứng dụng đầu tiên của bạn trên Kubernetes

Bây giờ là lúc cuối cùng để triển khai một cái gì đó lên cụm của bạn. Thông thường, để triển khai một ứng dụng, bạn sẽ chuẩn bị một tệp JSON hoặc YAML mô tả tất cả các thành phần mà ứng dụng của bạn bao gồm và áp dụng tệp đó lên cụm của bạn. Đây sẽ là cách tiếp cận khai báo (declarative approach).

Vì đây có thể là lần đầu tiên bạn triển khai một ứng dụng lên Kubernetes, hãy chọn một cách đơn giản hơn để thực hiện việc này. Chúng ta sẽ sử dụng các lệnh bắt buộc (imperative) đơn giản, chỉ một dòng để triển khai ứng dụng của bạn.


### 3.3.1 Triển khai ứng dụng của bạn

Cách triển khai ứng dụng theo kiểu **imperative** là sử dụng lệnh `kubectl create deployment`. Như chính tên gọi của lệnh, nó tạo ra một **Deployment object**, đại diện cho một ứng dụng được triển khai trong cluster.
Bằng cách sử dụng lệnh imperative, bạn tránh được việc phải biết cấu trúc của Deployment object như khi bạn viết YAML hoặc JSON manifests.

---

### Tạo một Deployment

Trong chương trước, bạn đã tạo một ứng dụng Node.js tên là **Kiada**, đóng gói nó thành một **container image** và đẩy lên **Docker Hub** để dễ dàng phân phối đến bất kỳ máy tính nào.

**Lưu ý**
Nếu bạn bỏ qua chương hai vì đã quen với Docker và container, bạn có thể quay lại đọc mục **2.2.1**, mô tả ứng dụng mà bạn sẽ triển khai ở đây và trong phần còn lại của cuốn sách.

Hãy triển khai ứng dụng Kiada vào Kubernetes cluster của bạn. Đây là lệnh thực hiện:

```
$ kubectl create deployment kiada --image=luksa/kiada:0.1
deployment.apps/kiada created
```

Trong lệnh trên, bạn chỉ định ba thứ:

* Bạn muốn tạo một **deployment object**.
* Bạn muốn đối tượng này có tên là **kiada**.
* Bạn muốn deployment sử dụng container image **luksa/kiada:0.1**.

Mặc định, image được tải từ **Docker Hub**, nhưng bạn cũng có thể chỉ định registry trong tên image (ví dụ: `quay.io/luksa/kiada:0.1`).

**Lưu ý**
Hãy chắc chắn rằng image được lưu trong **public registry** và có thể được tải mà không cần quyền truy cập. Bạn sẽ học cách cung cấp thông tin xác thực để tải **private images** trong chương 8.

**Deployment object** bây giờ được lưu trong **Kubernetes API**. Sự tồn tại của đối tượng này cho Kubernetes biết rằng container **luksa/kiada:0.1** phải chạy trong cluster của bạn. Bạn đã khai báo **trạng thái mong muốn**. Kubernetes bây giờ phải đảm bảo rằng **trạng thái thực tế** phản ánh đúng mong muốn đó.

---

### Liệt kê các deployments

Tương tác với Kubernetes chủ yếu bao gồm việc tạo và thao tác các đối tượng thông qua API của nó. Kubernetes lưu các đối tượng này, sau đó thực hiện các thao tác để đưa chúng vào hoạt động.
Ví dụ, khi bạn tạo một **Deployment object**, Kubernetes sẽ chạy một ứng dụng. Kubernetes sau đó sẽ thông báo cho bạn về trạng thái hiện tại của ứng dụng bằng cách ghi **status** vào chính Deployment object đó. Bạn có thể xem trạng thái bằng cách đọc lại đối tượng. Một cách để làm điều này là liệt kê tất cả các Deployment object như sau:

```
$ kubectl get deployments
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
kiada   0/1     1            0           6s
```

Lệnh `kubectl get deployments` liệt kê tất cả Deployment object hiện có trong cluster. Bạn chỉ có một Deployment trong cluster của mình. Nó chạy một instance của ứng dụng như được hiển thị trong cột **UP-TO-DATE**, nhưng cột **AVAILABLE** cho biết ứng dụng chưa sẵn sàng.
Điều này là vì container chưa sẵn sàng, như trong cột **READY** – bạn có thể thấy 0 trên tổng số 1 container đã sẵn sàng.

Bạn có thể tự hỏi liệu có thể yêu cầu Kubernetes liệt kê tất cả các container đang chạy bằng cách thực hiện `kubectl get containers` không. Hãy thử xem:

```
$ kubectl get containers
error: the server doesn't have a resource type "containers"
```

Lệnh này thất bại vì Kubernetes không có loại đối tượng “Container”. Điều này có thể hơi lạ, vì Kubernetes tập trung vào việc chạy container, nhưng có một sự thật khác. **Container không phải là đơn vị triển khai nhỏ nhất trong Kubernetes**. Vậy đơn vị đó là gì?

---

### Giới thiệu về Pods

Trong Kubernetes, thay vì triển khai các container riêng lẻ, bạn triển khai **nhóm các container** nằm cùng nhau – gọi là **pods**.

Một pod là một nhóm một hoặc nhiều container có liên quan chặt chẽ với nhau (giống như các hạt đậu trong một vỏ) chạy cùng nhau trên cùng một **worker node** và cần chia sẻ một số **Linux namespaces** nhất định, để chúng có thể tương tác gần gũi hơn so với các pod khác.

Trong chương trước, tôi đã chỉ ra ví dụ nơi hai process dùng chung namespace.

* Bằng cách chia sẻ **network namespace**, cả hai process dùng chung các **network interfaces**, **IP address** và **port space**.
* Bằng cách chia sẻ **UTS namespace**, cả hai cùng thấy một **system hostname** giống nhau.

Đây chính xác là những gì xảy ra khi bạn chạy các container trong cùng một pod. Chúng dùng chung **network** và **UTS namespaces**, cùng với những namespace khác, tùy thuộc vào **spec** của pod.

**Hình 3.8** Mối quan hệ giữa container, pod và worker node
![](https://img001.prntscr.com/file/img001/qlSvgKNxSyapul63CGZ6Rw.png)
Như minh họa trong **hình 3.8**, bạn có thể coi mỗi pod là một **máy tính logic** riêng biệt chứa một ứng dụng. Ứng dụng có thể gồm một process chạy trong container, hoặc một **main application process** cùng các **supporting process** bổ sung, mỗi process chạy trong một container riêng biệt. Pods được phân phối trên tất cả các worker node của cluster.

Mỗi pod có **IP**, **hostname**, **processes**, **network interfaces** và các tài nguyên khác của riêng nó. Các container trong cùng một pod nghĩ rằng chúng là những process duy nhất chạy trên máy tính đó. Chúng không thấy process của bất kỳ pod nào khác, ngay cả khi ở cùng một node.

---

### Liệt kê các pods

Vì **container** không phải là đối tượng top-level của Kubernetes, bạn không thể liệt kê chúng. Nhưng bạn có thể liệt kê **pods**.

Như kết quả của lệnh `kubectl get pods` dưới đây cho thấy, bằng cách tạo Deployment object, bạn đã triển khai một pod:

```
$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
kiada-9d785b578-p449x       0/1     Pending   0          1m   #A
```

Đây là pod chứa container chạy ứng dụng của bạn. Chính xác hơn, vì **STATUS** vẫn là **Pending**, ứng dụng hoặc container chưa chạy. Điều này cũng được thể hiện trong cột **READY**, cho biết pod có một container nhưng chưa sẵn sàng.

Nguyên nhân pod ở trạng thái Pending là do **worker node** mà pod được gán phải tải container image trước khi có thể chạy nó. Khi tải xong, container của pod được tạo và pod chuyển sang trạng thái **Running**.

Nếu Kubernetes không thể tải image từ registry, lệnh `kubectl get pods` sẽ hiển thị điều này trong cột **STATUS**. Nếu bạn sử dụng image của riêng mình, hãy đảm bảo nó được đánh dấu **public** trên Docker Hub. Hãy thử tải image thủ công bằng `docker pull` trên một máy tính khác.

Nếu có vấn đề khác khiến pod không chạy, hoặc bạn muốn xem thêm thông tin chi tiết, bạn có thể sử dụng lệnh `kubectl describe pod`, giống như bạn đã làm để xem chi tiết của worker node. Nếu có sự cố với pod, chúng sẽ được hiển thị. Xem các **event** ở cuối kết quả. Với một pod đang chạy, chúng sẽ gần giống như sau:

```
Type     Reason     Age   From               Message
----     ------     ---   ----               -------
Normal   Scheduled  25s   default-scheduler  Successfully assigned default/kiada-9d785b578-p4to kind-worker2
Normal   Pulling    23s   kubelet, kind-worker2  Pulling image "luksa/kiada"
Normal   Pulled     21s   kubelet, kind-worker2  Successfully pulled image
Normal   Created    21s   kubelet, kind-worker2  Created container kiada
Normal   Started    21s   kubelet, kind-worker2  Started container kiada
```

---

### Hiểu những gì xảy ra phía sau

Để giúp bạn hình dung những gì xảy ra khi bạn tạo một **Deployment**, xem **hình 3.9**.

**Hình 3.9** Cách việc tạo Deployment object dẫn đến container ứng dụng đang chạy
![](https://img001.prntscr.com/file/img001/JeuDHxXhTZWv1pFQON4J5Q.png)
Khi bạn chạy lệnh `kubectl create`, nó tạo một **Deployment object** mới trong cluster bằng cách gửi một **HTTP request** đến **Kubernetes API server**. Kubernetes sau đó tạo một **Pod object**, pod này được gán (scheduled) đến một worker node.

**Kubernetes agent** trên worker node (Kubelet) phát hiện pod mới, thấy rằng nó được gán cho node của nó, và yêu cầu Docker tải image từ registry, tạo container từ image, và chạy nó.

---

**Định nghĩa**
Thuật ngữ **scheduling** đề cập đến việc gán pod cho một node. Pod sẽ chạy ngay lập tức, không phải vào một thời điểm nào đó trong tương lai. Giống như **CPU scheduler** trong hệ điều hành chọn CPU để chạy process, **scheduler** trong Kubernetes quyết định **worker node** nào sẽ chạy container.

Không giống như process trong hệ điều hành, khi một pod đã được gán cho một node, nó chỉ chạy trên node đó. Ngay cả khi thất bại, instance của pod này sẽ không bao giờ được di chuyển sang node khác, nhưng một instance pod mới có thể được tạo để thay thế nó.

Tùy thuộc vào cách bạn chạy Kubernetes cluster, số lượng worker node trong cluster có thể khác nhau. Hình minh họa chỉ hiển thị worker node mà pod được gán. Trong cluster nhiều node, các worker node khác không tham gia vào quá trình này.

### 3.3.2 Mở ứng dụng của bạn cho thế giới

Ứng dụng của bạn hiện đang chạy, vì vậy câu hỏi tiếp theo là làm thế nào để truy cập nó. Tôi đã đề cập rằng mỗi pod sẽ nhận được một địa chỉ IP riêng, nhưng địa chỉ này chỉ nội bộ trong cluster và không thể truy cập từ bên ngoài. Để làm cho pod có thể truy cập từ bên ngoài, bạn sẽ mở nó ra bằng cách tạo một đối tượng **Service**.

Có một số loại đối tượng **Service** khác nhau. Bạn sẽ quyết định loại nào phù hợp với nhu cầu. Một số loại chỉ mở pod trong nội bộ cluster, trong khi một số loại khác cho phép truy cập từ bên ngoài. Một **Service** với kiểu **LoadBalancer** sẽ cung cấp một bộ cân bằng tải bên ngoài (external load balancer), cho phép dịch vụ truy cập qua một địa chỉ IP công cộng. Đây chính là loại dịch vụ bạn sẽ tạo bây giờ.

---

### Tạo một Service

Cách dễ nhất để tạo một service là sử dụng lệnh sau:

```bash
$ kubectl expose deployment kiada --type=LoadBalancer --port 8080
service/kiada exposed
```

Lệnh **create deployment** mà bạn chạy trước đó đã tạo một đối tượng **Deployment**, trong khi lệnh **expose deployment** sẽ tạo một đối tượng **Service**. Khi chạy lệnh trên, Kubernetes sẽ hiểu rằng:

* Bạn muốn mở tất cả các pod thuộc về Deployment **kiada** như một service mới.
* Bạn muốn các pod có thể truy cập từ bên ngoài cluster qua bộ cân bằng tải.
* Ứng dụng lắng nghe trên cổng 8080, vì vậy bạn muốn truy cập nó qua cổng này.
* Bạn không chỉ định tên cho đối tượng **Service**, nên nó sẽ kế thừa tên từ Deployment.

---

### Liệt kê các service

Service là các đối tượng API, giống như Pods, Deployments, Nodes và hầu hết mọi thứ khác trong Kubernetes, vì vậy bạn có thể liệt kê chúng bằng cách chạy:

```bash
$ kubectl get svc
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)           AGE
kubernetes   ClusterIP      10.19.240.1     <none>          443/TCP           34m
kiada        LoadBalancer   10.19.243.17    <pending>       8080:30838/TCP    4s
```

**Lưu ý**
Hãy chú ý rằng chúng ta dùng **svc** thay cho **services**. Hầu hết các loại tài nguyên đều có một tên viết tắt mà bạn có thể sử dụng thay cho tên đầy đủ (ví dụ: **po** cho **pods**, **no** cho **nodes** và **deploy** cho **deployments**).

Danh sách trên hiển thị hai service với loại, IP và các cổng mà chúng mở. Hãy bỏ qua service **kubernetes** và tập trung vào service **kiada**. Nó hiện chưa có địa chỉ IP bên ngoài. Việc nó có nhận được IP hay không phụ thuộc vào cách bạn triển khai cluster.

---

### Liệt kê các loại đối tượng có sẵn với kubectl api-resources

Bạn đã sử dụng lệnh **kubectl get** để liệt kê nhiều thứ trong cluster: Nodes, Deployments, Pods và bây giờ là Services. Đây đều là các loại đối tượng Kubernetes. Bạn có thể hiển thị danh sách tất cả các loại đối tượng được hỗ trợ bằng cách chạy:

```bash
kubectl api-resources
```

Danh sách này cũng hiển thị tên viết tắt cho mỗi loại và một số thông tin khác mà bạn sẽ cần khi định nghĩa các đối tượng trong tệp JSON/YAML, điều này bạn sẽ học trong các chương sau.

---

### Hiểu về dịch vụ load balancer

Trong khi Kubernetes cho phép bạn tạo các dịch vụ gọi là **LoadBalancer**, bản thân nó không cung cấp bộ cân bằng tải. Nếu cluster của bạn được triển khai trên nền tảng đám mây, Kubernetes có thể yêu cầu hạ tầng đám mây cấp phát một bộ cân bằng tải và cấu hình nó để chuyển tiếp lưu lượng vào cluster.

Hạ tầng sẽ thông báo cho Kubernetes địa chỉ IP của bộ cân bằng tải và địa chỉ này trở thành địa chỉ bên ngoài của dịch vụ.

Quy trình tạo đối tượng Service, cấp phát bộ cân bằng tải và cách nó chuyển tiếp kết nối vào cluster được minh họa trong hình sau:

**Hình 3.10**: Quy trình khi bạn tạo một đối tượng Service loại LoadBalancer

![](https://img001.prntscr.com/file/img001/pHKvYDFGSBKkRz7B5abX3Q.png)
---

Việc cấp phát bộ cân bằng tải mất một chút thời gian, vì vậy hãy đợi vài giây và kiểm tra lại xem địa chỉ IP đã được gán chưa. Lần này, thay vì liệt kê tất cả các service, bạn chỉ hiển thị service **kiada** như sau:

```bash
$ kubectl get svc kiada
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)           AGE
kiada   LoadBalancer   10.19.243.17    35.246.179.22    8080:30838/TCP    82s
```

Địa chỉ IP bên ngoài giờ đã xuất hiện. Điều này có nghĩa là bộ cân bằng tải đã sẵn sàng chuyển tiếp yêu cầu đến ứng dụng của bạn từ các khách hàng trên toàn thế giới.

**Lưu ý**
Nếu bạn triển khai cluster với **Docker Desktop**, địa chỉ IP của bộ cân bằng tải được hiển thị là **localhost**, đề cập đến máy Windows hoặc macOS của bạn, chứ không phải VM nơi Kubernetes và ứng dụng đang chạy. Nếu bạn sử dụng **Minikube** để tạo cluster, sẽ không có bộ cân bằng tải nào được tạo, nhưng bạn có thể truy cập dịch vụ theo cách khác. Chúng ta sẽ nói về vấn đề này sau.

---

### Truy cập ứng dụng của bạn qua bộ cân bằng tải

Bây giờ bạn có thể gửi yêu cầu đến ứng dụng của mình qua địa chỉ IP và cổng bên ngoài của dịch vụ:

```bash
$ curl 35.246.179.22:8080
Kiada version 0.1. Request processed by "kiada-9d785b578-p449x". Client IP:
```

**Lưu ý**
Nếu bạn dùng **Docker Desktop**, dịch vụ sẽ có sẵn tại **localhost:8080** từ hệ điều hành máy chủ của bạn. Hãy sử dụng **curl** hoặc trình duyệt để truy cập nó.

Chúc mừng! Nếu bạn sử dụng **Google Kubernetes Engine**, bạn đã xuất bản ứng dụng của mình đến người dùng trên toàn cầu. Bất kỳ ai biết IP và cổng của nó đều có thể truy cập.

Nếu không tính các bước cần thiết để triển khai cluster, chỉ có hai lệnh đơn giản cần thiết để triển khai ứng dụng của bạn:

```bash
kubectl create deployment
kubectl expose deployment
```

---

### Truy cập ứng dụng khi không có bộ cân bằng tải

Không phải tất cả các cluster Kubernetes đều có cơ chế cung cấp bộ cân bằng tải. Cluster do **Minikube** cung cấp là một trong số đó. Nếu bạn tạo một service loại **LoadBalancer**, bản thân dịch vụ hoạt động, nhưng sẽ không có bộ cân bằng tải nào. **Kubectl** luôn hiển thị địa chỉ IP bên ngoài là `<pending>` và bạn phải sử dụng phương pháp khác để truy cập dịch vụ.

Có một số phương pháp để truy cập dịch vụ. Bạn thậm chí có thể bỏ qua service và truy cập trực tiếp các pod riêng lẻ, nhưng cách này chủ yếu được sử dụng để khắc phục sự cố. Bạn sẽ học cách làm điều này trong **chương 5**. Hiện tại, hãy khám phá cách dễ hơn để truy cập dịch vụ khi không có bộ cân bằng tải.

**Minikube** có thể cho bạn biết nơi truy cập dịch vụ nếu bạn sử dụng lệnh sau:

```bash
$ minikube service kiada --url
http://192.168.99.102:30838
```

Lệnh này sẽ in ra URL của dịch vụ. Bây giờ bạn có thể dùng **curl** hoặc trình duyệt để truy cập ứng dụng của mình:

```bash
$ curl http://192.168.99.102:30838
Kiada version 0.1. Request processed by "kiada-9d785b578-p449x". Client IP:
```

**Mẹo**
Nếu bạn bỏ tùy chọn **--url** khi chạy lệnh **minikube service**, trình duyệt của bạn sẽ tự động mở và tải URL của dịch vụ.

---

Bạn có thể thắc mắc địa chỉ IP và cổng này đến từ đâu. Đây là địa chỉ IP của máy ảo **Minikube**. Bạn có thể xác nhận bằng cách chạy lệnh:

```bash
minikube ip
```

Máy ảo Minikube cũng chính là node worker duy nhất của bạn. Cổng **30838** là cái gọi là **node port**. Đây là cổng trên node worker chuyển tiếp kết nối đến dịch vụ của bạn. Bạn có thể thấy cổng này trong danh sách cổng của dịch vụ khi chạy:

```bash
$ kubectl get svc kiada
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)           AGE
kiada   LoadBalancer   10.19.243.17    <pending>      8080:30838/TCP    82s
```

Dịch vụ của bạn có thể truy cập qua số cổng này trên tất cả các node worker, bất kể bạn sử dụng Minikube hay bất kỳ cluster Kubernetes nào khác.

---

**Lưu ý**
Nếu bạn sử dụng **Docker Desktop**, VM chạy Kubernetes không thể truy cập từ hệ điều hành máy chủ thông qua IP của VM. Bạn chỉ có thể truy cập dịch vụ qua **node port** bên trong VM bằng cách đăng nhập vào nó thông qua container đặc biệt như đã mô tả trong **mục 3.1.1**.

Nếu bạn biết IP của ít nhất một node worker, bạn có thể truy cập dịch vụ của mình qua **IP\:port** này, miễn là các quy tắc tường lửa không ngăn chặn bạn truy cập cổng.

Hình tiếp theo minh họa cách các client bên ngoài truy cập ứng dụng qua **node port**.

**Hình 3.11**: Tuyến kết nối qua node port của service
![](https://img001.prntscr.com/file/img001/pHKvYDFGSBKkRz7B5abX3Q.png)
---

Liên hệ với những gì tôi đã đề cập trước đó về việc bộ cân bằng tải chuyển tiếp kết nối đến các node và sau đó các node chuyển tiếp chúng đến container: **node port** chính là nơi bộ cân bằng tải gửi các yêu cầu đến. Kubernetes sau đó sẽ đảm bảo các yêu cầu này được chuyển tiếp đến ứng dụng đang chạy trong container. Bạn sẽ học cách nó thực hiện điều này trong **chương 10**, khi chúng ta tìm hiểu sâu hơn về dịch vụ.

Đừng mất quá nhiều thời gian suy nghĩ về vấn đề này bây giờ. Thay vào đó, hãy tiếp tục khám phá cluster của chúng ta để xem Kubernetes còn làm được những gì khác.


### 3.3.3 Mở rộng ứng dụng theo chiều ngang

Giờ bạn đã có một ứng dụng đang chạy, được đại diện bởi một **Deployment** và được mở ra với thế giới bởi một đối tượng **Service**. Bây giờ hãy tạo thêm một chút “ma thuật” nữa.

Một trong những lợi ích lớn nhất của việc chạy ứng dụng trong container là khả năng mở rộng triển khai ứng dụng một cách dễ dàng. Hiện tại bạn đang chạy một instance duy nhất của ứng dụng. Hãy tưởng tượng bỗng nhiên có rất nhiều người dùng truy cập vào ứng dụng của bạn. Instance duy nhất này sẽ không thể xử lý được toàn bộ tải. Bạn cần chạy thêm nhiều instance khác để phân phối tải và phục vụ người dùng của mình. Điều này được gọi là **scaling out** (mở rộng ngang). Với Kubernetes, điều này cực kỳ đơn giản.

---

### Tăng số lượng instance của ứng dụng đang chạy

Để triển khai ứng dụng, bạn đã tạo một đối tượng **Deployment**. Theo mặc định, nó chạy một instance của ứng dụng. Để chạy thêm nhiều instance, bạn chỉ cần mở rộng đối tượng **Deployment** bằng lệnh sau:

```bash
$ kubectl scale deployment kiada --replicas=3
deployment.apps/kiada scaled
```

Giờ bạn đã thông báo cho Kubernetes rằng bạn muốn chạy ba bản sao chính xác của pod. Lưu ý rằng bạn không nói cho Kubernetes biết phải làm gì. Bạn không bảo nó thêm hai pod nữa. Bạn chỉ cần đặt số lượng replica mới mong muốn và để Kubernetes tự xác định các hành động cần thiết để đạt trạng thái mong muốn đó.

Đây là một trong những nguyên tắc cơ bản nhất của Kubernetes. Thay vì nói cho Kubernetes biết phải làm gì, bạn chỉ cần đặt trạng thái mong muốn mới của hệ thống và để Kubernetes thực hiện nó. Để làm điều này, nó sẽ kiểm tra trạng thái hiện tại, so sánh với trạng thái mong muốn, xác định sự khác biệt và quyết định những gì cần làm để đồng bộ chúng.

---

### Xem kết quả của việc mở rộng

Mặc dù đúng là lệnh **kubectl scale deployment** có vẻ mang tính mệnh lệnh vì nó dường như bảo Kubernetes mở rộng ứng dụng của bạn, nhưng trên thực tế, lệnh này chỉ sửa đổi đối tượng **Deployment** đã chỉ định.

Như bạn sẽ thấy trong các chương sau, bạn thậm chí có thể chỉ cần chỉnh sửa đối tượng thay vì dùng lệnh mệnh lệnh. Hãy xem lại đối tượng Deployment để xem lệnh scale đã ảnh hưởng đến nó như thế nào:

```bash
$ kubectl get deploy
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
kiada   3/3     3            3           18m
```

Ba instance hiện đã được cập nhật và sẵn sàng, ba trên ba container đều **READY**. Điều này không thể hiện rõ từ kết quả lệnh, nhưng ba container này không nằm trong cùng một instance pod. Có ba pod với mỗi pod chứa một container. Bạn có thể xác nhận điều này bằng cách liệt kê các pod:

```bash
$ kubectl get pods
NAME                         READY   STATUS    RESTARTS   AGE
kiada-9d785b578-58vhc        1/1     Running   0          17s
kiada-9d785b578-jmnj8        1/1     Running   0          17s
kiada-9d785b578-p449x        1/1     Running   0          18m
```

Như bạn thấy, hiện đã có ba pod. Như cột **READY** chỉ ra, mỗi pod có một container và tất cả container đều sẵn sàng. Tất cả pod đều đang **Running**.

---

### Hiển thị node host của pod khi liệt kê pod

Nếu bạn sử dụng cluster một node, tất cả pod của bạn sẽ chạy trên cùng một node. Nhưng trong một cluster nhiều node, ba pod này sẽ được phân phối khắp cluster. Để xem các pod được lập lịch trên node nào, bạn có thể dùng tùy chọn **-o wide** để hiển thị danh sách pod chi tiết hơn:

```bash
$ kubectl get pods -o wide
NAME                         ...     IP            NODE
kiada-9d785b578-58vhc        ...     10.244.1.5     kind-worker    #A
kiada-9d785b578-jmnj8        ...     10.244.2.4     kind-worker2   #B
kiada-9d785b578-p449x        ...     10.244.2.3     kind-worker2   #B
```

**Lưu ý**
Bạn cũng có thể dùng tùy chọn **-o wide** để xem thêm thông tin khi liệt kê các loại đối tượng khác.

Kết quả **wide** cho thấy một pod được lập lịch trên một node, trong khi hai pod khác được lập lịch trên một node khác. **Scheduler** thường phân phối pod đồng đều, nhưng điều này phụ thuộc vào cách cấu hình. Bạn sẽ học thêm về lập lịch trong **chương 21**.

---

### Node host có quan trọng không?

Bất kể chúng chạy trên node nào, tất cả các instance của ứng dụng đều có môi trường hệ điều hành giống hệt nhau vì chúng chạy trong container được tạo từ cùng một image. Bạn có thể nhớ từ chương trước rằng điều duy nhất có thể khác là **kernel** của hệ điều hành, nhưng điều này chỉ xảy ra khi các node khác nhau sử dụng phiên bản kernel khác nhau hoặc nạp module kernel khác nhau.

Ngoài ra, mỗi pod đều nhận được địa chỉ IP riêng và có thể giao tiếp với bất kỳ pod nào khác theo cùng một cách – không quan trọng pod kia nằm trên cùng một node, một node khác trong cùng tủ rack hay thậm chí một data center hoàn toàn khác.

Cho đến giờ, bạn chưa đặt yêu cầu tài nguyên cho pod, nhưng nếu bạn làm vậy, mỗi pod sẽ được cấp phát lượng tài nguyên tính toán được yêu cầu. Pod không cần quan tâm node nào cung cấp tài nguyên này, miễn là yêu cầu của pod được đáp ứng.

Do đó, bạn không cần quan tâm pod được lập lịch trên node nào. Đây cũng là lý do tại sao lệnh **kubectl get pods** mặc định không hiển thị thông tin về node worker của các pod. Trong thế giới Kubernetes, điều này không quá quan trọng.

Như bạn thấy, mở rộng một ứng dụng cực kỳ dễ dàng. Một khi ứng dụng của bạn chạy trong môi trường production và cần mở rộng, bạn có thể thêm các instance mới chỉ với một lệnh duy nhất mà không cần cài đặt, cấu hình và chạy thủ công các bản sao bổ sung.

**Lưu ý**
Bản thân ứng dụng phải hỗ trợ **horizontal scaling**. Kubernetes không tự động làm cho ứng dụng của bạn có thể mở rộng; nó chỉ làm cho việc nhân bản trở nên đơn giản.

---

### Quan sát các yêu cầu đến cả ba pod khi dùng service

Bây giờ khi nhiều instance của ứng dụng đang chạy, hãy xem điều gì xảy ra khi bạn gọi lại URL của service. Liệu phản hồi có đến từ cùng một instance mỗi lần không? Đây là câu trả lời:

```bash
$ curl 35.246.179.22:8080
Kiada version 0.1. Request processed by "kiada-9d785b578-58vhc". Client IP:
$ curl 35.246.179.22:8080
Kiada version 0.1. Request processed by "kiada-9d785b578-p449x". Client IP:
$ curl 35.246.179.22:8080
Kiada version 0.1. Request processed by "kiada-9d785b578-jmnj8". Client IP:
$ curl 35.246.179.22:8080
Kiada version 0.1. Request processed by "kiada-9d785b578-p449x". Client IP:
```

Nếu bạn để ý kỹ các phản hồi, bạn sẽ thấy chúng tương ứng với tên của các pod. Mỗi yêu cầu đến một pod khác nhau theo thứ tự ngẫu nhiên. Đây chính là điều mà các **Service** trong Kubernetes thực hiện khi có nhiều instance pod đứng phía sau chúng. Chúng hoạt động như các bộ cân bằng tải phía trước các pod.

Hãy hình dung hệ thống bằng hình sau:

**Hình 3.12**: Cân bằng tải giữa nhiều pod đứng sau cùng một service
![](https://img001.prntscr.com/file/img001/zfNO_E7aRGqx3IZI50PTiQ.png)
Như hình vẽ minh họa, bạn không nên nhầm lẫn cơ chế cân bằng tải này, được cung cấp bởi chính **Service** của Kubernetes, với bộ cân bằng tải bổ sung được cung cấp bởi hạ tầng khi chạy trong **GKE** hoặc một cluster đám mây khác.

Ngay cả khi bạn dùng **Minikube** và không có bộ cân bằng tải bên ngoài, các yêu cầu của bạn vẫn được phân phối qua ba pod bởi chính **Service**. Nếu bạn dùng **GKE**, thực ra sẽ có hai bộ cân bằng tải hoạt động song song.

Hình vẽ cho thấy bộ cân bằng tải được hạ tầng cung cấp phân phối các yêu cầu qua các node, sau đó **Service** phân phối yêu cầu qua các pod.

Tôi biết điều này có thể rất rối rắm ngay lúc này, nhưng mọi thứ sẽ trở nên rõ ràng trong **chương 10**.


### 3.3.4 Hiểu về ứng dụng đã triển khai

Để kết thúc chương này, hãy xem lại hệ thống của bạn gồm những gì. Có hai cách để nhìn vào hệ thống của bạn – góc nhìn logic và góc nhìn vật lý. Bạn vừa thấy góc nhìn vật lý trong hình 3.12. Có ba container đang chạy được triển khai trên ba node worker (một node duy nhất khi sử dụng Minikube). Nếu bạn chạy Kubernetes trên nền tảng đám mây, hạ tầng đám mây cũng đã tạo một bộ cân bằng tải (load balancer) cho bạn. Docker Desktop cũng tạo một loại bộ cân bằng tải cục bộ. Minikube thì không tạo bộ cân bằng tải, nhưng bạn có thể truy cập dịch vụ của mình trực tiếp qua node port.

Mặc dù có sự khác biệt trong góc nhìn vật lý của hệ thống ở các cluster khác nhau, nhưng góc nhìn logic thì luôn giống nhau, dù bạn sử dụng một cluster phát triển nhỏ hay một cluster sản xuất lớn với hàng ngàn node. Nếu bạn không phải là người quản lý cluster, bạn thậm chí không cần phải lo lắng về góc nhìn vật lý của cluster. Nếu mọi thứ hoạt động như mong đợi, góc nhìn logic là tất cả những gì bạn cần quan tâm. Hãy xem kỹ hơn về góc nhìn này.

---

### Hiểu về các đối tượng API đại diện cho ứng dụng của bạn

Góc nhìn logic bao gồm các đối tượng mà bạn đã tạo trong API của Kubernetes – trực tiếp hoặc gián tiếp. Hình dưới đây cho thấy các đối tượng liên quan đến nhau như thế nào.

**Hình 3.13** Ứng dụng đã triển khai của bạn bao gồm một Deployment, một số Pod và một Service.
![](https://img001.prntscr.com/file/img001/ivU3iSkMSR6E_Wv0khZE_Q.png)
Các đối tượng bao gồm:

* Đối tượng **Deployment** mà bạn đã tạo,
* Các đối tượng **Pod** được tự động tạo dựa trên Deployment, và
* Đối tượng **Service** mà bạn đã tạo thủ công.

Có các đối tượng khác giữa ba đối tượng vừa đề cập, nhưng bạn chưa cần biết đến chúng. Bạn sẽ tìm hiểu về chúng trong các chương tiếp theo.

Hãy nhớ khi tôi giải thích trong chương 1 rằng Kubernetes trừu tượng hóa hạ tầng? Góc nhìn logic của ứng dụng của bạn là một ví dụ tuyệt vời về điều này. Không có node, không có topology mạng phức tạp, không có bộ cân bằng tải vật lý. Chỉ là một góc nhìn đơn giản, chỉ chứa các ứng dụng của bạn và các đối tượng hỗ trợ. Hãy xem các đối tượng này kết hợp với nhau như thế nào và chúng đóng vai trò gì trong hệ thống nhỏ của bạn.

* **Đối tượng Deployment** đại diện cho một lần triển khai ứng dụng. Nó xác định image container nào chứa ứng dụng của bạn và Kubernetes sẽ chạy bao nhiêu bản sao của ứng dụng. Mỗi bản sao được đại diện bởi một đối tượng Pod.
* **Đối tượng Service** đại diện cho một điểm truy cập giao tiếp duy nhất đến các bản sao này.

---

### Hiểu về các Pod

Phần cốt lõi và quan trọng nhất của hệ thống của bạn là các **Pod**. Mỗi định nghĩa Pod chứa một hoặc nhiều container tạo thành Pod. Khi Kubernetes khởi tạo một Pod, nó sẽ chạy tất cả các container được chỉ định trong định nghĩa đó. Miễn là một đối tượng Pod tồn tại, Kubernetes sẽ cố gắng hết sức để đảm bảo các container của nó tiếp tục chạy. Nó chỉ tắt chúng khi đối tượng Pod bị xóa.

---

### Hiểu vai trò của Deployment

Khi bạn lần đầu tạo đối tượng Deployment, chỉ có một đối tượng Pod được tạo. Nhưng khi bạn tăng số lượng bản sao mong muốn trên Deployment, Kubernetes tạo thêm các bản sao. Kubernetes đảm bảo rằng số lượng Pod thực tế luôn khớp với số lượng mong muốn.

Nếu một hoặc nhiều Pod biến mất hoặc trạng thái của chúng không xác định, Kubernetes sẽ thay thế chúng để đưa số lượng Pod thực tế trở lại số lượng bản sao mong muốn. Một Pod biến mất khi ai đó hoặc điều gì đó xóa nó, trong khi trạng thái của Pod không xác định khi node mà nó đang chạy không còn báo cáo trạng thái của nó do sự cố mạng hoặc node.

Nói một cách nghiêm ngặt, một Deployment không làm gì hơn ngoài việc tạo ra một số lượng đối tượng Pod nhất định. Bạn có thể tự hỏi liệu có thể tạo Pod trực tiếp thay vì để Deployment tạo chúng cho bạn không. Bạn hoàn toàn có thể làm điều này, nhưng nếu muốn chạy nhiều bản sao, bạn sẽ phải tự tạo thủ công từng Pod một và đảm bảo rằng mỗi Pod có một tên duy nhất. Sau đó, bạn cũng phải liên tục theo dõi các Pod của mình để thay thế chúng nếu chúng đột nhiên biến mất hoặc node mà chúng chạy gặp sự cố. Và đó chính là lý do tại sao bạn hầu như không bao giờ tạo Pod trực tiếp mà thay vào đó sử dụng một Deployment.

---

### Hiểu tại sao bạn cần Service

Thành phần thứ ba của hệ thống là đối tượng **Service**. Khi tạo nó, bạn nói với Kubernetes rằng bạn cần một điểm truy cập giao tiếp duy nhất đến các Pod của mình. Service cung cấp cho bạn một địa chỉ IP duy nhất để giao tiếp với các Pod, bất kể có bao nhiêu bản sao hiện đang được triển khai. Nếu Service được hỗ trợ bởi nhiều Pod, nó hoạt động như một bộ cân bằng tải. Nhưng ngay cả khi chỉ có một Pod, bạn vẫn muốn expose nó thông qua một Service. Để hiểu lý do tại sao, bạn cần biết một chi tiết quan trọng về các Pod.

Pod là **tạm thời**. Một Pod có thể biến mất bất kỳ lúc nào. Điều này có thể xảy ra khi node lưu trữ của nó gặp sự cố, khi ai đó vô tình xóa Pod, hoặc khi Pod bị loại bỏ khỏi một node khỏe mạnh để nhường chỗ cho các Pod khác quan trọng hơn. Như đã giải thích ở phần trước, khi các Pod được tạo thông qua Deployment, một Pod bị thiếu sẽ ngay lập tức được thay thế bằng một Pod mới. Pod mới này không giống với Pod mà nó thay thế. Nó là một Pod hoàn toàn mới, với một địa chỉ IP mới.

Nếu bạn không sử dụng Service và cấu hình các client của mình kết nối trực tiếp đến IP của Pod ban đầu, bây giờ bạn sẽ cần cấu hình lại tất cả các client này để kết nối đến IP của Pod mới. Điều này là không cần thiết khi sử dụng Service. Không giống như Pod, Service không phải là tạm thời. Khi bạn tạo một Service, nó được gán một địa chỉ IP tĩnh không bao giờ thay đổi trong suốt vòng đời của Service.

Thay vì kết nối trực tiếp đến Pod, các client nên kết nối đến IP của Service. Điều này đảm bảo rằng các kết nối của chúng luôn được định tuyến đến một Pod khỏe mạnh, ngay cả khi tập hợp các Pod đằng sau Service liên tục thay đổi. Nó cũng đảm bảo rằng tải được phân phối đều trên tất cả các Pod nếu bạn quyết định scale Deployment theo chiều ngang.

---

## 3.4 Tóm tắt

Trong chương thực hành này, bạn đã học được rằng:

* Hầu như tất cả các nhà cung cấp dịch vụ đám mây đều cung cấp tùy chọn Kubernetes được quản lý. Họ chịu trách nhiệm duy trì cluster Kubernetes của bạn, trong khi bạn chỉ sử dụng API của nó để triển khai ứng dụng của mình.
* Bạn cũng có thể tự cài đặt Kubernetes trên đám mây, nhưng điều này thường không phải là ý tưởng hay cho đến khi bạn thành thạo mọi khía cạnh của việc quản lý Kubernetes.
* Bạn có thể cài đặt Kubernetes cục bộ, ngay cả trên laptop của mình, bằng các công cụ như **Docker Desktop** hoặc **Minikube**, chạy Kubernetes trong một máy ảo Linux, hoặc **kind**, chạy các node master và worker dưới dạng container Docker và các container ứng dụng bên trong những container đó.
* **Kubectl**, công cụ dòng lệnh, là cách thông thường để bạn tương tác với Kubernetes. Một bảng điều khiển dựa trên web cũng tồn tại nhưng không ổn định và cập nhật như công cụ CLI.
* Để làm việc nhanh hơn với **kubectl**, bạn nên định nghĩa một alias ngắn cho nó và bật tính năng tự động hoàn thành lệnh trên shell.
* Một ứng dụng có thể được triển khai bằng **kubectl create deployment**. Sau đó có thể expose nó cho client bằng cách chạy **kubectl expose deployment**.
* Scale ứng dụng theo chiều ngang rất đơn giản: **kubectl scale deployment** hướng dẫn Kubernetes thêm bản sao mới hoặc xóa các bản sao hiện có để đạt được số lượng bản sao mà bạn chỉ định.
* Đơn vị triển khai cơ bản không phải là container, mà là **Pod**, có thể chứa một hoặc nhiều container liên quan.
* **Deployments**, **Services**, **Pods** và **Nodes** là các đối tượng/tài nguyên của Kubernetes. Bạn có thể liệt kê chúng với **kubectl get** và kiểm tra chi tiết với **kubectl describe**.
* Đối tượng **Deployment** triển khai số lượng Pod mong muốn, trong khi đối tượng **Service** làm cho chúng có thể truy cập được dưới một địa chỉ IP ổn định duy nhất.
* Mỗi Service cung cấp cân bằng tải nội bộ trong cluster, nhưng nếu bạn đặt kiểu Service là **LoadBalancer**, Kubernetes sẽ yêu cầu hạ tầng đám mây mà nó chạy trên đó cung cấp thêm một bộ cân bằng tải để làm cho ứng dụng của bạn có thể truy cập được từ bên ngoài.

Bạn vừa hoàn thành chuyến tham quan có hướng dẫn đầu tiên quanh vịnh. Bây giờ là lúc bắt đầu học các kiến thức nền tảng, để bạn có thể tự mình điều khiển con thuyền. Phần tiếp theo của cuốn sách tập trung vào các đối tượng Kubernetes khác nhau và cách/khi nào sử dụng chúng. Bạn sẽ bắt đầu với đối tượng quan trọng nhất – **Pod**.

