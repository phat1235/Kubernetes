# 5 Chạy khối lượng công việc trong Pod
Chương này bao gồm

* Hiểu cách và thời điểm để nhóm các container
* Chạy một ứng dụng bằng cách tạo đối tượng Pod từ tệp YAML
* Giao tiếp với ứng dụng, xem nhật ký của nó và khám phá môi trường của nó
* Thêm container sidecar để mở rộng container chính của pod
* Khởi tạo pod bằng cách chạy các container init khi pod khởi động

Hãy để tôi nhắc lại bằng một sơ đồ hiển thị ba loại đối tượng mà bạn đã tạo trong chương 3 để triển khai một ứng dụng tối giản trên Kubernetes. Hình 5.1 cho thấy cách chúng liên quan với nhau và chức năng của chúng trong hệ thống.

**Hình 5.1** Ba loại đối tượng cơ bản cấu thành một ứng dụng được triển khai

![](https://img001.prntscr.com/file/img001/oZ0zn-qwQ1O5xdvnwoWL7A.png)

Bây giờ bạn đã có hiểu biết cơ bản về cách các đối tượng này được hiển thị thông qua API Kubernetes. Trong chương này và các chương tiếp theo, bạn sẽ tìm hiểu chi tiết về từng loại và nhiều loại khác thường được sử dụng để triển khai một ứng dụng đầy đủ. Hãy bắt đầu với đối tượng Pod, vì nó đại diện cho khái niệm trung tâm, quan trọng nhất trong Kubernetes — một phiên bản đang chạy của ứng dụng của bạn.

**Lưu ý**
Bạn sẽ tìm thấy mã nguồn cho chương này tại
[https://github.com/luksa/kubernetes-in-action-2ndedition/tree/master/Chapter05](https://github.com/luksa/kubernetes-in-action-2ndedition/tree/master/Chapter05)

---

### 5.1 Hiểu về Pod

Bạn đã học rằng Pod là một nhóm container được đặt cùng vị trí và là khối xây dựng cơ bản trong Kubernetes. Thay vì triển khai từng container riêng lẻ, bạn triển khai và quản lý một nhóm container như một đơn vị duy nhất — một Pod. Mặc dù Pod có thể chứa nhiều container, nhưng không hiếm khi Pod chỉ chứa một container duy nhất. Khi một Pod có nhiều container, tất cả chúng chạy trên cùng một nút worker — một phiên bản Pod duy nhất không bao giờ trải rộng trên nhiều nút. **Hình 5.2** sẽ giúp bạn hình dung thông tin này.

**Hình 5.2** Tất cả container của một Pod chạy trên cùng một nút. Một Pod không bao giờ trải rộng trên nhiều nút.

![](https://img001.prntscr.com/file/img001/pZwJgoZxTUOmmxupyXNsvA.png)
---

### 5.1.1 Hiểu tại sao chúng ta cần Pod

Hãy thảo luận lý do tại sao chúng ta cần chạy nhiều container cùng nhau, thay vì, ví dụ, chạy nhiều tiến trình trong cùng một container.

#### Hiểu tại sao một container không nên chứa nhiều tiến trình

Hãy tưởng tượng một ứng dụng gồm nhiều tiến trình giao tiếp với nhau qua IPC (Giao tiếp Liên Tiến trình) hoặc tệp chia sẻ, yêu cầu chúng phải chạy trên cùng một máy tính. Trong chương 2, bạn đã học rằng mỗi container giống như một máy tính hoặc máy ảo độc lập. Một máy tính thường chạy nhiều tiến trình; container cũng có thể làm điều này. Bạn có thể chạy tất cả các tiến trình tạo nên một ứng dụng trong chỉ một container, nhưng điều đó khiến container rất khó quản lý.

Container được thiết kế để chạy chỉ một tiến trình, không tính các tiến trình con mà nó tạo ra. Cả công cụ container và Kubernetes đều được phát triển dựa trên thực tế này. Ví dụ, một tiến trình chạy trong container được kỳ vọng sẽ ghi nhật ký của nó ra đầu ra chuẩn. Các lệnh Docker và Kubernetes mà bạn sử dụng để hiển thị nhật ký chỉ hiển thị những gì được ghi từ đầu ra này. Nếu một tiến trình duy nhất chạy trong container, nó là tiến trình duy nhất ghi nhật ký, nhưng nếu bạn chạy nhiều tiến trình trong container, tất cả chúng đều ghi vào cùng một đầu ra. Do đó, nhật ký của chúng bị trộn lẫn, và khó có thể biết dòng nào thuộc về tiến trình nào.

Một chỉ dẫn khác cho thấy container chỉ nên chạy một tiến trình là thực tế runtime của container chỉ khởi động lại container khi tiến trình gốc của container chết. Nó không quan tâm đến bất kỳ tiến trình con nào do tiến trình gốc này tạo ra. Nếu tiến trình gốc tạo ra các tiến trình con, chính nó chịu trách nhiệm giữ cho tất cả các tiến trình này chạy.

Để tận dụng đầy đủ các tính năng mà runtime container cung cấp, bạn nên chạy chỉ một tiến trình trong mỗi container.

---

#### Hiểu cách một Pod kết hợp nhiều container

Vì bạn không nên chạy nhiều tiến trình trong một container duy nhất, nên rõ ràng bạn cần một cấu trúc cấp cao hơn cho phép bạn chạy các tiến trình liên quan cùng nhau ngay cả khi chúng được chia thành nhiều container. Các tiến trình này phải có khả năng giao tiếp với nhau như trong một máy tính bình thường. Và đó là lý do tại sao Pod được giới thiệu.

Với một Pod, bạn có thể chạy các tiến trình liên quan chặt chẽ cùng nhau, cung cấp cho chúng (gần như) cùng một môi trường như thể tất cả chúng đang chạy trong một container duy nhất. Các tiến trình này có phần cách ly, nhưng không hoàn toàn — chúng chia sẻ một số tài nguyên. Điều này mang lại cho bạn những lợi ích tốt nhất của cả hai phía. Bạn có thể sử dụng tất cả các tính năng mà container cung cấp, nhưng cũng cho phép các tiến trình làm việc cùng nhau.

Pod giúp quản lý các container liên kết này như một đơn vị duy nhất.

Trong chương 2, bạn đã học rằng một container sử dụng tập hợp riêng của các namespace Linux, nhưng nó cũng có thể chia sẻ một số namespace với container khác. Việc chia sẻ namespace này chính là cách Kubernetes và runtime container kết hợp các container vào Pod.

Như minh họa trong **Hình 5.3**, tất cả container trong một Pod chia sẻ cùng một namespace Mạng và do đó các giao diện mạng, địa chỉ IP và không gian cổng thuộc về nó.

**Hình 5.3** Các container trong một Pod chia sẻ cùng giao diện mạng

![](https://img001.prntscr.com/file/img001/6Qsd0x3LS8WBvDoSp8CzTA.png)

Do chia sẻ không gian cổng, các tiến trình chạy trong container của cùng một Pod không thể được gắn vào cùng một số cổng, trong khi các tiến trình trong Pod khác có các giao diện mạng và không gian cổng riêng, loại bỏ xung đột cổng giữa các Pod khác nhau.

Tất cả các container trong một Pod cũng thấy cùng một hostname hệ thống, vì chúng chia sẻ namespace UTS, và có thể giao tiếp qua các cơ chế IPC thông thường vì chúng chia sẻ namespace IPC. Một Pod cũng có thể được cấu hình để sử dụng một namespace PID duy nhất cho tất cả container của nó, điều này khiến chúng chia sẻ cùng một cây tiến trình, nhưng bạn phải bật tính năng này rõ ràng cho từng Pod riêng lẻ.

**Lưu ý**
Khi các container của cùng một Pod sử dụng namespace PID riêng, chúng không thể nhìn thấy nhau hoặc gửi tín hiệu tiến trình như SIGTERM hoặc SIGINT cho nhau.

Chính việc chia sẻ một số namespace nhất định này khiến các tiến trình chạy trong Pod có cảm giác rằng chúng chạy cùng nhau, mặc dù thực tế chúng chạy trong các container riêng biệt.

Ngược lại, mỗi container luôn có namespace Mount riêng, cung cấp cho nó hệ thống tệp riêng, nhưng khi hai container phải chia sẻ một phần hệ thống tệp, bạn có thể thêm một volume vào Pod và gắn nó vào cả hai container. Hai container vẫn sử dụng hai namespace Mount riêng, nhưng volume được chia sẻ được gắn vào cả hai. Bạn sẽ tìm hiểu thêm về volume trong chương 7.

---

### 5.1.2 Tổ chức container vào Pod

Bạn có thể coi mỗi Pod như một máy tính riêng biệt. Không giống như máy ảo, thường lưu trữ nhiều ứng dụng, bạn thường chỉ chạy một ứng dụng trong mỗi Pod. Bạn không bao giờ cần kết hợp nhiều ứng dụng vào một Pod duy nhất, vì Pod hầu như không có chi phí tài nguyên bổ sung. Bạn có thể có bao nhiêu Pod tùy thích, vì vậy thay vì nhét tất cả ứng dụng của bạn vào một Pod duy nhất, bạn nên chia chúng ra để mỗi Pod chỉ chạy các tiến trình ứng dụng liên quan chặt chẽ.

Hãy để tôi minh họa điều này bằng một ví dụ cụ thể.

---

#### Tách một ứng dụng đa tầng thành nhiều Pod

Hãy tưởng tượng một hệ thống đơn giản gồm một máy chủ web front-end và một cơ sở dữ liệu back-end. Tôi đã giải thích rằng máy chủ front-end và cơ sở dữ liệu không nên chạy trong cùng một container, vì tất cả các tính năng được tích hợp trong container được thiết kế dựa trên giả định rằng không quá một tiến trình chạy trong một container. Nếu không trong cùng một container, vậy bạn có nên chạy chúng trong các container riêng biệt nhưng thuộc cùng một Pod không?

Mặc dù không có gì ngăn cản bạn chạy cả máy chủ front-end và cơ sở dữ liệu trong một Pod duy nhất, nhưng đây không phải là cách tiếp cận tốt nhất. Tôi đã giải thích rằng tất cả container của một Pod luôn chạy cùng vị trí, nhưng liệu máy chủ web và cơ sở dữ liệu có cần chạy trên cùng một máy tính không? Câu trả lời rõ ràng là không, vì chúng có thể dễ dàng giao tiếp qua mạng. Do đó, bạn không nên chạy chúng trong cùng một Pod.

Nếu cả front-end và back-end đều trong cùng một Pod, cả hai chạy trên cùng một nút trong cluster. Nếu bạn có một cluster hai nút và chỉ tạo Pod này, bạn chỉ đang sử dụng một nút worker và không tận dụng tài nguyên tính toán có sẵn trên nút thứ hai. Điều này có nghĩa là lãng phí CPU, bộ nhớ, lưu trữ đĩa và băng thông. Tách container thành hai Pod cho phép Kubernetes đặt Pod front-end trên một nút và Pod back-end trên nút kia, nhờ đó cải thiện việc sử dụng phần cứng của bạn.

---

#### Tách thành nhiều Pod để cho phép mở rộng riêng lẻ

Một lý do khác để không sử dụng một Pod duy nhất liên quan đến mở rộng theo chiều ngang. Pod không chỉ là đơn vị triển khai cơ bản mà còn là đơn vị mở rộng cơ bản. Trong chương 2, bạn đã mở rộng đối tượng Deployment và Kubernetes tạo thêm Pod — các bản sao bổ sung của ứng dụng của bạn. **Kubernetes không nhân bản container trong một Pod. Nó nhân bản toàn bộ Pod.**

Thành phần front-end thường có yêu cầu mở rộng khác với thành phần back-end, vì vậy chúng ta thường mở rộng chúng riêng lẻ. Khi Pod của bạn chứa cả container front-end và back-end và Kubernetes nhân bản nó, bạn sẽ có nhiều phiên bản của cả container front-end và back-end, điều này không phải lúc nào cũng là điều bạn muốn. Back-end có trạng thái, chẳng hạn như cơ sở dữ liệu, thường không thể mở rộng. Ít nhất là không dễ dàng như front-end không trạng thái. Nếu một container phải được mở rộng riêng biệt khỏi các thành phần khác, đây là dấu hiệu rõ ràng rằng nó phải được triển khai trong một Pod riêng biệt.

Hình sau minh họa những gì vừa được giải thích.

**Hình 5.4** Tách một ngăn xếp ứng dụng thành các Pod

![](https://img001.prntscr.com/file/img001/HoEsSRFNSr6HlP1VVVHgKA.png)

Tách ngăn xếp ứng dụng thành nhiều Pod là cách tiếp cận đúng. Nhưng khi nào thì chạy nhiều container trong cùng một Pod?

### Giới thiệu về container sidecar
Việc đặt nhiều container trong một pod chỉ phù hợp khi ứng dụng bao gồm một tiến trình chính và một hoặc nhiều tiến trình bổ sung cho hoạt động của tiến trình chính. Container mà trong đó tiến trình bổ sung chạy được gọi là **container sidecar** vì nó tương tự như một sidecar gắn vào xe máy, giúp xe máy ổn định hơn và có thể chở thêm một hành khách. Nhưng không giống như xe máy, một pod có thể có nhiều hơn một sidecar, như minh họa trong hình 5.5.

**Hình 5.5** Một pod với một container chính và các container sidecar

![](https://img001.prntscr.com/file/img001/NqtnAkUIQtasoR2XBIi-Ig.png)

Thật khó để hình dung như thế nào là một tiến trình bổ sung, vì vậy tôi sẽ đưa ra một số ví dụ. Trong chương 2, bạn đã triển khai các pod với một container chạy ứng dụng Node.js. Ứng dụng Node.js chỉ hỗ trợ giao thức HTTP. Để làm cho nó hỗ trợ HTTPS, chúng ta có thể thêm một chút mã JavaScript, nhưng chúng ta cũng có thể làm điều đó mà không cần thay đổi ứng dụng hiện có — bằng cách thêm một container bổ sung vào pod – một **reverse proxy** chuyển đổi lưu lượng HTTPS thành HTTP và chuyển tiếp nó đến container Node.js. Container Node.js là container chính, trong khi container chạy proxy là container sidecar. **Hình 5.6** minh họa ví dụ này.

**Hình 5.6** Một container sidecar chuyển đổi lưu lượng HTTPS thành HTTP

![](https://img001.prntscr.com/file/img001/RYl8wHEgTY6ykXY4J67dFw.png)

**Lưu ý**
Bạn sẽ tạo pod này trong mục 5.4.

Một ví dụ khác, như minh họa trong **hình 5.7**, là một pod trong đó container chính chạy một web server phục vụ các tệp từ thư mục webroot của nó. Container khác trong pod là một agent định kỳ tải nội dung từ nguồn bên ngoài và lưu trữ nó trong thư mục webroot của web server. Như đã đề cập trước đó, hai container có thể chia sẻ tệp bằng cách chia sẻ một volume. Thư mục webroot sẽ được đặt trên volume này.

**Hình 5.7** Một container sidecar cung cấp nội dung cho container web server thông qua volume

![](https://img001.prntscr.com/file/img001/-wyg0ggASQCnojmXQjZHww.png)

**Lưu ý**
Bạn sẽ tạo pod này trong chương 7.

Các ví dụ khác về container sidecar bao gồm bộ xoay và thu thập log, bộ xử lý dữ liệu, bộ chuyển đổi giao tiếp, và nhiều loại khác.

**Không giống như việc thay đổi mã hiện có của ứng dụng, việc thêm một sidecar sẽ làm tăng yêu cầu tài nguyên của pod vì phải chạy thêm một tiến trình. Nhưng hãy nhớ rằng việc thêm mã vào các ứng dụng cũ có thể rất khó khăn. Điều này có thể là do mã của nó khó sửa đổi, môi trường build khó thiết lập, hoặc mã nguồn bản thân không còn sẵn có. Mở rộng ứng dụng bằng cách thêm một tiến trình bổ sung đôi khi là một lựa chọn rẻ hơn và nhanh hơn.**

---

### Cách quyết định có nên tách các container thành nhiều pod

Khi quyết định có nên sử dụng mô hình sidecar và đặt các container trong một pod hay đặt chúng trong các pod riêng biệt, hãy tự hỏi bản thân những câu hỏi sau:

* Các container này có phải chạy trên cùng một host không?
* Tôi có muốn quản lý chúng như một đơn vị duy nhất không?
* Chúng có tạo thành một tổng thể thống nhất thay vì là các thành phần độc lập không?
* Chúng có phải được scale cùng nhau không?
* Một node duy nhất có đáp ứng được nhu cầu tài nguyên kết hợp của chúng không?

Nếu câu trả lời cho tất cả những câu hỏi này là **có**, hãy đặt tất cả chúng trong cùng một pod. Nguyên tắc chung là luôn đặt các container trong các pod riêng biệt trừ khi có một lý do cụ thể yêu cầu chúng phải là một phần của cùng một pod.

---

## 5.2 Tạo pod từ các tệp YAML hoặc JSON

Với những kiến thức bạn đã học ở các phần trước, bây giờ bạn có thể bắt đầu tạo các pod. Trong chương 3, bạn đã tạo chúng bằng lệnh **kubectl create** dạng mệnh lệnh, nhưng pod và các đối tượng Kubernetes khác thường được tạo bằng cách tạo một tệp manifest JSON hoặc YAML và gửi nó đến API của Kubernetes, như bạn đã học ở chương trước.

**Lưu ý**
Quyết định sử dụng YAML hay JSON để định nghĩa các đối tượng là tùy bạn. Hầu hết mọi người thích dùng YAML vì nó thân thiện hơn với con người và cho phép bạn thêm chú thích vào định nghĩa đối tượng.

Bằng cách sử dụng các tệp YAML để định nghĩa cấu trúc của ứng dụng, bạn không cần các script shell để làm cho quá trình triển khai ứng dụng của bạn có thể lặp lại, và bạn có thể lưu lại lịch sử tất cả thay đổi bằng cách lưu các tệp này trong VCS (Hệ thống Quản lý Phiên bản). Giống như cách bạn lưu mã nguồn.

Thực tế, tất cả các manifest của ứng dụng trong các bài tập của cuốn sách này đều được lưu trữ trong VCS. Bạn có thể tìm thấy chúng trên GitHub tại:
**github.com/luksa/kubernetes-inaction-2nd-edition**

---

### 5.2.1 Tạo manifest YAML cho một pod

Trong chương trước, bạn đã học cách lấy và xem xét các manifest YAML của các đối tượng API hiện có. Bây giờ bạn sẽ tạo một manifest đối tượng từ đầu.

Bạn sẽ bắt đầu bằng cách tạo một tệp có tên **pod.kiada.yaml** trên máy tính của mình, ở vị trí bạn chọn. Bạn cũng có thể tìm thấy tệp này trong kho mã của sách trong thư mục **Chapter05/**. Danh sách sau đây cho thấy nội dung của tệp:

**Danh sách 5.1** Một tệp manifest pod cơ bản

```yaml
apiVersion: v1          #A
kind: Pod               #B
metadata:
  name: kiada           #C
spec:
  containers:
  - name: kiada         #D
    image: luksa/kiada:0.1  #E
    ports:
    - containerPort: 8080   #F
```

Tôi chắc rằng bạn sẽ đồng ý rằng manifest pod này dễ hiểu hơn nhiều so với manifest khổng lồ đại diện cho đối tượng Node mà bạn đã thấy trong chương trước. Nhưng khi bạn gửi manifest đối tượng pod này đến API và sau đó đọc lại, nó sẽ không khác nhiều.

Manifest trong **danh sách 5.1** ngắn gọn chỉ vì nó chưa chứa tất cả các trường mà một đối tượng pod có được sau khi được tạo qua API. Ví dụ, bạn sẽ thấy rằng phần **metadata** chỉ chứa một trường duy nhất và phần **status** hoàn toàn thiếu. Khi bạn tạo đối tượng từ manifest này, điều này sẽ không còn như vậy nữa. Chúng ta sẽ tìm hiểu về điều này sau.

Trước khi tạo đối tượng, hãy xem xét chi tiết manifest. Nó sử dụng phiên bản **v1** của API Kubernetes để mô tả đối tượng. Loại đối tượng (**kind**) là **Pod** và tên của đối tượng (**name**) là **kiada**. Pod bao gồm một container duy nhất cũng được gọi là **kiada**, dựa trên image **luksa/kiada:0.1**. Định nghĩa pod cũng chỉ định rằng ứng dụng trong container lắng nghe trên cổng **8080**.

**Mẹo**
Bất cứ khi nào bạn muốn tạo một manifest pod từ đầu, bạn cũng có thể sử dụng lệnh sau để tạo tệp và sau đó chỉnh sửa nó để thêm nhiều trường hơn:

```bash
kubectl run kiada --image=luksa/kiada:0.1 --dry-run=client -o yaml > mypod.yaml
```

Cờ **--dry-run=client** yêu cầu kubectl xuất định nghĩa thay vì thực sự tạo đối tượng qua API.

Các trường trong tệp YAML khá dễ hiểu, nhưng nếu bạn muốn có thêm thông tin về từng trường hoặc muốn biết có thể thêm các trường nào khác, hãy nhớ sử dụng lệnh **kubectl explain pods**.

---

### 5.2.2 Tạo đối tượng Pod từ tệp YAML

Sau khi chuẩn bị tệp manifest cho pod của bạn, bây giờ bạn có thể tạo đối tượng bằng cách gửi tệp đến API của Kubernetes.

**Tạo đối tượng bằng cách áp dụng tệp manifest vào cluster**

Khi bạn gửi manifest đến API, bạn đang yêu cầu Kubernetes áp dụng manifest đó vào cluster. Đó là lý do tại sao lệnh con **kubectl** thực hiện việc này được gọi là **apply**. Hãy sử dụng nó để tạo pod:

```bash
$ kubectl apply -f pod.kiada.yaml
pod "kiada" created
```

**Cập nhật đối tượng bằng cách chỉnh sửa tệp manifest và áp dụng lại**

Lệnh **kubectl apply** được sử dụng để tạo đối tượng cũng như thực hiện các thay đổi đối với đối tượng hiện có. Nếu sau này bạn quyết định thay đổi đối tượng pod của mình, bạn có thể đơn giản chỉnh sửa tệp **pod.kiada.yaml** và chạy lại lệnh **apply**. Một số trường của pod không thể thay đổi, nên việc cập nhật có thể thất bại, nhưng bạn luôn có thể xóa pod và tạo lại nó. Bạn sẽ học cách xóa pod và các đối tượng khác ở cuối chương này.

**Lấy manifest đầy đủ của một pod đang chạy**

Đối tượng pod bây giờ là một phần của cấu hình cluster. Bạn có thể đọc lại nó từ API để xem manifest đầy đủ của đối tượng bằng lệnh sau:

```bash
$ kubectl get po kiada -o yaml
```

Nếu bạn chạy lệnh này, bạn sẽ thấy manifest đã mở rộng đáng kể so với tệp **pod.kiada.yaml**. Bạn sẽ thấy rằng phần **metadata** bây giờ lớn hơn nhiều, và đối tượng bây giờ có thêm phần **status**. Phần **spec** cũng đã tăng thêm một số trường. Bạn có thể sử dụng **kubectl explain** để tìm hiểu thêm về các trường mới này, nhưng hầu hết chúng sẽ được giải thích trong chương này và các chương tiếp theo.

### 5.2.3 Kiểm tra pod mới tạo

Hãy sử dụng các lệnh cơ bản của **kubectl** để xem pod hoạt động như thế nào trước khi chúng ta bắt đầu tương tác với ứng dụng đang chạy bên trong nó.

---

#### Kiểm tra nhanh trạng thái của pod

Đối tượng Pod của bạn đã được tạo, nhưng làm sao bạn biết container trong pod có thực sự đang chạy không?
Bạn có thể dùng lệnh **kubectl get** để xem tóm tắt về pod:

```bash
$ kubectl get pod kiada
NAME    READY   STATUS    RESTARTS   AGE
kiada   1/1     Running   0          32s
```

Bạn có thể thấy pod đang chạy, nhưng không thấy thêm nhiều thông tin khác.
Để xem thêm, bạn có thể thử **kubectl get pod -o wide** hoặc lệnh **kubectl describe** mà bạn đã học ở chương trước.

---

#### Sử dụng kubectl describe để xem chi tiết pod

Để hiển thị thông tin chi tiết hơn của pod, hãy dùng lệnh **kubectl describe**:

```bash
$ kubectl describe pod kiada
Name:         kiada
Namespace:    default
Priority:     0
Node:         worker2/172.18.0.4
Start Time:   Mon, 27 Jan 2020 12:53:28 +0100
...
```

Danh sách trên không hiển thị toàn bộ kết quả, nhưng nếu bạn tự chạy lệnh, bạn sẽ thấy hầu như toàn bộ thông tin mà bạn cũng có thể xem được khi in ra toàn bộ manifest của đối tượng bằng lệnh **kubectl get -o yaml**.

---

#### Kiểm tra các sự kiện để xem chuyện gì diễn ra bên dưới

Giống như ở chương trước khi bạn dùng **describe node** để kiểm tra một đối tượng Node, lệnh **describe pod** cũng sẽ hiển thị một số sự kiện liên quan đến pod ở cuối phần kết quả.

Hãy nhớ rằng các sự kiện này không phải là một phần của đối tượng pod, mà là các đối tượng riêng biệt. Hãy in chúng ra để tìm hiểu xem điều gì xảy ra khi bạn tạo pod. Dưới đây là các sự kiện được ghi lại sau khi pod được tạo:

```bash
$ kubectl get events
LAST SEEN   TYPE     REASON      OBJECT      MESSAGE
<unknown>   Normal   Scheduled   pod/kiada   Successfully assigned default/kiada to kind-worker2
5m          Normal   Pulling     pod/kiada   Pulling image luksa/kiada:0.1
5m          Normal   Pulled      pod/kiada   Successfully pulled image
5m          Normal   Created     pod/kiada   Created container kiada
5m          Normal   Started     pod/kiada   Started container kiada
```

Các sự kiện được in ra theo thứ tự thời gian. Sự kiện mới nhất nằm ở cuối.
Bạn thấy rằng pod được gán cho một node worker, sau đó image container được kéo về, rồi container được tạo và cuối cùng là khởi động thành công.

Không có sự kiện cảnh báo nào được hiển thị, vì vậy mọi thứ dường như ổn. Nếu trong cluster của bạn không như vậy, hãy đọc mục **5.4** để tìm hiểu cách xử lý sự cố pod thất bại.

---

### 5.3 Tương tác với ứng dụng và pod

Container của bạn hiện đang chạy. Trong phần này, bạn sẽ học cách giao tiếp với ứng dụng, kiểm tra log và thực thi lệnh trong container để khám phá môi trường của ứng dụng.
Hãy xác nhận rằng ứng dụng đang chạy trong container phản hồi lại yêu cầu của bạn.

---

#### 5.3.1 Gửi yêu cầu đến ứng dụng trong pod

Ở **chương 2**, bạn đã dùng lệnh **kubectl expose** để tạo một service cung cấp load balancer để bạn có thể giao tiếp với ứng dụng đang chạy trong pod của mình.
Bây giờ, chúng ta sẽ dùng một cách tiếp cận khác.
Trong quá trình phát triển, kiểm thử và gỡ lỗi, bạn có thể muốn giao tiếp trực tiếp với một pod cụ thể, thay vì dùng một service chuyển tiếp kết nối đến các pod được chọn ngẫu nhiên.

Bạn đã biết rằng mỗi pod được gán một địa chỉ IP riêng, nơi nó có thể được truy cập bởi mọi pod khác trong cluster.
Địa chỉ IP này thường là nội bộ của cluster. Bạn không thể truy cập nó từ máy tính cá nhân của mình, trừ khi Kubernetes được triển khai theo một cách cụ thể – ví dụ: khi dùng **kind** hoặc **Minikube** không chạy trong VM để tạo cluster.

Nói chung, để truy cập các pod, bạn phải dùng một trong các phương pháp được mô tả ở các phần sau.
Trước tiên, hãy xác định địa chỉ IP của pod.

---

#### Lấy địa chỉ IP của pod

Bạn có thể lấy địa chỉ IP của pod bằng cách lấy toàn bộ YAML của pod và tìm trường **podIP** trong phần **status**.
Ngoài ra, bạn có thể hiển thị IP bằng **kubectl describe**, nhưng cách dễ nhất là dùng **kubectl get** với tùy chọn **-o wide**:

```bash
$ kubectl get pod kiada -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP            NODE       ...
kiada   1/1     Running   0          35m   10.244.2.4    worker2    ...
```

Như trong cột **IP** cho thấy, IP của pod tôi là **10.244.2.4**.
Bây giờ tôi cần xác định số cổng mà ứng dụng đang lắng nghe.

---

#### Lấy số cổng mà ứng dụng sử dụng

Nếu tôi không phải là tác giả của ứng dụng, sẽ rất khó để biết ứng dụng đang lắng nghe ở cổng nào.
Tôi có thể kiểm tra mã nguồn hoặc Dockerfile của image container, vì cổng thường được chỉ định ở đó, nhưng tôi có thể không có quyền truy cập vào cả hai. Nếu người khác tạo pod, làm sao tôi biết nó đang nghe ở cổng nào?

May mắn thay, bạn có thể chỉ định danh sách cổng trong định nghĩa pod. Không bắt buộc phải chỉ định cổng nào, nhưng nên làm như vậy. Xem chi tiết trong phần bên dưới.

---

##### Tại sao nên chỉ định cổng container trong định nghĩa pod

Việc chỉ định cổng trong định nghĩa pod chỉ mang tính thông tin.
Việc bỏ qua cổng không ảnh hưởng đến khả năng client kết nối với cổng của pod.
Nếu container chấp nhận kết nối qua một cổng gắn với địa chỉ IP của nó, bất kỳ ai cũng có thể kết nối đến, ngay cả khi cổng đó không được chỉ định trong spec của pod hoặc nếu bạn chỉ định sai số cổng.

Dù vậy, việc luôn chỉ định cổng là một ý tưởng tốt để bất kỳ ai có quyền truy cập vào cluster cũng có thể thấy mỗi pod mở cổng nào.
Bằng cách định nghĩa rõ ràng các cổng, bạn cũng có thể gán tên cho từng cổng, rất hữu ích khi bạn expose pod qua service.

Manifest của pod cho biết container sử dụng cổng **8080**, vậy là bây giờ bạn có đủ thông tin để giao tiếp với ứng dụng.

---

#### Kết nối đến pod từ các node worker

Mô hình mạng của Kubernetes quy định rằng mỗi pod có thể được truy cập từ bất kỳ pod nào khác và mỗi node có thể truy cập bất kỳ pod nào trên bất kỳ node nào trong cluster.
Vì vậy, một cách để giao tiếp với pod là đăng nhập vào một node worker và kết nối đến pod từ đó.

Bạn đã học rằng cách đăng nhập vào node phụ thuộc vào công cụ bạn dùng để triển khai cluster:

* Nếu bạn dùng **kind**, chạy: `docker exec -it kind-worker bash`
* Nếu bạn dùng **Minikube**, chạy: `minikube ssh`
* Trên **GKE**, dùng lệnh `gcloud compute ssh`
* Với các cluster khác, tham khảo tài liệu của họ.

Khi đã đăng nhập vào node, dùng lệnh **curl** với IP và cổng của pod để truy cập ứng dụng.
IP pod của tôi là **10.244.2.4** và cổng là **8080**, vậy nên tôi chạy lệnh sau:

```bash
$ curl 10.244.2.4:8080
Kiada version 0.1. Request processed by "kiada". Client IP: ::ffff:10.244.2
```

Thông thường bạn không dùng cách này để giao tiếp với pod, nhưng bạn có thể cần dùng khi có sự cố kết nối và muốn tìm nguyên nhân bằng cách thử tuyến kết nối ngắn nhất.
Trong trường hợp này, tốt nhất là đăng nhập vào node nơi pod đang chạy và chạy **curl** từ đó. Kết nối giữa node và pod diễn ra nội bộ, nên phương pháp này luôn có tỷ lệ thành công cao nhất.


**Kết nối từ một pod client dùng một lần**
Cách thứ hai để kiểm tra khả năng kết nối của ứng dụng là chạy curl trong một pod khác mà bạn tạo ra chỉ cho nhiệm vụ này. Sử dụng phương pháp này để kiểm tra xem các pod khác có thể truy cập pod của bạn hay không. Ngay cả khi mạng hoạt động hoàn hảo, điều này có thể không đúng. Trong chương 24, bạn sẽ học cách khóa mạng bằng cách cô lập các pod với nhau. Trong một hệ thống như vậy, một pod chỉ có thể giao tiếp với các pod mà nó được phép.
Để chạy curl trong một pod dùng một lần, hãy sử dụng lệnh sau:

```bash
$ kubectl run --image=curlimages/curl -it --restart=Never --rm client-pod c
Kiada version 0.1. Request processed by "kiada". Client IP: ::ffff:10.244.2
pod "client-pod" deleted
```

Lệnh này chạy một pod với một container duy nhất được tạo từ image `curlimages/curl`. Bạn cũng có thể sử dụng bất kỳ image nào khác có cung cấp tệp thực thi `curl`. Tùy chọn `-it` gắn kết console của bạn với đầu vào và đầu ra chuẩn của container, tùy chọn `--restart=Never` đảm bảo rằng pod được coi là **Completed** khi lệnh curl và container của nó kết thúc, và tùy chọn `--rm` xóa pod khi kết thúc. Tên của pod là `client-pod` và lệnh được thực thi trong container của nó là `curl 10.244.2.4:8080`.

**Ghi chú**
Bạn cũng có thể sửa đổi lệnh để chạy shell bash trong pod client và sau đó chạy curl từ shell.

Việc tạo một pod chỉ để xem nó có thể truy cập pod khác hay không rất hữu ích khi bạn kiểm tra khả năng kết nối giữa các pod. Nếu bạn chỉ muốn biết pod của mình có phản hồi yêu cầu hay không, bạn cũng có thể sử dụng phương pháp được giải thích trong phần tiếp theo.

---

### Kết nối với các pod thông qua kubectl port forwarding

Trong quá trình phát triển, cách dễ nhất để trao đổi với các ứng dụng chạy trong pod của bạn là sử dụng lệnh `kubectl port-forward`, cho phép bạn giao tiếp với một pod cụ thể thông qua một proxy được gắn với cổng mạng trên máy tính cục bộ của bạn, như hình dưới đây.

**Hình 5.8 Kết nối đến một pod thông qua proxy kubectl port-forward**

![](https://img001.prntscr.com/file/img001/uAhuC8zaSeKZCFCiacXOww.png)
Để mở đường kết nối với một pod, bạn thậm chí không cần tra IP của pod, vì bạn chỉ cần chỉ định tên và cổng của nó. Lệnh sau đây khởi chạy một proxy chuyển tiếp cổng cục bộ 8080 trên máy của bạn đến cổng 8080 của pod `kiada`:

```bash
$ kubectl port-forward kiada 8080
... Forwarding from 127.0.0.1:8080 -> 8080
... Forwarding from [::1]:8080 -> 8080
```

Proxy giờ đây chờ các kết nối đến. Chạy lệnh curl sau trong một terminal khác:

```bash
$ curl localhost:8080
Kiada version 0.1. Request processed by "kiada". Client IP: ::ffff:127.0.0.
```

Như bạn thấy, curl đã kết nối với proxy cục bộ và nhận phản hồi từ pod. Mặc dù lệnh port-forward là phương pháp dễ nhất để giao tiếp với một pod cụ thể trong quá trình phát triển và xử lý sự cố, nhưng đây cũng là phương pháp phức tạp nhất về những gì diễn ra bên dưới. Giao tiếp đi qua nhiều thành phần, vì vậy nếu có gì đó hỏng trong đường kết nối, bạn sẽ không thể trao đổi với pod, ngay cả khi pod có thể truy cập được qua các kênh liên lạc thông thường.

**Ghi chú**
Lệnh `kubectl port-forward` cũng có thể chuyển tiếp kết nối đến các service thay vì pod và có nhiều tính năng hữu ích khác. Chạy `kubectl port-forward --help` để tìm hiểu thêm.

Hình 5.9 cho thấy cách các gói mạng di chuyển từ tiến trình curl đến ứng dụng của bạn và quay lại.

**Hình 5.9 Đường kết nối dài giữa curl và container khi sử dụng port forwarding**

![](https://img001.prntscr.com/file/img001/HsE_nm9MTt2ZUbrZPl7-qQ.png)

Như hình minh họa, tiến trình curl kết nối đến proxy, proxy kết nối đến API server, sau đó kết nối đến Kubelet trên node lưu trữ pod, và Kubelet kết nối đến container thông qua thiết bị loopback của pod (nói cách khác, qua địa chỉ localhost). Bạn sẽ đồng ý rằng đường kết nối này cực kỳ dài.

**Ghi chú**
Ứng dụng trong container phải được gắn với một cổng trên thiết bị loopback để Kubelet có thể kết nối tới nó. Nếu ứng dụng chỉ lắng nghe trên giao diện mạng eth0 của pod, bạn sẽ không thể truy cập nó bằng lệnh `kubectl port-forward`.

---

## 5.3.2 Xem log của ứng dụng

Ứng dụng Node.js của bạn ghi log ra luồng đầu ra chuẩn. Thay vì ghi log ra tệp, các ứng dụng được container hóa thường ghi log ra **standard output (stdout)** và **standard error (stderr)**. Điều này cho phép trình chạy container chặn đầu ra, lưu trữ nó ở một vị trí nhất quán (thường là `/var/log/containers`) và cung cấp quyền truy cập log mà không cần biết từng ứng dụng lưu log ở đâu.

Khi bạn chạy ứng dụng trong container bằng Docker, bạn có thể hiển thị log bằng `docker logs <container-id>`. Khi bạn chạy ứng dụng trong Kubernetes, bạn có thể đăng nhập vào node lưu trữ pod và hiển thị log bằng `docker logs`, nhưng Kubernetes cung cấp cách dễ dàng hơn với lệnh `kubectl logs`.

---

### Lấy log của pod bằng kubectl logs

Để xem log của pod (chính xác hơn là log của container), chạy lệnh sau:

```bash
$ kubectl logs kiada
Kiada - Kubernetes in Action Demo Application
---------------------------------------------
Kiada 0.1 starting...
Local hostname is kiada
Listening on port 8080
Received request for / from ::ffff:10.244.2.1 #A
Received request for / from ::ffff:10.244.2.5 #B
Received request for / from ::ffff:127.0.0.1 #C
```

---

### Truyền log trực tiếp bằng kubectl logs -f

Nếu bạn muốn truyền log của ứng dụng theo thời gian thực để xem từng yêu cầu khi nó đến, bạn có thể chạy lệnh với tùy chọn `--follow` (hoặc viết tắt `-f`):

```bash
$ kubectl logs kiada -f
```

Bây giờ hãy gửi thêm một số yêu cầu đến ứng dụng và xem log. Nhấn **ctrl-C** để dừng truyền log khi bạn xong.

---

### Hiển thị dấu thời gian của từng dòng log

Bạn có thể nhận thấy rằng chúng ta quên đưa dấu thời gian vào câu lệnh log. Log không có dấu thời gian bị hạn chế về khả năng sử dụng. May mắn thay, trình chạy container tự động gắn dấu thời gian hiện tại vào mỗi dòng mà ứng dụng tạo ra. Bạn có thể hiển thị các dấu thời gian này bằng cách sử dụng tùy chọn `--timestamps=true` như sau:

```bash
$ kubectl logs kiada --timestamps=true
2020-02-01T09:44:40.954641934Z Kiada - Kubernetes in Action Demo Applicatio
2020-02-01T09:44:40.954843234Z --------------------------------------------
2020-02-01T09:44:40.955032432Z Kiada 0.1 starting...
2020-02-01T09:44:40.955123432Z Local hostname is kiada
2020-02-01T09:44:40.956435431Z Listening on port 8080
2020-02-01T09:50:04.978043089Z Received request for / from ...
2020-02-01T09:50:33.640897378Z Received request for / from ...
2020-02-01T09:50:44.781473256Z Received request for / from ...
```

**Mẹo**
Bạn có thể hiển thị dấu thời gian chỉ bằng cách gõ `--timestamps` mà không cần giá trị. Đối với các tùy chọn boolean, chỉ cần chỉ định tên tùy chọn là giá trị sẽ được đặt thành true. Điều này áp dụng cho tất cả các tùy chọn kubectl có giá trị boolean và mặc định là false.

---

### Hiển thị log gần đây

Tính năng trước rất hữu ích nếu bạn chạy các ứng dụng của bên thứ ba không có dấu thời gian trong log, nhưng thực tế mỗi dòng đều có dấu thời gian mang lại một lợi ích khác: lọc log theo thời gian. Kubectl cung cấp hai cách lọc log theo thời gian.

Cách đầu tiên là chỉ hiển thị log trong vài giây, phút hoặc giờ trước. Ví dụ, để xem log được tạo trong hai phút vừa qua, chạy:

```bash
$ kubectl logs kiada --since=2m
```

Cách thứ hai là hiển thị log được tạo sau một ngày giờ cụ thể bằng tùy chọn `--since-time`. Định dạng thời gian được sử dụng là RFC3339. Ví dụ, lệnh sau dùng để in log được tạo sau 9:50 sáng ngày 1 tháng 2 năm 2020:

```bash
$ kubectl logs kiada --since-time=2020-02-01T09:50:00Z
```

---

### Hiển thị một vài dòng log cuối cùng

Thay vì lọc theo thời gian, bạn cũng có thể chỉ định số dòng cuối của log mà bạn muốn hiển thị. Để hiển thị mười dòng cuối cùng, hãy thử:

```bash
$ kubectl logs kiada --tail=10
```

**Ghi chú**
Các tùy chọn kubectl nhận giá trị có thể được chỉ định bằng dấu bằng hoặc bằng khoảng trắng. Thay vì `--tail=10`, bạn cũng có thể gõ `--tail 10`.

---

### Hiểu về khả năng truy cập log của pod

Kubernetes lưu một tệp log riêng cho từng container. Chúng thường được lưu ở `/var/log/containers` trên node chạy container. Một tệp riêng được tạo cho mỗi container. Nếu container khởi động lại, log của nó được ghi vào một tệp mới. Vì vậy, nếu container khởi động lại trong khi bạn đang theo dõi log với `kubectl logs -f`, lệnh sẽ kết thúc và bạn cần chạy lại để truyền log của container mới.

Lệnh `kubectl logs` chỉ hiển thị log của container hiện tại. Để xem log từ container trước đó, sử dụng tùy chọn `--previous` (hoặc `-p`).

**Ghi chú**
Tùy thuộc vào cấu hình cluster, các tệp log cũng có thể được xoay vòng khi đạt đến một kích thước nhất định. Trong trường hợp này, `kubectl logs` chỉ hiển thị tệp log hiện tại. Khi truyền log, bạn phải khởi động lại lệnh để chuyển sang tệp mới khi log được xoay vòng.

Khi bạn xóa một pod, tất cả các tệp log của nó cũng bị xóa. Để giữ log của pod vĩnh viễn, bạn cần thiết lập một hệ thống log tập trung cho toàn cluster. Chương 23 sẽ giải thích cách làm.

---

### Còn các ứng dụng ghi log vào tệp thì sao?

Nếu ứng dụng của bạn ghi log vào tệp thay vì stdout, bạn có thể tự hỏi làm cách nào để truy cập tệp đó. Lý tưởng nhất là bạn cấu hình hệ thống log tập trung để thu thập log để bạn có thể xem chúng ở một vị trí tập trung, nhưng đôi khi bạn chỉ muốn giữ mọi thứ đơn giản và không ngại truy cập log thủ công. Trong hai phần tiếp theo, bạn sẽ học cách sao chép log và các tệp khác từ container về máy tính của mình và ngược lại, cũng như cách chạy lệnh trong các container đang chạy. Bạn có thể sử dụng bất kỳ phương pháp nào để hiển thị các tệp log hoặc bất kỳ tệp nào khác bên trong container.


### **5.3.3 Sao chép tệp vào và ra khỏi container**
Đôi khi bạn có thể muốn thêm một tệp vào một container đang chạy hoặc lấy một tệp từ đó. Việc chỉnh sửa tệp trong các container đang chạy thường không phải là điều bạn làm — ít nhất là không phải trong môi trường production — nhưng nó có thể hữu ích trong quá trình phát triển.

Kubectl cung cấp lệnh **cp** để sao chép tệp hoặc thư mục từ máy tính cục bộ của bạn vào container của bất kỳ pod nào hoặc từ container về máy tính của bạn.

Ví dụ, nếu bạn muốn chỉnh sửa tệp HTML mà pod **kiada** đang phục vụ, bạn có thể sử dụng lệnh sau để sao chép nó về hệ thống tệp cục bộ:

```bash
$ kubectl cp kiada:html/index.html /tmp/index.html
```

Lệnh này sao chép tệp **/html/index.html** từ pod có tên **kiada** về tệp **/tmp/index.html** trên máy tính của bạn. Bây giờ bạn có thể chỉnh sửa tệp này trên máy cục bộ. Sau khi hài lòng với các thay đổi, hãy sao chép tệp này trở lại container bằng lệnh sau:

```bash
$ kubectl cp /tmp/index.html kiada:html/
```

Nhấn **refresh** trong trình duyệt của bạn và bạn sẽ thấy các thay đổi vừa thực hiện.

**Lưu ý**
Lệnh **kubectl cp** yêu cầu binary **tar** phải có trong container của bạn, nhưng yêu cầu này có thể thay đổi trong tương lai.

---

### **5.3.4 Thực thi lệnh trong các container đang chạy**
Khi gỡ lỗi một ứng dụng đang chạy trong container, có thể cần phải kiểm tra container và môi trường của nó từ bên trong. **Kubectl** cũng cung cấp chức năng này. Bạn có thể thực thi bất kỳ tệp nhị phân nào có trong hệ thống tệp của container bằng lệnh **kubectl exec**.

### Gọi một lệnh duy nhất trong container

Ví dụ, bạn có thể liệt kê các tiến trình đang chạy trong container của pod **kiada** bằng cách chạy lệnh sau:

```bash
$ kubectl exec kiada -- ps aux
USER   PID  %CPU %MEM    VSZ   RSS TTY   STAT START   TIME COMMAND
root     1  0.0  1.3 812860 27356 ?     Ssl  11:54   0:00 node app.js  #A
root   120  0.0  0.1  17500  2128 ?     Rs   12:22   0:00 ps aux        #B
```

Đây là lệnh tương đương trong Kubernetes với lệnh **Docker** mà bạn đã dùng để kiểm tra các tiến trình trong một container đang chạy ở chương 2. Nó cho phép bạn chạy lệnh từ xa trong bất kỳ pod nào mà không cần đăng nhập vào node đang chứa pod đó. Nếu bạn đã từng sử dụng **ssh** để thực thi lệnh trên một hệ thống từ xa, bạn sẽ thấy **kubectl exec** không khác nhiều.

Trong phần 5.3.1, bạn đã thực thi lệnh **curl** trong một pod client chạy một lần để gửi yêu cầu đến ứng dụng của bạn, nhưng bạn cũng có thể chạy lệnh bên trong chính pod **kiada**:

```bash
$ kubectl exec kiada -- curl -s localhost:8080
Kiada version 0.1. Request processed by "kiada". Client IP: ::1
```

---

### Tại sao sử dụng hai dấu gạch ngang trong lệnh kubectl exec?

Hai dấu gạch ngang (**--**) trong lệnh phân cách các tham số của **kubectl** với lệnh sẽ được thực thi trong container. Việc sử dụng hai dấu gạch ngang không cần thiết nếu lệnh không có tham số nào bắt đầu bằng dấu gạch ngang.

Nếu bạn bỏ qua hai dấu gạch ngang trong ví dụ trước, tùy chọn **-s** sẽ được hiểu là một tùy chọn của **kubectl exec** và dẫn đến lỗi gây hiểu nhầm như sau:

```bash
$ kubectl exec kiada curl -s localhost:8080
The connection to the server localhost:8080 was refused – did you specify t
```

Nhìn vào có vẻ như máy chủ Node.js từ chối kết nối, nhưng vấn đề lại nằm ở chỗ khác. Lệnh **curl** chưa bao giờ được thực thi. Lỗi này được báo cáo bởi **kubectl** khi nó cố gắng kết nối với **Kubernetes API server** tại **localhost:8080**, nơi mà máy chủ thực sự không chạy ở đó.

Nếu bạn chạy lệnh **kubectl options**, bạn sẽ thấy rằng tùy chọn **-s** có thể được dùng để chỉ định địa chỉ và cổng của **Kubernetes API server**. Thay vì chuyển tùy chọn đó cho **curl**, **kubectl** lại nhận nó như là của chính nó. Thêm hai dấu gạch ngang sẽ ngăn điều này.

May mắn thay, để tránh tình huống như vậy, các phiên bản **kubectl** mới hơn sẽ trả về lỗi nếu bạn quên thêm hai dấu gạch ngang.

---

### Chạy một shell tương tác trong container

Hai ví dụ trước cho thấy cách một lệnh duy nhất có thể được thực thi trong container. Khi lệnh hoàn thành, bạn sẽ được trả về shell của mình. Nếu bạn muốn chạy nhiều lệnh trong container, bạn có thể chạy một shell trong container như sau:

```bash
$ kubectl exec -it kiada -- bash
root@kiada:/#    #A
```

Tham số **-it** là viết tắt của hai tùy chọn: **-i** và **-t**, biểu thị rằng bạn muốn thực thi lệnh **bash** một cách tương tác bằng cách truyền **standard input** vào container và đánh dấu nó như một **terminal (TTY)**.

Bây giờ bạn có thể khám phá bên trong container bằng cách thực thi các lệnh trong shell. Ví dụ, bạn có thể xem các tệp trong container bằng lệnh **ls -la**, xem các giao diện mạng với **ip link**, hoặc kiểm tra kết nối với **ping**. Bạn có thể chạy bất kỳ công cụ nào có trong container.

---

### Không phải tất cả container đều cho phép bạn chạy shell

Image container của ứng dụng của bạn có chứa nhiều công cụ gỡ lỗi quan trọng, nhưng điều này không đúng với mọi image container. Để giữ cho image nhỏ và tăng cường bảo mật trong container, hầu hết các container sử dụng trong môi trường production không chứa bất kỳ tệp nhị phân nào khác ngoài những tệp cần thiết cho tiến trình chính của container. Điều này giúp giảm đáng kể bề mặt tấn công, nhưng cũng có nghĩa là bạn không thể chạy shell hoặc các công cụ khác trong container production.

May mắn thay, một tính năng mới của Kubernetes gọi là **ephemeral containers** cho phép bạn gỡ lỗi các container đang chạy bằng cách gắn một container gỡ lỗi vào chúng.

---

### Ghi chú cho độc giả MEAP

**Ephemeral containers** hiện tại là một tính năng **alpha**, nghĩa là chúng có thể thay đổi hoặc thậm chí bị loại bỏ bất kỳ lúc nào. Đây cũng là lý do tại sao chúng hiện chưa được giải thích trong cuốn sách này. Nếu chúng được nâng cấp lên **beta** trước khi cuốn sách xuất bản, một phần giải thích về chúng sẽ được thêm vào.

### 5.3.5 Gắn vào một container đang chạy

Lệnh `kubectl attach` là một cách khác để tương tác với một container đang chạy. Nó gắn kết vào các luồng đầu vào, đầu ra và lỗi chuẩn của tiến trình chính đang chạy trong container. Thông thường, bạn chỉ sử dụng nó để tương tác với các ứng dụng đọc từ đầu vào chuẩn.

#### Sử dụng kubectl attach để xem ứng dụng in ra đầu ra chuẩn

Nếu ứng dụng không đọc từ đầu vào chuẩn, lệnh `kubectl attach` chẳng khác gì một cách thay thế để truyền tải nhật ký của ứng dụng, vì chúng thường được ghi vào các luồng đầu ra và lỗi chuẩn, và lệnh `attach` truyền chúng giống hệt như lệnh `kubectl logs -f`.

Gắn vào pod kiada của bạn bằng cách chạy lệnh sau:

```bash
$ kubectl attach kiada
Defaulting container name to kiada.
Use 'kubectl describe pod/kiada -n default' to see all of the containers in
```

Nếu bạn không thấy dấu nhắc lệnh, hãy thử nhấn ENTER.

Bây giờ, khi bạn gửi các yêu cầu HTTP mới đến ứng dụng bằng `curl` trong một terminal khác, bạn sẽ thấy các dòng mà ứng dụng ghi vào đầu ra chuẩn cũng được in trong terminal nơi lệnh `kubectl attach` được thực thi.

---

#### Sử dụng kubectl attach để ghi vào đầu vào chuẩn của ứng dụng

Ứng dụng Kiada phiên bản 0.1 không đọc từ luồng đầu vào chuẩn, nhưng bạn sẽ tìm thấy mã nguồn của phiên bản 0.2 có thực hiện việc này trong kho mã của sách. Phiên bản này cho phép bạn đặt một thông báo trạng thái bằng cách ghi nó vào luồng đầu vào chuẩn của ứng dụng. Thông báo trạng thái này sẽ được bao gồm trong phản hồi của ứng dụng. Hãy triển khai phiên bản này của ứng dụng trong một pod mới và sử dụng lệnh `kubectl attach` để đặt thông báo trạng thái.

Bạn có thể tìm các artifact cần thiết để xây dựng image trong thư mục `kiada-0.2/`. Bạn cũng có thể sử dụng image dựng sẵn `docker.io/luksa/kiada:0.2`. Tệp manifest của pod nằm trong tệp `Chapter05/pod.kiada-stdin.yaml` và được hiển thị trong danh sách sau. Nó chứa một dòng bổ sung so với manifest trước đó (dòng này được đánh dấu trong danh sách).

**Danh sách 5.2 Bật đầu vào chuẩn cho một container**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kiada-stdin #A
spec:
  containers:
  - name: kiada
    image: luksa/kiada:0.2 #B
    stdin: true #C
    ports:
    - containerPort: 8080
```

Như bạn có thể thấy trong danh sách, nếu ứng dụng chạy trong pod muốn đọc từ đầu vào chuẩn, bạn phải chỉ định điều này trong manifest của pod bằng cách đặt trường `stdin` trong định nghĩa container thành `true`. Điều này yêu cầu Kubernetes cấp phát một bộ đệm cho luồng đầu vào chuẩn, nếu không ứng dụng sẽ luôn nhận được EOF khi cố gắng đọc từ nó.

Tạo pod từ tệp manifest này với lệnh `kubectl apply`:

```bash
$ kubectl apply -f pod.kiada-stdin.yaml
pod/kiada-stdin created
```

Để bật giao tiếp với ứng dụng, hãy sử dụng lại lệnh `kubectl port-forward`, nhưng vì cổng cục bộ 8080 vẫn đang được sử dụng bởi lệnh `port-forward` trước đó, bạn phải hoặc dừng nó hoặc chọn một cổng cục bộ khác để chuyển tiếp đến pod mới. Bạn có thể làm như sau:

```bash
$ kubectl port-forward kiada-stdin 8888:8080
Forwarding from 127.0.0.1:8888 -> 8080
Forwarding from [::1]:8888 -> 8080
```

Đối số dòng lệnh `8888:8080` yêu cầu lệnh chuyển tiếp cổng cục bộ 8888 đến cổng 8080 của pod.

Bây giờ bạn có thể truy cập ứng dụng tại `http://localhost:8888`:

```bash
$ curl localhost:8888
Kiada version 0.2. Request processed by "kiada-stdin". Client IP: ::ffff:12
```

Hãy đặt thông báo trạng thái bằng cách sử dụng `kubectl attach` để ghi vào luồng đầu vào chuẩn của ứng dụng. Chạy lệnh sau:

```bash
$ kubectl attach -i kiada-stdin
```

Lưu ý việc sử dụng tùy chọn bổ sung `-i` trong lệnh. Nó yêu cầu `kubectl` truyền đầu vào chuẩn của nó đến container.

> **Lưu ý**
> Giống như lệnh `kubectl exec`, `kubectl attach` cũng hỗ trợ tùy chọn `--tty` hoặc `-t`, cho biết rằng đầu vào chuẩn là một terminal (TTY), nhưng container phải được cấu hình để cấp phát một terminal thông qua trường `tty` trong định nghĩa container.

Bây giờ bạn có thể nhập thông báo trạng thái vào terminal và nhấn phím ENTER. Ví dụ, gõ thông điệp sau:

```
This is my custom status message.
```

Ứng dụng in thông điệp mới ra đầu ra chuẩn:

```
Status message set to: This is my custom status message.
```

Để xem ứng dụng hiện có bao gồm thông điệp này trong phản hồi của nó với các yêu cầu HTTP hay không, hãy chạy lại lệnh `curl` hoặc làm mới trang trong trình duyệt web của bạn:

```bash
$ curl localhost:8888
Kiada version 0.2. Request processed by "kiada-stdin". Client IP: ::ffff:12
This is my custom status message. #A
```

Bạn có thể thay đổi thông báo trạng thái một lần nữa bằng cách nhập một dòng khác trong terminal đang chạy lệnh `kubectl attach`. Để thoát lệnh `attach`, nhấn `Control-C` hoặc phím tương đương.

> **Lưu ý**
> Một trường bổ sung trong định nghĩa container, `stdinOnce`, xác định liệu kênh đầu vào chuẩn có bị đóng khi phiên attach kết thúc hay không. Mặc định nó được đặt thành `false`, cho phép bạn sử dụng đầu vào chuẩn trong mọi phiên `kubectl attach`. Nếu bạn đặt nó thành `true`, đầu vào chuẩn chỉ mở trong phiên đầu tiên.

---

### 5.4 Chạy nhiều container trong một pod

Ứng dụng Kiada mà bạn triển khai trong mục 5.2 chỉ hỗ trợ HTTP. Hãy thêm hỗ trợ TLS để nó cũng có thể phục vụ khách hàng qua HTTPS. Bạn có thể làm điều này bằng cách thêm mã vào tệp `app.js`, nhưng có một tùy chọn dễ dàng hơn mà bạn không cần chỉnh sửa mã chút nào.

Bạn có thể chạy một reverse proxy cùng với ứng dụng Node.js trong một container sidecar, như đã giải thích trong mục 5.1.2, và để nó xử lý các yêu cầu HTTPS thay mặt cho ứng dụng. Một gói phần mềm rất phổ biến có thể cung cấp chức năng này là **Envoy**. Envoy proxy là một proxy dịch vụ hiệu năng cao mã nguồn mở ban đầu được xây dựng bởi Lyft và sau đó đã được đóng góp cho **Cloud Native Computing Foundation**. Hãy thêm nó vào pod của bạn.


### 5.4.1 Mở rộng ứng dụng Kiada Node.js bằng Envoy proxy

Hãy để tôi giải thích ngắn gọn về kiến trúc mới của ứng dụng sẽ trông như thế nào. Như được minh họa trong hình tiếp theo, pod sẽ có hai container – container Node.js và container Envoy mới. Container Node.js sẽ tiếp tục xử lý các yêu cầu HTTP trực tiếp, nhưng các yêu cầu HTTPS sẽ được xử lý bởi Envoy. Với mỗi yêu cầu HTTPS đến, Envoy sẽ tạo một yêu cầu HTTP mới và sau đó gửi nó đến ứng dụng Node.js thông qua thiết bị loopback cục bộ (thông qua địa chỉ IP localhost).

**Hình 5.10**: Chi tiết về các container và giao diện mạng của pod


![](https://img001.prntscr.com/file/img001/Kmvg_nIESaOXiQB12xJIAg.png)
Envoy cũng cung cấp một giao diện quản trị dựa trên web, điều này sẽ hữu ích trong một số bài tập ở chương tiếp theo.

Rõ ràng nếu bạn triển khai hỗ trợ TLS trực tiếp trong ứng dụng Node.js, ứng dụng sẽ tiêu tốn ít tài nguyên tính toán hơn và có độ trễ thấp hơn vì không cần thêm một bước mạng bổ sung nào, nhưng việc thêm Envoy proxy có thể là một giải pháp nhanh và dễ dàng hơn. Nó cũng cung cấp một điểm khởi đầu tốt để bạn có thể thêm nhiều tính năng khác do Envoy cung cấp mà bạn có thể sẽ không bao giờ triển khai trong mã nguồn ứng dụng. Tham khảo tài liệu Envoy proxy tại **envoyproxy.io** để tìm hiểu thêm.

---

### 5.4.2 Thêm Envoy proxy vào pod

Bạn sẽ tạo một pod mới với hai container. Bạn đã có container Node.js, nhưng bạn cũng cần một container để chạy Envoy.

#### Tạo image cho Envoy container

Các tác giả của Envoy proxy đã xuất bản image chính thức của Envoy proxy trên Docker Hub. Bạn có thể sử dụng image này trực tiếp, nhưng bạn sẽ cần cung cấp tệp cấu hình, chứng chỉ và khóa riêng cho tiến trình Envoy trong container. Bạn sẽ học cách thực hiện điều này ở chương 7. Hiện tại, bạn sẽ sử dụng một image đã có sẵn cả ba tệp này.

Tôi đã tạo sẵn image và cung cấp tại **docker.io/luksa/kiada-ssl-proxy:0.1**, nhưng nếu bạn muốn tự xây dựng, bạn có thể tìm thấy các tệp trong thư mục **kiada-ssl-proxy-image** trong kho mã nguồn đi kèm với sách.

Thư mục này chứa **Dockerfile**, cũng như khóa riêng và chứng chỉ mà proxy sẽ dùng để cung cấp HTTPS. Nó cũng chứa tệp cấu hình **envoy.conf**. Trong đó, bạn sẽ thấy proxy được cấu hình để lắng nghe trên cổng **8443**, chấm dứt TLS và chuyển tiếp các yêu cầu đến cổng **8080** trên localhost, nơi ứng dụng Node.js đang lắng nghe. Proxy cũng được cấu hình để cung cấp giao diện quản trị trên cổng **9901**, như đã giải thích trước đó.

#### Tạo manifest cho pod

Sau khi xây dựng image, bạn phải tạo manifest cho pod mới. Danh sách sau đây cho thấy nội dung của tệp manifest **pod.kiada-ssl.yaml**:

**Listing 5.3** Manifest của pod kiada-ssl

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kiada-ssl
spec:
  containers:
  - name: kiada #A
    image: luksa/kiada:0.2 #A
    ports: #A
    - name: http #A
      containerPort: 8080 #A
  - name: envoy #B
    image: luksa/kiada-ssl-proxy:0.1 #B
    ports: #B
    - name: https #B
      containerPort: 8443 #B
    - name: admin #B
      containerPort: 9901 #B
```

Tên của pod này là **kiada-ssl**. Nó có hai container: **kiada** và **envoy**. Manifest chỉ phức tạp hơn một chút so với manifest ở mục 5.2.1. Các trường mới duy nhất là **tên các cổng**, được thêm vào để bất kỳ ai đọc manifest có thể hiểu được ý nghĩa của từng số cổng.

#### Tạo pod

Tạo pod từ manifest bằng lệnh:

```
kubectl apply -f pod.kiada-ssl.yaml
```

Sau đó sử dụng các lệnh

```
kubectl get
kubectl describe
```

để xác nhận rằng các container của pod đã được khởi chạy thành công.

---

### 5.4.3 Tương tác với pod có hai container

Khi pod khởi động, bạn có thể bắt đầu sử dụng ứng dụng trong pod, kiểm tra nhật ký và khám phá các container từ bên trong.

#### Giao tiếp với ứng dụng

Như trước đây, bạn có thể sử dụng **kubectl port-forward** để kích hoạt giao tiếp với ứng dụng trong pod. Vì nó mở ba cổng khác nhau, bạn sẽ kích hoạt chuyển tiếp đến cả ba cổng như sau:

```
$ kubectl port-forward kiada-ssl 8080 8443 9901
Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080
Forwarding from 127.0.0.1:8443 -> 8443
Forwarding from [::1]:8443 -> 8443
Forwarding from 127.0.0.1:9901 -> 9901
Forwarding from [::1]:9901 -> 9901
```

Trước tiên, hãy xác nhận rằng bạn có thể giao tiếp với ứng dụng qua HTTP bằng cách mở URL

```
http://localhost:8080
```

trong trình duyệt hoặc sử dụng **curl**:

```
$ curl localhost:8080
Kiada version 0.2. Request processed by "kiada-ssl". Client IP: ::ffff:127.
```

Nếu điều này hoạt động, bạn cũng có thể thử truy cập ứng dụng qua HTTPS tại

```
https://localhost:8443
```

Với **curl**, bạn có thể làm như sau:

```
$ curl https://localhost:8443 --insecure
Kiada version 0.2. Request processed by "kiada-ssl". Client IP: ::ffff:127.
```

Thành công! Envoy proxy xử lý tác vụ một cách hoàn hảo. Ứng dụng của bạn giờ đã hỗ trợ HTTPS bằng container sidecar.

---

#### Tại sao sử dụng tùy chọn --insecure?

Có hai lý do để sử dụng tùy chọn **--insecure** khi truy cập dịch vụ. Chứng chỉ được Envoy proxy sử dụng là **self-signed** và được phát hành cho tên miền **example.com**. Bạn đang truy cập dịch vụ thông qua **localhost**, nơi tiến trình **kubectl proxy** cục bộ đang lắng nghe. Do đó, **tên máy chủ** không khớp với tên trong chứng chỉ máy chủ.

Để làm cho tên khớp nhau, bạn có thể yêu cầu **curl** gửi yêu cầu đến **example.com**, nhưng phân giải nó thành **127.0.0.1** bằng cờ **--resolve**. Điều này sẽ đảm bảo chứng chỉ khớp với URL được yêu cầu, nhưng vì chứng chỉ của máy chủ là **self-signed**, **curl** vẫn sẽ không chấp nhận nó là hợp lệ. Bạn có thể khắc phục bằng cách nói với **curl** chứng chỉ cần sử dụng để xác minh máy chủ với cờ **--cacert**. Toàn bộ lệnh sẽ như sau:

```
$ curl https://example.com:8443 --resolve example.com:8443:127.0.0.1 --cacert ...
```

Đó là quá nhiều thao tác. Đó là lý do tại sao tôi thích sử dụng tùy chọn **--insecure** hoặc dạng ngắn hơn là **-k**.

---

#### Hiển thị nhật ký của pod với nhiều container

Pod **kiada-ssl** có hai container, vì vậy nếu bạn muốn hiển thị nhật ký, bạn phải chỉ định tên container bằng tùy chọn **--container** hoặc **-c**. Ví dụ, để xem nhật ký của container **kiada**, chạy lệnh:

```
$ kubectl logs kiada-ssl -c kiada
```

Envoy proxy chạy trong container tên **envoy**, nên bạn hiển thị nhật ký của nó như sau:

```
$ kubectl logs kiada-ssl -c envoy
```

Ngoài ra, bạn có thể hiển thị nhật ký của cả hai container bằng tùy chọn **--all-containers**:

```
$ kubectl logs kiada-ssl --all-containers
```

Bạn cũng có thể kết hợp các lệnh này với các tùy chọn khác được giải thích ở mục 5.3.2.

---

#### Chạy lệnh trong các container của pod nhiều container

Nếu bạn muốn chạy shell hoặc lệnh khác trong một container của pod bằng lệnh **kubectl exec**, bạn cũng chỉ định tên container bằng tùy chọn **--container** hoặc **-c**. Ví dụ, để chạy shell bên trong container **envoy**, chạy lệnh:

```
$ kubectl exec -it kiada-ssl -c envoy -- bash
```

**Lưu ý**
Nếu bạn không cung cấp tên container, **kubectl exec** mặc định sẽ sử dụng container đầu tiên được chỉ định trong manifest của pod.


5.5 Chạy các container bổ sung khi khởi động pod
Khi một pod chứa nhiều hơn một container, tất cả các container sẽ được khởi động song song. Kubernetes hiện chưa cung cấp cơ chế để xác định xem một container có phụ thuộc vào container khác hay không, điều này sẽ cho phép bạn đảm bảo container này được khởi động trước container kia. Tuy nhiên, Kubernetes cho phép bạn chạy một chuỗi container để khởi tạo pod trước khi các container chính của nó bắt đầu. Loại container đặc biệt này sẽ được giải thích trong phần này.

### 5.5.1 Giới thiệu về init container

Một manifest pod có thể chỉ định một danh sách container chạy khi pod khởi động và trước khi các container thông thường của pod được khởi động. Những container này được thiết kế để khởi tạo pod và được gọi là init container. Như hình dưới đây cho thấy, chúng chạy lần lượt từng cái một và tất cả phải hoàn thành thành công trước khi các container chính của pod được khởi động.

**Hình 5.11** Trình tự thời gian cho thấy cách init container và container thông thường của pod được khởi động

![](https://img001.prntscr.com/file/img001/0Irh5bz8STO9Nc0JPE9XnQ.png)

Init container giống như các container thông thường của pod, nhưng chúng không chạy song song – chỉ có một init container chạy tại một thời điểm.

#### Hiểu init container có thể làm gì

Init container thường được thêm vào pod để thực hiện những việc sau:

* **Khởi tạo các tệp trong các volume** được sử dụng bởi các container chính của pod. Điều này bao gồm việc lấy chứng chỉ và khóa riêng được sử dụng bởi container chính từ các kho lưu trữ chứng chỉ an toàn, tạo tệp cấu hình, tải dữ liệu, v.v.
* **Khởi tạo hệ thống mạng của pod.** Vì tất cả các container của pod chia sẻ cùng một network namespace và do đó là các giao diện và cấu hình mạng, mọi thay đổi được thực hiện bởi init container cũng sẽ ảnh hưởng đến container chính.
* **Trì hoãn việc khởi động các container chính** cho đến khi điều kiện tiên quyết được đáp ứng. Ví dụ, nếu container chính phụ thuộc vào một dịch vụ khác phải khả dụng trước khi container được khởi động, một init container có thể chặn cho đến khi dịch vụ này sẵn sàng.
* **Thông báo cho một dịch vụ bên ngoài** rằng pod sắp bắt đầu chạy. Trong các trường hợp đặc biệt khi một hệ thống bên ngoài phải được thông báo khi một phiên bản mới của ứng dụng được khởi chạy, một init container có thể được sử dụng để gửi thông báo này.

Bạn có thể thực hiện những thao tác này ngay trong container chính, nhưng sử dụng init container đôi khi là lựa chọn tốt hơn và có thể mang lại những lợi ích khác. Hãy xem lý do tại sao.

#### Hiểu khi nào nên chuyển mã khởi tạo sang init container

Sử dụng init container để thực hiện các tác vụ khởi tạo **không yêu cầu phải xây dựng lại image của container chính** và cho phép một image init container duy nhất có thể được tái sử dụng với nhiều ứng dụng khác nhau. Điều này đặc biệt hữu ích nếu bạn muốn chèn cùng một đoạn mã khởi tạo dành riêng cho hạ tầng vào tất cả các pod của mình.

Việc sử dụng init container cũng đảm bảo rằng quá trình khởi tạo này hoàn tất **trước khi bất kỳ container chính nào (có thể là nhiều container) được khởi động**.

Một lý do quan trọng khác là **bảo mật**. Bằng cách di chuyển các công cụ hoặc dữ liệu có thể bị kẻ tấn công lợi dụng để xâm nhập cụm khỏi container chính sang init container, bạn giảm bề mặt tấn công của pod.

Ví dụ, hãy tưởng tượng rằng pod phải được đăng ký với một hệ thống bên ngoài. Pod cần một loại token bí mật để xác thực với hệ thống này. Nếu quy trình đăng ký được thực hiện bởi container chính, token bí mật này phải có mặt trong filesystem của nó. Nếu ứng dụng chạy trong container chính có lỗ hổng cho phép kẻ tấn công đọc các tệp tùy ý trên filesystem, kẻ tấn công có thể lấy được token này. Bằng cách thực hiện đăng ký từ một init container, token chỉ cần có mặt trong filesystem của init container, thứ mà kẻ tấn công khó có thể xâm phạm.

---

### 5.5.2 Thêm init container vào một pod

Trong manifest pod, các init container được định nghĩa trong trường **initContainers** của phần **spec**, giống như cách các container thông thường được định nghĩa trong trường **containers**.

#### Định nghĩa init container trong manifest pod

Hãy xem một ví dụ về việc thêm hai init container vào pod **kiada**.

* Init container đầu tiên mô phỏng một quy trình khởi tạo. Nó chạy trong 5 giây, trong khi in một vài dòng văn bản ra output chuẩn.
* Init container thứ hai thực hiện kiểm tra kết nối mạng bằng cách sử dụng lệnh **ping** để kiểm tra xem một địa chỉ IP cụ thể có thể truy cập được từ trong pod hay không. Địa chỉ IP này có thể cấu hình được thông qua đối số dòng lệnh, mặc định là **1.1.1.1**.

**Lưu ý:**
Một init container kiểm tra xem các địa chỉ IP cụ thể có thể truy cập được hay không có thể được sử dụng để **ngăn ứng dụng khởi động cho đến khi các dịch vụ mà nó phụ thuộc trở nên khả dụng**.

Bạn sẽ tìm thấy các Dockerfile và các tệp liên quan cho cả hai image trong mã nguồn của sách, nếu bạn muốn tự xây dựng chúng. Hoặc bạn có thể sử dụng các image mà tôi đã xây dựng sẵn.

Một tệp manifest pod chứa hai init container này là **pod.kiada-init.yaml**. Nội dung của nó được hiển thị trong listing dưới đây.

---

**Listing 5.4 Định nghĩa init container trong manifest pod**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kiada-init
spec:
  initContainers:            #A
    - name: init-demo         #B
      image: luksa/init-demo:0.1   #B
    - name: network-check     #C
      image: luksa/network-connectivity-checker:0.1  #C
  containers:                #D
    - name: kiada             #D
      image: luksa/kiada:0.2  #D
      stdin: true             #D
      ports:                  #D
        - name: http          #D
          containerPort: 8080 #D
    - name: envoy             #D
      image: luksa/kiada-ssl-proxy:0.1  #D
      ports:                  #D
        - name: https         #D
          containerPort: 8443 #D
        - name: admin         #D
          containerPort: 9901 #D
```

Như bạn thấy, định nghĩa một init container gần như rất đơn giản. Chỉ cần chỉ định **tên** và **image** cho mỗi container là đủ.

**Lưu ý:**
Tên container phải là **duy nhất** trong tất cả init container và container thông thường.

---

#### Triển khai pod với init container

Trước khi bạn tạo pod từ tệp manifest, hãy chạy lệnh sau trong một terminal riêng để quan sát trạng thái pod thay đổi khi init container và container chính khởi động:

```bash
$ kubectl get pods -w
```

Bạn cũng nên quan sát các sự kiện trong một terminal khác bằng lệnh:

```bash
$ kubectl get events -w
```

Khi sẵn sàng, hãy tạo pod bằng lệnh:

```bash
$ kubectl apply -f pod.kiada-init.yaml
```

---

#### Kiểm tra quá trình khởi động của pod với init container

Khi pod khởi động, hãy kiểm tra các sự kiện được hiển thị bởi lệnh `kubectl get events -w`:

```
TYPE    REASON     MESSAGE
Normal  Scheduled  Successfully assigned pod to worker2
Normal  Pulling    Pulling image "luksa/init-demo:0.1"        #A
Normal  Pulled     Successfully pulled image                 #A
Normal  Created    Created container init-demo                #A
Normal  Started    Started container init-demo                #A
Normal  Pulling    Pulling image "luksa/network-connec..."     #B
Normal  Pulled     Successfully pulled image                  #B
Normal  Created    Created container network-check            #B
Normal  Started    Started container network-check            #B
Normal  Pulled     Container image "luksa/kiada:0.1" already present on machine   #C
Normal  Created    Created container kiada                    #C
Normal  Started    Started container kiada                    #C
Normal  Pulled     Container image "luksa/kiada-ssl-proxy:0.1" already present on machine   #C
Normal  Created    Created container envoy                    #C
Normal  Started    Started container envoy                    #C
```

Listing cho thấy thứ tự mà các container được khởi động. Container **init-demo** được khởi động đầu tiên. Khi nó hoàn tất, container **network-check** được khởi động, và khi nó hoàn tất, hai container chính **kiada** và **envoy** được khởi động.

Bây giờ hãy kiểm tra trạng thái của pod trong terminal còn lại. Nó sẽ trông như thế này:

```
NAME         READY   STATUS            RESTARTS   AGE
kiada-init   0/2     Pending           0          0s
kiada-init   0/2     Pending           0          0s
kiada-init   0/2     Init:0/2          0          0s     #A
kiada-init   0/2     Init:0/2          0          1s     #A
kiada-init   0/2     Init:1/2          0          6s     #B
kiada-init   0/2     PodInitializing   0          7s     #C
kiada-init   2/2     Running           0          8s     #D
```

Như listing cho thấy, khi init container chạy, trạng thái pod hiển thị số lượng init container đã hoàn thành và tổng số init container. Khi tất cả init container hoàn tất, trạng thái pod được hiển thị là **PodInitializing**. Lúc này, các image của container chính sẽ được kéo về. Khi các container bắt đầu chạy, trạng thái sẽ chuyển sang **Running**.

5.5.3 Kiểm tra các init container
Giống như với các container thông thường, bạn có thể chạy thêm các lệnh trong một init container đang chạy bằng cách sử dụng **kubectl exec** và hiển thị nhật ký bằng **kubectl logs**.

**Hiển thị nhật ký của một init container**
Đầu ra tiêu chuẩn và đầu ra lỗi, nơi mỗi init container có thể ghi dữ liệu, được ghi lại giống hệt như với các container thông thường. Nhật ký của một init container có thể được hiển thị bằng lệnh **kubectl logs** bằng cách chỉ định tên của container với tùy chọn **-c**, hoặc khi container đang chạy, hoặc sau khi nó đã hoàn thành. Để hiển thị nhật ký của container **network-check** trong pod **kiada-init**, hãy chạy lệnh sau:

```
$ kubectl logs kiada-init -c network-check
Checking network connectivity to 1.1.1.1 ...
Host appears to be reachable
```

Nhật ký cho thấy init container **network-check** đã chạy mà không có lỗi nào. Trong chương tiếp theo, bạn sẽ thấy điều gì xảy ra nếu một init container gặp lỗi.

**Truy cập vào một init container đang chạy**
Bạn có thể sử dụng lệnh **kubectl exec** để chạy một shell hoặc một lệnh khác bên trong một init container giống như với các container thông thường, nhưng bạn chỉ có thể làm điều này trước khi init container kết thúc.
Nếu bạn muốn tự mình thử, hãy tạo một pod từ tệp **pod.kiada-initslow\.yaml**, tệp này sẽ khiến container **init-demo** chạy trong 60 giây. Khi pod bắt đầu, hãy chạy một shell trong container với lệnh sau:

```
$ kubectl exec -it kiada-init-slow -c init-demo -- sh
```

Bạn có thể sử dụng shell để khám phá container từ bên trong, nhưng chỉ trong một thời gian ngắn. Khi tiến trình chính của container thoát sau 60 giây, tiến trình shell cũng sẽ bị kết thúc.

Thông thường, bạn chỉ truy cập vào một init container đang chạy khi nó không hoàn thành đúng thời gian, và bạn muốn tìm ra nguyên nhân. Trong quá trình hoạt động bình thường, init container kết thúc trước khi bạn có thể chạy lệnh **kubectl exec**.

---

### 5.6 Xóa pod và các đối tượng khác

Nếu bạn đã thử các bài tập trong chương này và chương 2, thì trong cluster của bạn hiện có nhiều pod và các đối tượng khác. Để kết thúc chương này, bạn sẽ học các cách khác nhau để xóa chúng.

Việc xóa một pod sẽ kết thúc các container của nó và xóa chúng khỏi node. Việc xóa một đối tượng **Deployment** sẽ dẫn đến xóa các pod của nó, trong khi xóa một **Service** kiểu **LoadBalancer** sẽ giải phóng load balancer nếu nó đã được cấp phát.

---

### 5.6.1 Xóa một pod theo tên

Cách đơn giản nhất để xóa một đối tượng là xóa nó theo tên.

**Xóa một pod đơn lẻ**
Sử dụng lệnh sau để xóa pod **kiada** khỏi cluster của bạn:

```
$ kubectl delete po kiada
pod "kiada" deleted
```

Bằng cách xóa một pod, bạn cho biết rằng bạn không còn muốn pod hoặc các container của nó tồn tại nữa. **Kubelet** sẽ tắt các container của pod, xóa tất cả các tài nguyên liên quan như tệp nhật ký, và thông báo cho API server sau khi quá trình này hoàn tất. Đối tượng **Pod** sau đó sẽ bị xóa.

**Mẹo**
Theo mặc định, lệnh **kubectl delete** sẽ đợi cho đến khi đối tượng không còn tồn tại. Để bỏ qua việc chờ đợi, hãy chạy lệnh với tùy chọn **--wait=false**.
Trong khi pod đang trong quá trình tắt, trạng thái của nó sẽ chuyển sang **Terminating**:

```
$ kubectl get po kiada
NAME    READY   STATUS        RESTARTS   AGE
kiada   1/1     Terminating   0          35m
```

Biết chính xác cách container được tắt là điều quan trọng nếu bạn muốn ứng dụng của mình mang lại trải nghiệm tốt cho khách hàng. Điều này sẽ được giải thích trong chương tiếp theo, nơi chúng ta sẽ đi sâu hơn vào vòng đời của pod và các container của nó.

**Lưu ý**
Nếu bạn quen với Docker, bạn có thể tự hỏi liệu có thể dừng một pod và khởi động lại nó sau này, giống như với các container Docker hay không. Câu trả lời là **không**. Với Kubernetes, bạn chỉ có thể xóa hoàn toàn một pod và tạo lại nó sau này.

**Xóa nhiều pod bằng một lệnh duy nhất**
Bạn cũng có thể xóa nhiều pod bằng một lệnh duy nhất. Nếu bạn đã chạy các pod **kiada-init** và **kiada-init-slow**, bạn có thể xóa cả hai bằng cách chỉ định tên của chúng, cách nhau bởi dấu cách, như sau:

```
$ kubectl delete po kiada-init kiada-init-slow
pod "kiada-init" deleted
pod "kiada-init-slow" deleted
```

---

### 5.6.2 Xóa các đối tượng được định nghĩa trong các tệp manifest

Bất cứ khi nào bạn tạo các đối tượng từ một tệp, bạn cũng có thể xóa chúng bằng cách truyền tệp đó vào lệnh **delete** thay vì chỉ định tên của pod.

**Xóa đối tượng bằng cách chỉ định tệp manifest**
Bạn có thể xóa pod **kiada-ssl**, pod mà bạn đã tạo từ tệp **pod.kiada-ssl.yaml**, với lệnh sau:

```
$ kubectl delete -f pod.kiada-ssl.yaml
pod "kiada-ssl" deleted
```

Trong trường hợp của bạn, tệp chỉ chứa một đối tượng pod duy nhất, nhưng bạn sẽ thường gặp các tệp chứa nhiều đối tượng thuộc các loại khác nhau đại diện cho một ứng dụng hoàn chỉnh. Điều này giúp việc triển khai và gỡ bỏ ứng dụng trở nên dễ dàng như việc thực thi:

```
kubectl apply -f app.yaml
kubectl delete -f app.yaml
```

**Xóa đối tượng từ nhiều tệp manifest**
Đôi khi, một ứng dụng được định nghĩa trong nhiều tệp manifest. Bạn có thể chỉ định nhiều tệp bằng cách phân tách chúng bằng dấu phẩy. Ví dụ:

```
$ kubectl delete -f pod.kiada.yaml,pod.kiada-ssl.yaml
```

**Lưu ý**
Bạn cũng có thể áp dụng nhiều tệp cùng lúc bằng cú pháp này (ví dụ:

```
kubectl apply -f pod.kiada.yaml,pod.kiada-ssl.yaml
```

).

Tôi thực sự chưa bao giờ sử dụng cách tiếp cận này trong nhiều năm làm việc với Kubernetes, nhưng tôi thường triển khai tất cả các tệp manifest từ một thư mục bằng cách chỉ định tên thư mục thay vì tên của từng tệp riêng lẻ. Ví dụ: bạn có thể triển khai lại tất cả các pod mà bạn đã tạo trong chương này bằng cách chạy lệnh sau trong thư mục gốc của mã nguồn sách:

```
$ kubectl apply -f Chapter05/
```

Lệnh này áp dụng cho tất cả các tệp trong thư mục có phần mở rộng tệp đúng (**.yaml**, **.json**, và các loại tương tự). Sau đó, bạn có thể xóa các pod bằng cùng một phương pháp:

```
$ kubectl delete -f Chapter05/
```

**Lưu ý**
Nếu các tệp manifest của bạn được lưu trữ trong các thư mục con, bạn phải sử dụng cờ **--recursive** (hoặc **-R**).


### 5.6.3 Xóa tất cả các pod

Bạn đã xóa tất cả các pod ngoại trừ **kiada-stdin** và các pod mà bạn đã tạo trong chương 3 bằng lệnh **kubectl create deployment**. Tùy thuộc vào cách bạn đã scale deployment, một số pod trong số này vẫn sẽ đang chạy:

```bash
$ kubectl get pods
NAME                          READY   STATUS    RESTARTS   AGE
kiada-stdin                   1/1     Running   0          10m
kiada-9d785b578-58vhc         1/1     Running   0          1d
kiada-9d785b578-jmnj8         1/1     Running   0          1d
```

Thay vì xóa từng pod theo tên, chúng ta có thể xóa tất cả bằng tùy chọn **--all**:

```bash
$ kubectl delete po --all
pod "kiada-stdin" deleted
pod "kiada-9d785b578-58vhc" deleted
pod "kiada-9d785b578-jmnj8" deleted
```

Bây giờ xác nhận rằng không có pod nào tồn tại bằng cách chạy lại lệnh **kubectl get pods**:

```bash
$ kubectl get po
NAME                          READY   STATUS    RESTARTS   AGE
kiada-9d785b578-cc6tk         1/1     Running   0          13s
kiada-9d785b578-h4gml         1/1     Running   0          13s
```

Điều này thật bất ngờ! Hai pod vẫn đang chạy. Nếu bạn quan sát kỹ tên của chúng, bạn sẽ thấy rằng đây không phải là hai pod mà bạn vừa xóa. Cột **AGE** cũng cho thấy đây là các pod mới. Bạn có thể thử xóa chúng, nhưng bạn sẽ thấy rằng dù bạn xóa bao nhiêu lần, các pod mới vẫn được tạo ra để thay thế.

Lý do tại sao các pod này cứ xuất hiện là vì **Deployment object**. Controller chịu trách nhiệm quản lý các Deployment phải đảm bảo rằng số lượng pod luôn khớp với số lượng replica mong muốn được chỉ định trong đối tượng. Khi bạn xóa một pod thuộc Deployment, controller ngay lập tức tạo một pod thay thế.

Để xóa các pod này, bạn phải **scale Deployment về 0** hoặc xóa luôn đối tượng Deployment. Điều này có nghĩa là bạn không còn muốn deployment này hoặc các pod của nó tồn tại trong cluster nữa.

---

### 5.6.4 Xóa các đối tượng bằng từ khóa “all”

Bạn có thể xóa mọi thứ bạn đã tạo cho đến nay – bao gồm deployment, các pod, và service – bằng lệnh sau:

```bash
$ kubectl delete all --all
pod "kiada-9d785b578-cc6tk" deleted
pod "kiada-9d785b578-h4gml" deleted
service "kubernetes" deleted
service "kiada" deleted
deployment.apps "kiada" deleted
replicaset.apps "kiada-9d785b578" deleted
```

Chữ **all** đầu tiên trong lệnh cho biết rằng bạn muốn xóa tất cả các loại đối tượng. Tùy chọn **--all** cho biết rằng bạn muốn xóa tất cả các instance của từng loại đối tượng. Bạn đã sử dụng tùy chọn này ở phần trước khi bạn thử xóa tất cả các pod.

Khi xóa các đối tượng, **kubectl** sẽ in ra loại và tên của từng đối tượng bị xóa. Ở ví dụ trên, bạn thấy rằng nó đã xóa các pod, deployment và service, nhưng cũng có một đối tượng gọi là **replica set**. Bạn sẽ tìm hiểu kỹ hơn về nó trong chương 11, khi chúng ta xem xét chi tiết về deployments.

Bạn sẽ thấy rằng lệnh **delete** cũng xóa **kubernetes service** tích hợp sẵn. Đừng lo lắng, vì service này sẽ được tự động tạo lại sau vài giây.

Một số đối tượng sẽ không bị xóa khi dùng cách này, vì từ khóa **all** không bao gồm tất cả các loại đối tượng. Đây là biện pháp phòng ngừa để ngăn bạn vô tình xóa các đối tượng chứa thông tin quan trọng. **Event object** là một ví dụ về điều này.

**Lưu ý**
Bạn có thể chỉ định nhiều loại đối tượng trong lệnh **delete**. Ví dụ:

```bash
kubectl delete events,all --all
```

để xóa **events** cùng với tất cả các loại đối tượng được bao gồm trong **all**.

---

### 5.7 Tóm tắt

Trong chương này, bạn đã học:

* Pod chạy một hoặc nhiều container như một nhóm cùng vị trí. Chúng là đơn vị triển khai và mở rộng theo chiều ngang. Một container điển hình chỉ chạy một tiến trình. **Sidecar container** bổ sung cho container chính trong pod.
* Các container chỉ nên là một phần của cùng một pod nếu chúng **phải chạy cùng nhau**. Một tiến trình frontend và backend nên chạy trong các pod riêng biệt. Điều này cho phép chúng được scale độc lập.
* Khi một pod khởi động, **init container** của nó sẽ chạy tuần tự. Khi container init cuối cùng hoàn tất, các container chính của pod sẽ được khởi động. Bạn có thể sử dụng **init container** để cấu hình pod từ bên trong, trì hoãn việc khởi động các container chính cho đến khi một điều kiện được đáp ứng hoặc thông báo cho một dịch vụ bên ngoài rằng pod sắp bắt đầu chạy.
* Công cụ **kubectl** được dùng để tạo pod, xem log của chúng, sao chép file vào/từ các container, thực thi lệnh trong các container và cho phép giao tiếp với các pod riêng lẻ trong quá trình phát triển.
* Trong chương tiếp theo, bạn sẽ tìm hiểu về **vòng đời của pod và các container** của nó.
